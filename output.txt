# data_capture_rightmove_service/pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
      - id: black
        args: ["--line-length=88"]
  - repo: https://github.com/charliermarsh/ruff
    rev: v0.0.278
    hooks:
      - id: ruff
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v0.971
    hooks:
      - id: mypy


# data_capture_rightmove_service/Dockerfile.prod
# auth_service/Dockerfile.prod
# --- Builder Stage ---
FROM python:3.12-slim AS builder

ENV POETRY_NO_INTERACTION=1 \
    POETRY_VIRTUALENVS_CREATE=false \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1

WORKDIR /app

# Install poetry
RUN pip install poetry

# Copy only dependency files
COPY pyproject.toml poetry.lock ./

# Install only production dependencies
RUN poetry install --no-root --only main


# --- Final Stage ---
FROM python:3.12-slim AS final

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH=/app/src

WORKDIR /app

# Create a non-root user for security
RUN addgroup --system app && adduser --system --ingroup app app

# Copy the installed dependencies from the builder stage
COPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages

# Copy the executables (like alembic, uvicorn) from the builder stage
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy the application source code
COPY ./src ./src
COPY ./alembic ./alembic
COPY alembic.ini .

# Set ownership to the non-root user
RUN chown -R app:app /app

# Switch to the non-root user
USER app

EXPOSE 8000

# Command to run the production server with multiple workers
CMD ["uvicorn", "src.data_capture_rightmove_service.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]

# data_capture_rightmove_service/pytest.ini
[pytest]
testpaths = tests
asyncio_mode = strict
; asyncio_default_fixture_loop_scope = session
; asyncio_default_test_loop_scope = session
pythonpath = src
env_files =
    .env.test

filterwarnings =
    ignore::DeprecationWarning

# data_capture_rightmove_service/alembic.ini
# A generic, single database configuration.

[alembic]
# path to migration scripts
script_location = alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python-dateutil library that can be
# installed by adding `alembic[tz]` to the pip requirements
# string value is passed to dateutil.tz.gettz()
# leave blank for localtime
# timezone =

# max length of characters to apply to the
# "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
version_path_separator = os  # Use os.pathsep. Default configuration used on Windows.

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

sqlalchemy.url = 

[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S


# data_capture_rightmove_service/pyproject.toml
# This file now uses the modern PEP 621 standard for project metadata.
[project]
name = "data-capture-rightmove-service" 

version = "0.1.0"
description = "Handles data capture from Rightmove for the Paservices platform."
authors = [
    {name = "daniel", email = "danielnwachukwu5738@gmail.com"},
]
readme = "README.md"
requires-python = ">=3.12,<4.0"
dependencies = [
  # Core web framework
  "fastapi>=0.111.0,<1.0.0",
  "uvicorn[standard]>=0.30.1,<1.0.0",

  # Settings and data validation (with email support)
  "pydantic[email]>=2.5.0,<3.0.0",
  "pydantic-settings>=2.3.4,<3.0.0",

  # Database (switched to psycopg3 for consistency and modern features)
  "sqlalchemy[asyncio]>=2.0.31,<3.0.0",
  "psycopg[binary,pool]>=3.1.8,<4.0.0", # Replaced asyncpg
  "alembic>=1.13.1,<2.0.0",

  # Security and Authentication
  "python-jose[cryptography]>=3.3.0,<4.0.0",
  "passlib[bcrypt]>=1.7.4,<2.0.0",

  # External Services and Utilities
  "supabase[async]>=2.5.0,<3.0.0", # Switched to the official async client
  "fastapi-limiter>=0.1.6,<1.0.0",
  "slowapi>=0.1.9,<1.0.0", # Required for rate limiting
]

# Modern way to declare optional dependency groups like 'dev'.
# This is a placeholder; Poetry uses its own 'tool.poetry.group' table below.
[project.optional-dependencies]
dev = []


# --- Poetry Specific Configuration ---

[tool.poetry]
# Metadata is now in [project], but poetry needs these for its own commands.
name = "data-capture-rightmove-service" 
version = "0.1.0"
description = "Handles data capture from Rightmove for the Paservices platform."
authors = ["daniel <danielnwachukwu5738@gmail.com>"]
readme = "README.md"
# Defines where your actual Python package is located.
packages = [{include = "data_capture_rightmove_service", from = "src"}]


# Poetry's dependency management section (mirrors [project] table for poetry commands)
[tool.poetry.dependencies]
python = ">=3.12,<4.0"
fastapi = "^0.111.0"
uvicorn = {extras = ["standard"], version = "^0.30.1"}
pydantic = {extras = ["email"], version = "^2.7.4"}
pydantic-settings = "^2.3.4"
sqlalchemy = {extras = ["asyncio"], version = "^2.0.31"}
psycopg = {extras = ["binary", "pool"], version = "^3.1.19"}
alembic = "^1.13.1"
python-jose = {extras = ["cryptography"], version = "^3.3.0"}
passlib = {extras = ["bcrypt"], version = "^1.7.4"}
supabase = {extras = ["async"], version = "^2.5.0"}
fastapi-limiter = "^0.1.6"
slowapi = "^0.1.9"


# A comprehensive set of development dependencies
[tool.poetry.group.dev.dependencies]
# Testing
pytest = "^8.2.2"
pytest-asyncio = "^0.23.7"
pytest-cov = "^5.0.0"      # For checking test coverage
httpx = "^0.27.0"           # For making HTTP requests in tests
asgi-lifespan = "^2.1.0"    # For testing FastAPI startup/shutdown events

# Code Quality & Formatting
ruff = "^0.4.10"            # Fast linter and formatter
black = "^24.4.2"           # Opinionated code formatter
mypy = "^1.10.0"            # Static type checker

# Development Workflow
pre-commit = "^3.7.1"       # For running checks before git commits


[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

# data_capture_rightmove_service/.env.prod
# Production Environment Configuration
# IMPORTANT: This is an example file. Do not store actual secrets in this file.
# In production, use secure methods to inject these variables into the container.

# Core Configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_ENVIRONMENT=production
DATA_CAPTURE_RIGHTMOVE_SERVICE_ROOT_PATH=/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_BASE_URL=https://data-capture-rightmove.supersami.com
DATA_CAPTURE_RIGHTMOVE_SERVICE_LOGGING_LEVEL=INFO

# Supabase Configuration

# Option 1: Cloud-hosted Supabase
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_URL=https://uyjxbqnuprpzaukjlxub.supabase.co
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InV5anhicW51cHJwemF1a2pseHViIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTA4NzIyMzUsImV4cCI6MjA2NjQ0ODIzNX0.7V-9troSvclxJ2c8M5NNmGZWTQiiMz_qPLm12dpAmoA
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InV5anhicW51cHJwemF1a2pseHViIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MDg3MjIzNSwiZXhwIjoyMDY2NDQ4MjM1fQ.PiT3oWe9M3Bj4KMQMmgV5611-Zx23IDIgKMYE2e7IlE
DATA_CAPTURE_RIGHTMOVE_DOMAIN=https://data-capture-rightmove.supersami.com

# Option 2: Self-hosted Supabase
# Uncomment and configure these settings if using self-hosted Supabase
AUTH_SERVICE_SUPABASE_SELF_HOSTED=false
# AUTH_SERVICE_SUPABASE_URL=https://your-domain.com
# AUTH_SERVICE_SUPABASE_ANON_KEY=your-anon-key  # From generate-keys.sh script
# AUTH_SERVICE_SUPABASE_SERVICE_ROLE_KEY=your-service-role-key  # From generate-keys.sh script
# AUTH_SERVICE_SUPABASE_DB_HOST=db  # Use 'db' if within the same Docker network, otherwise the actual host address
# AUTH_SERVICE_SUPABASE_DB_PORT=5432
# SUPABASE_DB_NAME=postgres
# SUPABASE_DB_USER=postgres
# SUPABASE_DB_PASSWORD=your-db-password

# Authentication and Service connections
DATA_CAPTURE_RIGHTMOVE_SERVICE_AUTH_SERVICE_URL=http://auth_service:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPER_ID_SERVICE_URL=http://super_id_service:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_ID=development-client
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_SECRET=development-secret
DATA_CAPTURE_RIGHTMOVE_SERVICE_JWT_SECRET_KEY=development_jwt_secret

# Shared Supabase settings
AUTH_SERVICE_SUPABASE_EMAIL_CONFIRMATION_REQUIRED=true
AUTH_SERVICE_SUPABASE_AUTO_CONFIRM_NEW_USERS=false

# Database Configuration
# Using psycopg3 driver which supports both sync and async operations
DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL=postgresql+psycopg://postgres.uyjxbqnuprpzaukjlxub:aRvOIliyfnEfW1P0@aws-0-us-east-2.pooler.supabase.com:6543/postgres
USE_PGBOUNCER=false

# JWT Configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_JWT_SECRET_KEY=R/63F1Kd/G4Heoa8nQoefaiXfo7cliYHfUvvezvIFtk=
M2M_JWT_ACCESS_TOKEN_EXPIRE_MINUTES=15

# Rate Limiting Configuration
RATE_LIMIT_LOGIN=5/minute
RATE_LIMIT_REGISTER=3/minute
RATE_LIMIT_TOKEN=10/minute
RATE_LIMIT_PASSWORD_RESET=3/minute

# Redis Configuration (for token revocation)
# REDIS_URL=redis://redis:6379/0
REDIS_URL=redis://:pKzwp7Kcmi@paservices-redis-master.default.svc.cluster.local:6379/0
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_HOST=redis
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_PORT=6379
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_URL=redis://redis:6379/0

# Initial Admin Configuration (used only during first startup)
INITIAL_ADMIN_EMAIL=admin@admin.com
INITIAL_ADMIN_PASSWORD=admin

# OAuth Configuration
OAUTH_STATE_COOKIE_NAME=supabase-auth-state
OAUTH_CALLBACK_ROUTE_BASE=/auth/users/oauth/callback

# Email redirection
EMAIL_CONFIRMATION_REDIRECT_URL=https://your-frontend.com/confirm-email
PASSWORD_RESET_REDIRECT_URL=https://your-frontend.com/reset-password

# RightMove API configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTIES_DETAILS_ENDPOINT=/properties/details
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT=/buy/property-for-sale
DATA_CAPTURE_RIGHTMOVE_SERVICE_BATCH_SIZE=10
DATA_CAPTURE_RIGHTMOVE_SERVICE_FETCH_INTERVAL_SECONDS=3600

# data_capture_rightmove_service/.env.test
# Core service settings
DATA_CAPTURE_RIGHTMOVE_SERVICE_ENVIRONMENT=development
DATA_CAPTURE_RIGHTMOVE_SERVICE_ROOT_PATH=/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_LOGGING_LEVEL=DEBUG

# Database configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL=postgresql+psycopg://postgres:postgres@supabase_db_paservices:5432/rightmove_test_db
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_HOST=supabase_db_paservices
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_PORT=5432
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_USER=postgres
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_PASSWORD=postgres
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_DB=rightmove_test_db

DATA_CAPTURE_RIGHTMOVE_SERVICE_POOL_SIZE=5
DATA_CAPTURE_RIGHTMOVE_SERVICE_MAX_OVERFLOW=10

# Redis configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_HOST=redis
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_PORT=6379
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_URL=redis://redis:6379/0

# Authentication and Service connections
DATA_CAPTURE_RIGHTMOVE_SERVICE_AUTH_SERVICE_URL=http://auth_service:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPER_ID_SERVICE_URL=http://super_id_service:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_ID=development-client
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_SECRET=development-secret
DATA_CAPTURE_RIGHTMOVE_SERVICE_JWT_SECRET_KEY=development_jwt_secret

# API settings
DATA_CAPTURE_RIGHTMOVE_SERVICE_RATE_LIMIT_REQUESTS_PER_MINUTE=100
DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_KEY=fake-api-key-for-development
DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_HOST=uk-real-estate-rightmove.p.rapidapi.com

# RightMove API configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTIES_DETAILS_ENDPOINT=/properties/details
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT=/buy/property-for-sale
DATA_CAPTURE_RIGHTMOVE_SERVICE_BATCH_SIZE=10
DATA_CAPTURE_RIGHTMOVE_SERVICE_FETCH_INTERVAL_SECONDS=3600

# data_capture_rightmove_service/docker-compose.dev.yml
services:
  data_capture_rightmove_service_dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "8003:8000"
    volumes:
      - ./src:/app/src
      - ./alembic:/app/alembic
      - ./alembic.ini:/app/alembic.ini
      - ./tests:/app/tests
      - ./scripts:/app/scripts
    env_file:
      - ./.env.dev
    networks:
      - paservices_network
      - supabase_network_paservices # Connect to Supabase network from root compose

networks:
  paservices_network:
    name: paservices_network
    driver: bridge
  supabase_network_paservices:
    external: true


# data_capture_rightmove_service/README.md
# Data Capture Rightmove Service

A microservice for capturing and processing property data from the Rightmove API.

## Architecture

This service follows the PA Services microservice architecture patterns with standardized configurations and utilities:

- **FastAPI** for the REST API framework
- **SQLAlchemy 2.0** with async capabilities for database operations
- **Pydantic V2** for data validation and serialization
- **JWT-based authentication** for service-to-service communication
- **Rate limiting** to protect downstream services and APIs
- **Structured JSON logging** for production environments
- **Alembic** for database migrations

## Project Structure

```
data_capture_rightmove_service/
├── alembic/                      # Database migration files
├── k8s/                          # Kubernetes deployment manifests
├── src/
│   └── data_capture_rightmove_service/
│       ├── clients/              # API clients for external services
│       ├── crud/                 # Database CRUD operations
│       ├── models/               # SQLAlchemy ORM models
│       ├── routers/              # API route handlers
│       ├── schemas/              # Pydantic models for request/response validation
│       ├── utils/                # Utility modules for logging, security, etc.
│       ├── config.py             # Configuration settings with environment variables
│       ├── db.py                 # Database connection management
│       ├── main.py               # Application entrypoint
├── tests/                        # Test suite
├── alembic.ini                   # Alembic configuration
├── docker-compose.yml            # Local development environment
├── Dockerfile                    # Container build configuration
├── pyproject.toml                # Project metadata and dependencies
└── README.md                     # Project documentation
```

## Environment Variables

The service uses environment variables with the `DATA_CAPTURE_RIGHTMOVE_SERVICE_` prefix to avoid conflicts with other services:

| Variable                                            | Description                                                | Default                  |
| --------------------------------------------------- | ---------------------------------------------------------- | ------------------------ |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_ENVIRONMENT          | Application environment (development, testing, production) | development              |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_ROOT_PATH            | API root path for reverse proxies                          | /api/v1                  |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_LOGGING_LEVEL        | Logging level                                              | INFO                     |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL         | PostgreSQL connection string                               | (Required)               |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_AUTH_SERVICE_URL     | URL for the Auth Service API                               | (Required)               |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPER_ID_SERVICE_URL | URL for the Super ID Service API                           | (Required)               |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_ID        | Client ID for machine-to-machine auth                      | (Required)               |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_SECRET    | Client secret for machine-to-machine auth                  | (Required)               |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_JWT_SECRET_KEY       | Secret key for JWT validation                              | (Required)               |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_URL            | Redis connection string                                    | redis://localhost:6379/0 |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_RATE_LIMIT           | Rate limit configuration                                   | 100/minute               |
| DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPIDAPI_KEY         | API key for RapidAPI                                       | (Required)               |

## Local Development

### Prerequisites

- Docker and Docker Compose
- Python 3.11+
- PostgreSQL 15+
- Redis

### Setup

1. Clone the repository:

```bash
git clone https://github.com/your-organization/paservices.git
cd paservices/data_capture_rightmove_service
```

2. Set up the development environment:

```bash
# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"
```

3. Start services with Docker Compose:

```bash
docker-compose up -d
```

4. Run database migrations:

```bash
alembic upgrade head
```

5. Start the development server:

```bash
uvicorn data_capture_rightmove_service.main:app --reload
```

The API will be available at http://localhost:8000

### Database Migrations

Create a new migration:

```bash
alembic revision --autogenerate -m "description"
```

Apply migrations:

```bash
alembic upgrade head
```

## Testing

Run the test suite:

```bash
pytest
```

Run with coverage report:

```bash
pytest --cov=data_capture_rightmove_service
```

## Deployment

### Docker

Build the container:

```bash
docker build -t data-capture-rightmove-service:latest .
```

### Kubernetes

1. Create the required namespace (if not already created):

```bash
kubectl create namespace paservices
```

2. Apply ConfigMap:

```bash
kubectl apply -f k8s/configmap.yaml
```

3. Create secrets (replace placeholders with actual values):

```bash
# Create from template
envsubst < k8s/secret.yaml.template > k8s/secret.yaml
# Apply secret
kubectl apply -f k8s/secret.yaml
```

4. Deploy the service:

```bash
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
```

## API Documentation

When the service is running, OpenAPI documentation is available at:

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## Security

- All endpoints are protected with JWT authentication
- M2M (machine-to-machine) authentication uses OAuth2 client credentials flow
- Tokens are validated with scope enforcement
- Rate limiting is applied to prevent abuse

## Additional Documentation

For more detailed documentation on specific components, refer to the following:

- [API Client Documentation](docs/api-clients.md)
- [Database Model Documentation](docs/database-models.md)
- [Deployment Guidelines](docs/deployment.md)

curl -X POST "http://localhost:8003/api/v1/properties/fetch/combined" -H "Content-Type: application/json" -d '{"property_url": "https://www.rightmove.co.uk/properties/154508327#/?channel=RES_LET"}' | jq


# data_capture_rightmove_service/Dockerfile.dev
# Base image for development
FROM python:3.12-slim

# Set environment variables for Poetry and Python
ENV POETRY_NO_INTERACTION=1 \
    POETRY_VIRTUALENVS_IN_PROJECT=false \
    POETRY_VIRTUALENVS_CREATE=false \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH=/app/src

WORKDIR /app

RUN apt-get update && \
    apt-get install -y --no-install-recommends postgresql-client dnsutils && \
    rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install poetry

# Copy only the dependency files to leverage Docker cache
COPY pyproject.toml poetry.lock ./

# Install all dependencies, including dev dependencies
RUN poetry install --no-root

# Copy the entire service source code
COPY . .

# Expose the port the app runs on
EXPOSE 8000

# Start the development server with hot-reloading
CMD ["uvicorn", "src.data_capture_rightmove_service.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

# data_capture_rightmove_service/.env.dev
# Core service settings
DATA_CAPTURE_RIGHTMOVE_SERVICE_ENVIRONMENT=development
DATA_CAPTURE_RIGHTMOVE_SERVICE_ROOT_PATH=/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_LOGGING_LEVEL=DEBUG

# # Database configuration - LOCAL INSTANCE
# DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL=postgresql+psycopg://postgres:postgres@supabase_db_paservices:5432/data_capture_rightmove_dev_db

# Database configuration - CLOUD INSTANCE
DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL=postgresql+psycopg://postgres.uyjxbqnuprpzaukjlxub:aRvOIliyfnEfW1P0@aws-0-us-east-2.pooler.supabase.com:6543/postgres

# Redis configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_HOST=redis
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_PORT=6379
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_URL=redis://redis:6379/0

# Authentication and Service connections
DATA_CAPTURE_RIGHTMOVE_SERVICE_AUTH_SERVICE_URL=http://auth_service:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPER_ID_SERVICE_URL=http://super_id_service:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_ID=fe2c7655-0860-4d98-9034-cd5e1ac90a41
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_SECRET=dev-rightmove-service-secret
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_JWT_SECRET_KEY=shared_secret_key

# # Supabase LOCAL configuration
# DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_URL=http://supabase_kong_paservices:8000
# DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0
# DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU

# Supabase CLOUD configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_URL=https://uyjxbqnuprpzaukjlxub.supabase.co
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTcxOTA0MzgzNywiZXhwIjoyMDM0NjE5ODM3fQ.dnpFblRk8XxSMpFOuhO8VYVYvi13hV8-E-QDZkuJXRs
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoic2VydmljZV9yb2xlIiwiaWF0IjoxNzE5MDQzODM3LCJleHAiOjIwMzQ2MTk4Mzd9.qPI5TPgtitHduhVxN3jOPN-6MlwPbG1Tct9jD9sXHaM

# API settings
DATA_CAPTURE_RIGHTMOVE_SERVICE_RATE_LIMIT_REQUESTS_PER_MINUTE=100
DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_KEY=f4adffc4dbmsh8f530f1ac9b4b1ep11e20djsn17b8fc732bab
DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_HOST=uk-real-estate-rightmove.p.rapidapi.com

# RightMove API configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTIES_DETAILS_ENDPOINT=/properties/details
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT=/buy/property-for-sale
DATA_CAPTURE_RIGHTMOVE_SERVICE_BATCH_SIZE=10
DATA_CAPTURE_RIGHTMOVE_SERVICE_FETCH_INTERVAL_SECONDS=3600


# data_capture_rightmove_service/docker-compose.prod.yml
services:
  traefik:
    image: traefik:v2.10
    container_name: paservices_traefik
    restart: unless-stopped
    command:
      - "--api.insecure=false"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL:-your-email@example.com}"
      - "--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json"
      - "--certificatesresolvers.letsencrypt.acme.tlschallenge=true"
      - "--entrypoints.web.http.redirections.entryPoint.to=websecure"
      - "--entrypoints.web.http.redirections.entryPoint.scheme=https"
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik-certificates:/letsencrypt
    networks:
      - web
    environment:
      - TZ=UTC

  data_capture_rightmove_service:
    build:
      context: .
      dockerfile: Dockerfile.prod
    image: paservices-data_capture_rightmove_service:prod
    container_name: data_capture_rightmove_service_prod
    restart: unless-stopped
    environment:
      - ENVIRONMENT=production
      - ROOT_PATH=/api/v1
      - BASE_URL=https://${AUTH_DOMAIN:-auth.supersami.com}
      - LOGGING_LEVEL=INFO
    env_file:
      - .env.production
    networks:
      - web
      - internal
      - data_capture_rightmove_service_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.auth.rule=Host(`${AUTH_DOMAIN:-auth.supersami.com}`)"
      - "traefik.http.routers.auth.entrypoints=websecure"
      - "traefik.http.routers.auth.tls.certresolver=letsencrypt"
      - "traefik.http.services.auth.loadbalancer.server.port=8000"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M

  redis:
    image: redis:7-alpine
    container_name: auth_redis_prod
    restart: unless-stopped
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis_data:/data
    networks:
      - internal
      - data_capture_rightmove_service_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

networks:
  web:
  internal:
  data_capture_rightmove_service_network:
  supabase_network:
    external:
      true # This assumes the Supabase network already exists
      # Comment this out if not using self-hosted Supabase

volumes:
  redis_data:
    driver: local
  traefik-certificates:


# data_capture_rightmove_service/docker-compose.test.yml
# data_capture_rightmove_service/docker-compose.test.yml
services:
  data_capture_rightmove_service_test:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - ENVIRONMENT=testing
    env_file:
      - ./.env.test
    networks:
      - paservices_network
      - supabase_network_paservices
    command: ["pytest", "-v", "tests/"]

networks:
  paservices_network:
    name: paservices_network
    driver: bridge
  supabase_network_paservices:
    external: true


# data_capture_rightmove_service/env.test
# Database configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_HOST=postgres_test
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_PORT=5432
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_USER=postgres
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_PASSWORD=postgres
DATA_CAPTURE_RIGHTMOVE_SERVICE_POSTGRES_DB=rightmove_test
DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres_test:5432/rightmove_test
DATA_CAPTURE_RIGHTMOVE_SERVICE_POOL_SIZE=5
DATA_CAPTURE_RIGHTMOVE_SERVICE_MAX_OVERFLOW=10

# Core service settings
DATA_CAPTURE_RIGHTMOVE_SERVICE_ENVIRONMENT=testing
DATA_CAPTURE_RIGHTMOVE_SERVICE_ROOT_PATH=/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_LOGGING_LEVEL=DEBUG

# Redis configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_HOST=redis_test
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_PORT=6379
DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_URL=redis://redis_test:6379/0

# Authentication and Service connections
DATA_CAPTURE_RIGHTMOVE_SERVICE_AUTH_SERVICE_URL=http://auth_service_test:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPER_ID_SERVICE_URL=http://super_id_service_test:8000/api/v1
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_ID=test-client
DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_SECRET=test-secret
DATA_CAPTURE_RIGHTMOVE_SERVICE_JWT_SECRET_KEY=test_jwt_secret

# API settings
DATA_CAPTURE_RIGHTMOVE_SERVICE_RATE_LIMIT_REQUESTS_PER_MINUTE=1000
DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_KEY=fake-api-key-for-testing
DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_HOST=uk-real-estate-rightmove.p.rapidapi.com

# RightMove API configuration
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTIES_DETAILS_ENDPOINT=/properties/details
DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT=/buy/property-for-sale
DATA_CAPTURE_RIGHTMOVE_SERVICE_BATCH_SIZE=5
DATA_CAPTURE_RIGHTMOVE_SERVICE_FETCH_INTERVAL_SECONDS=60


# data_capture_rightmove_service/tests/conftest.py
"""
Main conftest file that imports and re-exports all fixtures from modular files.
This approach improves maintainability by organizing fixtures into logical modules.
"""

import asyncio
import os
from typing import AsyncGenerator, Generator

import pytest
from dotenv import load_dotenv
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine

# Explicitly load the test environment variables
dotenv_path = os.path.join(os.path.dirname(__file__), "..", ".env.test")
if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path=dotenv_path, override=True)
else:
    print(f"Warning: .env.test file not found at {dotenv_path}")

# Now reload the config to ensure it picks up test settings
from importlib import reload

from src.data_capture_rightmove_service import config

reload(config)

# Use a dedicated database for testing
# This should be different from the development database
SQLALCHEMY_TEST_DATABASE_URL = f"postgresql+psycopg://{config.DB_USER}:{config.DB_PASSWORD}@{config.DB_HOST}:{config.DB_PORT}/{config.DB_NAME}_test"

# Create async engine and session for testing
test_engine = create_async_engine(
    SQLALCHEMY_TEST_DATABASE_URL,
    echo=False,
    connect_args={"server_settings": {"search_path": "rightmove,public"}},
)

TestAsyncSessionLocal = async_sessionmaker(
    test_engine, expire_on_commit=False, class_=AsyncSession
)


@pytest.fixture
async def event_loop() -> Generator:
    """Create an instance of the default event loop for each test case."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest.fixture
async def setup_test_database() -> AsyncGenerator:
    """
    Setup a test database by creating tables and setting up the schema.
    """
    # Create tables and set up schema
    async with test_engine.begin() as conn:
        # Create the rightmove schema if it doesn't exist
        await conn.execute(text("CREATE SCHEMA IF NOT EXISTS rightmove;"))

        # Import and create tables based on models
        from data_capture_rightmove_service.models.base import Base
        from data_capture_rightmove_service.models.properties_details_v2 import (  # Import all other models used in the tests
            ApiPropertiesDetailsV2,
        )
        from data_capture_rightmove_service.models.property_details import (  # Import all other models used in the tests
            ApiPropertyDetails,
        )

        # Create all tables in the metadata
        await conn.run_sync(Base.metadata.create_all)

    yield

    # Teardown - Drop all tables
    async with test_engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)


@pytest.fixture
async def db_session(setup_test_database) -> AsyncGenerator[AsyncSession, None]:
    """
    Create a fresh session for each test, then roll back all the changes.
    """
    async with TestAsyncSessionLocal() as session:
        yield session
        await session.rollback()


@pytest.fixture
async def seed_rightmove_property():
    """Helper fixture to seed a test Rightmove property."""

    async def _seed_rightmove_property(
        db_session: AsyncSession, property_id=None, with_relations=False
    ):
        """Seed a test Rightmove property record with specified ID or auto-generated one.

        Args:
            db_session: The database session
            property_id: Optional property ID to use (BigInt)
            with_relations: Whether to create related records too

        Returns:
            The ID of the created property
        """
        import random

        from data_capture_rightmove_service.models.properties_details_v2 import (
            ApiPropertiesDetailsV2,
            ApiPropertiesDetailsV2Misinfo,
            ApiPropertiesDetailsV2Price,
        )

        # Create base property
        if property_id is None:
            property_id = random.randint(10000000, 99999999)

        # Create main property record
        property_record = ApiPropertiesDetailsV2(
            id=property_id,
            transaction_type="SALE",
            bedrooms=3,
            summary="Test property for unit tests",
            address="123 Test Street, Testville",
        )
        db_session.add(property_record)
        await db_session.flush()

        if with_relations:
            # Add misinfo relation
            misinfo = ApiPropertiesDetailsV2Misinfo(
                api_property_id=property_id,
                branch_id=12345,
                brand_plus=False,
                featured_property=True,
                channel="BUY",
            )
            db_session.add(misinfo)

            # Add price relation
            price = ApiPropertiesDetailsV2Price(
                api_property_id=property_id,
                amount=250000,
                currency_code="GBP",
                frequency=None,
                qualifier="Guide Price",
            )
            db_session.add(price)

        await db_session.commit()
        return property_id

    return _seed_rightmove_property


# data_capture_rightmove_service/tests/__init__.py
"""
Test package for the data_capture_rightmove_service.
"""


# data_capture_rightmove_service/tests/routers/test_combined_property_endpoint.py
"""
Tests for the combined property endpoints in property_router.
"""
import uuid
from typing import AsyncGenerator
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from fastapi import FastAPI
from httpx import AsyncClient
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.routers.property_router import router


@pytest.fixture
def app() -> FastAPI:
    """Create test FastAPI app with the property router."""
    app = FastAPI()
    app.include_router(router)
    return app


@pytest.fixture
async def client(app: FastAPI) -> AsyncGenerator:
    """Get test client for the FastAPI app."""
    async with AsyncClient(app=app, base_url="http://test") as client:
        yield client


@pytest.fixture
def mock_db_session():
    """Create a mock DB session."""
    return AsyncMock(AsyncSession)


@pytest.fixture
def mock_super_id_client():
    """Mock the super_id_service_client."""
    with patch("data_capture_rightmove_service.routers.property_router.super_id_service_client") as mock:
        mock.create_super_id = AsyncMock(return_value=uuid.uuid4())
        yield mock


@pytest.fixture
def mock_rightmove_api_client():
    """Mock the rightmove_api_client."""
    with patch("data_capture_rightmove_service.routers.property_router.rightmove_api_client") as mock:
        # Sample data structures that match expected API responses
        mock.get_property_details = AsyncMock(return_value={
            "propertyId": 123456789,
            "transactionType": "SALE",
            "bedrooms": 3,
            "price": {"amount": 350000, "qualifier": "Guide Price"},
            "agent": {
                "branchId": 12345,
                "branchName": "Test Agent",
                "branchLogoUrl": "https://example.com/logo.jpg",
            },
            "propertyImages": {
                "images": [
                    {"url": "https://example.com/image1.jpg", "caption": "Front view"},
                    {"url": "https://example.com/image2.jpg", "caption": "Kitchen"},
                ]
            },
            "floorplans": [
                {"url": "https://example.com/floorplan.jpg"}
            ],
        })
        
        mock.get_property_for_sale_details = AsyncMock(return_value={
            "id": 123456789,
            "propertyType": "Detached house",
            "bedrooms": 3,
            "summary": "A beautiful 3 bed detached house",
            "price": {
                "currencyCode": "GBP",
                "displayPrice": "£350,000",
                "priceQualifier": "Guide Price",
            },
            "customer": {
                "branchId": 12345,
                "branchName": "Test Agent",
                "companyName": "Test Company",
                "branchLogo": "https://example.com/logo.jpg",
            },
            "images": [
                {"url": "https://example.com/image1.jpg", "caption": "Front view"},
                {"url": "https://example.com/image2.jpg", "caption": "Kitchen"},
            ],
            "floorplans": [
                {"url": "https://example.com/floorplan.jpg", "caption": "Floor 1"},
            ],
        })
        
        yield mock


@pytest.fixture
def mock_store_functions():
    """Mock the database store functions."""
    with patch("data_capture_rightmove_service.routers.property_router.store_properties_details") as mock_store_properties:
        with patch("data_capture_rightmove_service.routers.property_router.store_property_details") as mock_store_property:
            mock_store_properties.return_value = (True, "Successfully stored properties details")
            mock_store_property.return_value = (True, "Successfully stored property details")
            
            yield mock_store_properties, mock_store_property


@pytest.mark.asyncio
async def test_fetch_combined_with_property_id(
    client, 
    mock_db_session, 
    mock_super_id_client, 
    mock_rightmove_api_client, 
    mock_store_functions
):
    """Test the combined fetch endpoint with a property ID."""
    # Override dependency
    app = client.app
    app.dependency_overrides = {
        "get_db": lambda: mock_db_session,
    }
    
    # Make the request
    response = await client.post(
        "/properties/fetch/combined",
        json={"property_id": 123456789}
    )
    
    # Check response
    assert response.status_code == 200
    data = response.json()
    
    # Verify response structure
    assert data["property_id"] == 123456789
    assert "results" in data
    assert len(data["results"]) == 2
    
    # Verify API calls
    mock_rightmove_api_client.get_property_details.assert_called_once_with("123456789")
    mock_rightmove_api_client.get_property_for_sale_details.assert_called_once_with("123456789")
    
    # Verify storage calls
    mock_store_properties, mock_store_property = mock_store_functions
    mock_store_properties.assert_called_once()
    mock_store_property.assert_called_once()


@pytest.mark.asyncio
async def test_fetch_combined_with_property_url(
    client, 
    mock_db_session, 
    mock_super_id_client, 
    mock_rightmove_api_client, 
    mock_store_functions
):
    """Test the combined fetch endpoint with a property URL."""
    # Override dependency
    app = client.app
    app.dependency_overrides = {
        "get_db": lambda: mock_db_session,
    }
    
    # Make the request with a URL
    test_url = "https://www.rightmove.co.uk/properties/123456789#/?channel=RES_BUY"
    response = await client.post(
        "/properties/fetch/combined",
        json={"property_url": test_url}
    )
    
    # Check response
    assert response.status_code == 200
    data = response.json()
    
    # Verify response structure
    assert data["property_id"] == 123456789
    assert data["property_url"] == test_url
    assert "results" in data
    assert len(data["results"]) == 2
    
    # Verify API calls - should use extracted ID
    mock_rightmove_api_client.get_property_details.assert_called_once_with("123456789")
    mock_rightmove_api_client.get_property_for_sale_details.assert_called_once_with("123456789")
    
    # Verify storage calls
    mock_store_properties, mock_store_property = mock_store_functions
    mock_store_properties.assert_called_once()
    mock_store_property.assert_called_once()


@pytest.mark.asyncio
async def test_fetch_combined_invalid_url(
    client, 
    mock_db_session
):
    """Test the combined fetch endpoint with an invalid URL."""
    # Override dependency
    app = client.app
    app.dependency_overrides = {
        "get_db": lambda: mock_db_session,
    }
    
    # Make the request with an invalid URL
    response = await client.post(
        "/properties/fetch/combined",
        json={"property_url": "https://www.example.com/not-rightmove"}
    )
    
    # Check response is an error
    assert response.status_code == 400
    data = response.json()
    assert "Failed to extract property ID" in data["detail"]


@pytest.mark.asyncio
async def test_fetch_combined_no_identifiers(
    client, 
    mock_db_session
):
    """Test the combined fetch endpoint with no property identifiers."""
    # Override dependency
    app = client.app
    app.dependency_overrides = {
        "get_db": lambda: mock_db_session,
    }
    
    # Make the request with no identifiers
    response = await client.post(
        "/properties/fetch/combined",
        json={"description": "Test property"}
    )
    
    # Check response is an error
    assert response.status_code == 400
    data = response.json()
    assert "Either property_id or property_url must be provided" in data["detail"]


@pytest.mark.asyncio
async def test_validate_url_endpoint_valid_url(client):
    """Test the URL validation endpoint with a valid URL."""
    response = await client.get(
        "/properties/validate-url",
        params={"url": "https://www.rightmove.co.uk/properties/123456789"}
    )
    
    assert response.status_code == 200
    data = response.json()
    assert data["valid"] is True
    assert data["property_id"] == 123456789


@pytest.mark.asyncio
async def test_validate_url_endpoint_invalid_url(client):
    """Test the URL validation endpoint with an invalid URL."""
    response = await client.get(
        "/properties/validate-url",
        params={"url": "https://www.example.com/not-rightmove"}
    )
    
    assert response.status_code == 200
    data = response.json()
    assert data["valid"] is False
    assert data["property_id"] is None


# data_capture_rightmove_service/tests/unit/test_properties_details_v2_models.py
"""
Unit tests for the properties_details_v2 SQLAlchemy models.
Tests database interactions and model relationships using the test database.
"""
import uuid
import pytest
import logging
from decimal import Decimal
from sqlalchemy import select
from sqlalchemy.exc import IntegrityError
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.models.properties_details_v2 import (
    ApiPropertiesDetailsV2,
    ApiPropertiesDetailsV2Misinfo,
    ApiPropertiesDetailsV2Status,
    ApiPropertiesDetailsV2StampDuty,
    ApiPropertiesDetailsV2Features,
    ApiPropertiesDetailsV2Branch,
    ApiPropertiesDetailsV2Price
)

# Set up logger
logger = logging.getLogger(__name__)


class TestPropertiesDetailsV2Models:
    """Test suite for properties_details_v2 models and their relationships."""
    
    @pytest.mark.asyncio
    async def test_create_main_property_model(self, db_session):
        """Test creating a property record with basic fields."""
        # Arrange - Create property data
        property_id = 12345678
        test_property = ApiPropertiesDetailsV2(
            id=property_id,
            transaction_type="SALE",
            bedrooms=3,
            address="123 Test Street, Testville",
            summary="A test property with 3 bedrooms",
            display_address="Test Street, Testville",
            property_type="TERRACED",
            property_sub_type="TERRACED_HOUSE",
            bathrooms=2,
            view_count=150
        )
        
        # Act - Save to database
        db_session.add(test_property)
        await db_session.flush()
        
        # Generate a super_id value
        test_property.super_id = uuid.uuid4()
        await db_session.commit()
        
        # Assert - Verify record was saved properly
        result = await db_session.execute(
            select(ApiPropertiesDetailsV2).where(ApiPropertiesDetailsV2.id == property_id)
        )
        saved_property = result.scalars().first()
        
        # Check field values
        assert saved_property is not None
        assert saved_property.id == property_id
        assert saved_property.transaction_type == "SALE"
        assert saved_property.bedrooms == 3
        assert saved_property.address == "123 Test Street, Testville"
        assert saved_property.summary == "A test property with 3 bedrooms"
        assert saved_property.property_type == "TERRACED"
        assert saved_property.property_sub_type == "TERRACED_HOUSE"
        assert saved_property.super_id is not None

    @pytest.mark.asyncio
    async def test_create_property_with_relationships(self, db_session):
        """Test creating a property with related records."""
        # Arrange - Create property record with ID
        property_id = 23456789
        test_property = ApiPropertiesDetailsV2(
            id=property_id,
            transaction_type="SALE",
            bedrooms=3,
            address="456 Related Property, Testborough"
        )
        
        # Add property and flush to generate ID
        db_session.add(test_property)
        await db_session.flush()
        
        # Create related records
        misinfo = ApiPropertiesDetailsV2Misinfo(
            api_property_id=property_id,
            branch_id=9876,
            brand_plus=True,
            featured_property=True,
            channel="BUY",
            premium_display=False
        )
        
        status = ApiPropertiesDetailsV2Status(
            api_property_id=property_id,
            display_status="FOR_SALE",
            can_display_floorplans=True,
            can_display_photos=True,
            published=True
        )
        
        price = ApiPropertiesDetailsV2Price(
            api_property_id=property_id,
            amount=350000,
            currency_code="GBP",
            qualifier="Guide Price"
        )
        
        # Add related records to session
        db_session.add_all([misinfo, status, price])
        await db_session.commit()
        
        # Act - Query the property with related data
        result = await db_session.execute(
            select(ApiPropertiesDetailsV2).where(ApiPropertiesDetailsV2.id == property_id)
        )
        saved_property = result.scalars().first()
        
        # Assert - Check relationships loaded correctly
        assert saved_property is not None
        
        # Check each relationship
        assert saved_property.misinfo is not None
        assert saved_property.misinfo.branch_id == 9876
        assert saved_property.misinfo.brand_plus is True
        
        assert saved_property.status is not None
        assert saved_property.status.display_status == "FOR_SALE"
        assert saved_property.status.published is True
        
        assert saved_property.price is not None
        assert saved_property.price.amount == 350000
        assert saved_property.price.currency_code == "GBP"
        
    @pytest.mark.asyncio
    async def test_cascade_delete(self, db_session):
        """Test cascade delete behavior between property and related tables."""
        # Arrange - Create property with related records
        property_id = 34567890
        
        # Create main property
        test_property = ApiPropertiesDetailsV2(
            id=property_id,
            transaction_type="SALE",
            bedrooms=2,
            address="789 Cascade Test Lane, Testford"
        )
        
        # Add property and flush to generate ID
        db_session.add(test_property)
        await db_session.flush()
        
        # Create related records
        misinfo = ApiPropertiesDetailsV2Misinfo(
            api_property_id=property_id,
            branch_id=5432,
            channel="BUY"
        )
        
        branch = ApiPropertiesDetailsV2Branch(
            api_property_id=property_id,
            branch_id=5432,
            branch_name="Test Branch",
            company_name="Test Property Company"
        )
        
        # Add related records to session
        db_session.add_all([misinfo, branch])
        await db_session.commit()
        
        # Act - Delete the main property record
        await db_session.execute(
            select(ApiPropertiesDetailsV2).where(ApiPropertiesDetailsV2.id == property_id)
        )
        property_to_delete = (await db_session.execute(
            select(ApiPropertiesDetailsV2).where(ApiPropertiesDetailsV2.id == property_id)
        )).scalars().first()
        
        await db_session.delete(property_to_delete)
        await db_session.commit()
        
        # Assert - Verify cascade delete worked
        # Check main property is gone
        property_check = (await db_session.execute(
            select(ApiPropertiesDetailsV2).where(ApiPropertiesDetailsV2.id == property_id)
        )).scalars().first()
        assert property_check is None
        
        # Check related records are gone
        misinfo_check = (await db_session.execute(
            select(ApiPropertiesDetailsV2Misinfo).where(ApiPropertiesDetailsV2Misinfo.api_property_id == property_id)
        )).scalars().first()
        assert misinfo_check is None
        
        branch_check = (await db_session.execute(
            select(ApiPropertiesDetailsV2Branch).where(ApiPropertiesDetailsV2Branch.api_property_id == property_id)
        )).scalars().first()
        assert branch_check is None

    @pytest.mark.asyncio
    async def test_foreign_key_constraint(self, db_session):
        """Test foreign key constraint enforces relationship integrity."""
        # Try to create related record without a main property
        non_existent_property_id = 99999999
        
        # Create related record referencing non-existent property
        invalid_misinfo = ApiPropertiesDetailsV2Misinfo(
            api_property_id=non_existent_property_id,
            branch_id=1234,
            channel="BUY"
        )
        
        db_session.add(invalid_misinfo)
        
        # Assert - Should raise IntegrityError due to foreign key constraint
        with pytest.raises(IntegrityError):
            await db_session.flush()
        
        # Roll back after the exception
        await db_session.rollback()

    @pytest.mark.asyncio
    async def test_complex_property_record(self, db_session):
        """Test creating a property with multiple complex relationships."""
        # Arrange - Create main property
        property_id = 45678901
        test_property = ApiPropertiesDetailsV2(
            id=property_id,
            transaction_type="SALE",
            bedrooms=4,
            property_type="DETACHED",
            address="Complex Property, Test City",
            summary="A complex test property",
        )
        
        # Add property and flush to generate ID
        db_session.add(test_property)
        await db_session.flush()
        
        # Create multiple related records
        misinfo = ApiPropertiesDetailsV2Misinfo(
            api_property_id=property_id,
            branch_id=7777,
            brand_plus=False,
            featured_property=True,
            channel="BUY"
        )
        
        status = ApiPropertiesDetailsV2Status(
            api_property_id=property_id,
            display_status="FOR_SALE",
            can_display_floorplans=True,
            can_display_photos=True
        )
        
        price = ApiPropertiesDetailsV2Price(
            api_property_id=property_id,
            amount=450000,
            currency_code="GBP",
            qualifier="Offers Over"
        )
        
        stamp_duty = ApiPropertiesDetailsV2StampDuty(
            api_property_id=property_id,
            effective_date="2023-01-01",
            is_second_home=False
        )
        
        features = ApiPropertiesDetailsV2Features(
            api_property_id=property_id,
            bullets=["Garden", "Garage", "Modern Kitchen", "En-suite"],
            summary="Beautiful detached house with garden and modern features"
        )
        
        branch = ApiPropertiesDetailsV2Branch(
            api_property_id=property_id,
            branch_id=7777,
            branch_name="Premium Branch",
            company_name="Luxury Properties Ltd",
            branch_postcode="TE1 1ST",
            phone_number="01234567890"
        )
        
        # Add all related records to session
        db_session.add_all([misinfo, status, price, stamp_duty, features, branch])
        await db_session.commit()
        
        # Act - Query the property with all its relationships
        result = await db_session.execute(
            select(ApiPropertiesDetailsV2).where(ApiPropertiesDetailsV2.id == property_id)
        )
        saved_property = result.scalars().first()
        
        # Assert - Check property and all relationships
        assert saved_property is not None
        assert saved_property.id == property_id
        
        # Check relationships
        assert saved_property.misinfo is not None
        assert saved_property.misinfo.branch_id == 7777
        
        assert saved_property.status is not None
        assert saved_property.status.display_status == "FOR_SALE"
        
        assert saved_property.price is not None
        assert saved_property.price.amount == 450000
        assert saved_property.price.qualifier == "Offers Over"
        
        assert saved_property.stamp_duty is not None
        assert saved_property.stamp_duty.is_second_home is False
        
        assert saved_property.features is not None
        assert len(saved_property.features.bullets) == 4
        assert "Garden" in saved_property.features.bullets
        
        assert saved_property.branch is not None
        assert saved_property.branch.branch_name == "Premium Branch"
        assert saved_property.branch.phone_number == "01234567890"


# data_capture_rightmove_service/tests/unit/test_property_details_models.py
"""
Unit tests for the property_details SQLAlchemy models.
Tests database interactions and model relationships using the test database.
"""
import uuid
import pytest
import logging
from decimal import Decimal
from datetime import date
from sqlalchemy import select
from sqlalchemy.exc import IntegrityError
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.models.property_details import (
    ApiPropertyDetails,
    ApiPropertyDetailAddress,
    ApiPropertyDetailCustomer,
    ApiPropertyDetailDfpAdInfo,
    ApiPropertyDetailImage,
    ApiPropertyDetailFloorplan,
    ApiPropertyDetailPrice,
    ApiPropertyDetailLocation,
    ApiPropertyDetailMisInfo,
    ApiPropertyDetailStatus
)

# Set up logger
logger = logging.getLogger(__name__)


class TestPropertyDetailsModels:
    """Test suite for property_details models and their relationships."""
    
    @pytest.mark.asyncio
    async def test_create_main_property_model(self, db_session):
        """Test creating a property record with basic fields."""
        # Arrange - Create property data
        property_id = 87654321
        test_property = ApiPropertyDetails(
            id=property_id,
            transaction_type="SALE",
            bedrooms=3,
            property_type="SEMI_DETACHED",
            property_sub_type="SEMI_DETACHED_HOUSE",
            commercial=False,
            bathrooms=2,
            ai_location_info="Great location near schools and parks"
        )
        
        # Act - Save to database
        db_session.add(test_property)
        await db_session.flush()
        
        # Generate a super_id value
        test_property.super_id = uuid.uuid4()
        await db_session.commit()
        
        # Assert - Verify record was saved properly
        result = await db_session.execute(
            select(ApiPropertyDetails).where(ApiPropertyDetails.id == property_id)
        )
        saved_property = result.scalars().first()
        
        # Check field values
        assert saved_property is not None
        assert saved_property.id == property_id
        assert saved_property.transaction_type == "SALE"
        assert saved_property.bedrooms == 3
        assert saved_property.property_type == "SEMI_DETACHED"
        assert saved_property.property_sub_type == "SEMI_DETACHED_HOUSE"
        assert saved_property.commercial is False
        assert saved_property.bathrooms == 2
        assert saved_property.super_id is not None

    @pytest.mark.asyncio
    async def test_create_property_with_relationships(self, db_session):
        """Test creating a property with related records."""
        # Arrange - Create property record with ID
        property_id = 76543210
        test_property = ApiPropertyDetails(
            id=property_id,
            transaction_type="SALE",
            bedrooms=4,
            key_features=["Garden", "Garage", "Renovated Kitchen"]
        )
        
        # Add property and flush to get ID
        db_session.add(test_property)
        await db_session.flush()
        
        # Create related records
        address = ApiPropertyDetailAddress(
            api_property_detail_id=property_id,
            display_address="123 Test Lane, Testington",
            country_code="GB",
            outcode="TE1",
            incode="2AB"
        )
        
        price = ApiPropertyDetailPrice(
            api_property_detail_id=property_id,
            currency_code="GBP",
            display_price="£450,000"
        )
        
        customer = ApiPropertyDetailCustomer(
            api_property_detail_id=property_id,
            branch_id=12345,
            branch_name="Premier Properties",
            company_name="Test Real Estate Ltd",
            branch_display_name="Premier Properties - Testington",
            display_address="High Street, Testington",
            is_new_home_developer=False
        )
        
        # Add related records to session
        db_session.add_all([address, price, customer])
        await db_session.commit()
        
        # Act - Query the property with related data
        result = await db_session.execute(
            select(ApiPropertyDetails).where(ApiPropertyDetails.id == property_id)
        )
        saved_property = result.scalars().first()
        
        # Assert - Check relationships loaded correctly
        assert saved_property is not None
        
        # Check each relationship
        assert saved_property.address is not None
        assert saved_property.address.display_address == "123 Test Lane, Testington"
        assert saved_property.address.country_code == "GB"
        
        assert saved_property.price is not None
        assert saved_property.price.currency_code == "GBP"
        assert saved_property.price.display_price == "£450,000"
        
        assert saved_property.customer is not None
        assert saved_property.customer.branch_id == 12345
        assert saved_property.customer.company_name == "Test Real Estate Ltd"

    @pytest.mark.asyncio
    async def test_cascade_delete(self, db_session):
        """Test cascade delete behavior between property and related tables."""
        # Arrange - Create property with related records
        property_id = 65432109
        
        # Create main property
        test_property = ApiPropertyDetails(
            id=property_id,
            transaction_type="SALE",
            bedrooms=3,
        )
        
        # Add property and flush to generate ID
        db_session.add(test_property)
        await db_session.flush()
        
        # Create related records
        mis_info = ApiPropertyDetailMisInfo(
            api_property_detail_id=property_id,
            branch_id=54321,
            brand_plus=True,
            featured_property=True
        )
        
        location = ApiPropertyDetailLocation(
            api_property_detail_id=property_id,
            latitude=Decimal("51.5074"),
            longitude=Decimal("-0.1278"),
            circle_radius_on_map=1000,
            show_map=True
        )
        
        # Add images
        image1 = ApiPropertyDetailImage(
            api_property_detail_id=property_id,
            url="https://example.com/image1.jpg",
            caption="Front of property"
        )
        
        image2 = ApiPropertyDetailImage(
            api_property_detail_id=property_id,
            url="https://example.com/image2.jpg",
            caption="Kitchen" 
        )
        
        # Add related records to session
        db_session.add_all([mis_info, location, image1, image2])
        await db_session.commit()
        
        # Act - Delete the main property record
        property_to_delete = (await db_session.execute(
            select(ApiPropertyDetails).where(ApiPropertyDetails.id == property_id)
        )).scalars().first()
        
        # Verify images were created correctly first
        image_count = await db_session.execute(
            select(ApiPropertyDetailImage).where(ApiPropertyDetailImage.api_property_detail_id == property_id)
        )
        assert len(image_count.scalars().all()) == 2
        
        # Now delete the property
        await db_session.delete(property_to_delete)
        await db_session.commit()
        
        # Assert - Verify cascade delete worked
        # Check main property is gone
        property_check = (await db_session.execute(
            select(ApiPropertyDetails).where(ApiPropertyDetails.id == property_id)
        )).scalars().first()
        assert property_check is None
        
        # Check related records are gone
        misinfo_check = (await db_session.execute(
            select(ApiPropertyDetailMisInfo).where(ApiPropertyDetailMisInfo.api_property_detail_id == property_id)
        )).scalars().first()
        assert misinfo_check is None
        
        location_check = (await db_session.execute(
            select(ApiPropertyDetailLocation).where(ApiPropertyDetailLocation.api_property_detail_id == property_id)
        )).scalars().first()
        assert location_check is None
        
        # Check that one-to-many relationships are also deleted
        images_check = (await db_session.execute(
            select(ApiPropertyDetailImage).where(ApiPropertyDetailImage.api_property_detail_id == property_id)
        )).scalars().all()
        assert len(images_check) == 0

    @pytest.mark.asyncio
    async def test_foreign_key_constraint(self, db_session):
        """Test foreign key constraint enforces relationship integrity."""
        # Try to create related record without a main property
        non_existent_property_id = 11111111
        
        # Create related record referencing non-existent property
        invalid_address = ApiPropertyDetailAddress(
            api_property_detail_id=non_existent_property_id,
            display_address="Invalid Address",
            country_code="GB"
        )
        
        db_session.add(invalid_address)
        
        # Assert - Should raise IntegrityError due to foreign key constraint
        with pytest.raises(IntegrityError):
            await db_session.flush()
        
        # Roll back after the exception
        await db_session.rollback()

    @pytest.mark.asyncio
    async def test_one_to_many_relationships(self, db_session):
        """Test one-to-many relationships like images and floorplans."""
        # Arrange - Create property
        property_id = 54321098
        test_property = ApiPropertyDetails(
            id=property_id,
            transaction_type="SALE",
            bedrooms=5,
            property_type="DETACHED"
        )
        
        # Add property and flush to get ID
        db_session.add(test_property)
        await db_session.flush()
        
        # Add multiple images
        images = [
            ApiPropertyDetailImage(
                api_property_detail_id=property_id,
                url=f"https://example.com/image{i}.jpg",
                caption=f"Image {i}",
                order_index=i
            )
            for i in range(1, 6)  # Create 5 images
        ]
        
        # Add multiple floorplans
        floorplans = [
            ApiPropertyDetailFloorplan(
                api_property_detail_id=property_id,
                url=f"https://example.com/floorplan{i}.jpg",
                caption=f"Floorplan {i}",
                order_index=i
            )
            for i in range(1, 3)  # Create 2 floorplans
        ]
        
        # Add all records
        db_session.add_all(images + floorplans)
        await db_session.commit()
        
        # Act - Query the property with its collections
        result = await db_session.execute(
            select(ApiPropertyDetails).where(ApiPropertyDetails.id == property_id)
        )
        saved_property = result.scalars().first()
        
        # Assert - Check collections are loaded correctly
        assert saved_property is not None
        
        # Check images collection
        assert len(saved_property.images) == 5
        # Verify images are ordered by order_index
        image_order = [img.order_index for img in saved_property.images]
        assert image_order == sorted(image_order)  # Should be in ascending order
        
        # Check floorplans collection
        assert len(saved_property.floorplans) == 2
        
        # Check specific image properties
        test_image = saved_property.images[0]  # Get first image
        assert test_image.url.startswith("https://example.com/image")
        assert test_image.caption.startswith("Image")

    @pytest.mark.asyncio
    async def test_complex_property_record(self, db_session):
        """Test creating a property with multiple complex relationships."""
        # Arrange - Create main property
        property_id = 43210987
        test_property = ApiPropertyDetails(
            id=property_id,
            transaction_type="SALE",
            bedrooms=6,
            bathrooms=4,
            property_type="DETACHED",
            property_sub_type="DETACHED_HOUSE",
            commercial=False,
            business_for_sale=False,
            key_features=["Swimming Pool", "Cinema Room", "Private Garden", 
                          "Double Garage", "Underfloor Heating"],
            brochures={"url": "https://example.com/brochure.pdf"},
            commercial_use_classes=None
        )
        
        # Add property and flush to generate ID
        db_session.add(test_property)
        await db_session.flush()
        
        # Create multiple related records
        address = ApiPropertyDetailAddress(
            api_property_detail_id=property_id,
            display_address="Luxury Villa, Test Boulevard",
            country_code="GB",
            outcode="TE1",
            incode="3ST",
            uk_country="England"
        )
        
        price = ApiPropertyDetailPrice(
            api_property_detail_id=property_id,
            currency_code="GBP",
            display_price="£1,250,000"
        )
        
        customer = ApiPropertyDetailCustomer(
            api_property_detail_id=property_id,
            branch_id=99999,
            branch_name="Luxury Real Estate",
            company_name="Premium Properties International",
            display_address="Victory House, Central Plaza, London",
            logo_path="https://example.com/logo.png"
        )
        
        location = ApiPropertyDetailLocation(
            api_property_detail_id=property_id,
            latitude=Decimal("52.4068"),
            longitude=Decimal("-1.5197"),
            circle_radius_on_map=1500,
            show_map=True,
            zoom_level=14
        )
        
        mis_info = ApiPropertyDetailMisInfo(
            api_property_detail_id=property_id,
            branch_id=99999,
            brand_plus=True,
            featured_property=True,
            premium_display=True
        )
        
        status = ApiPropertyDetailStatus(
            api_property_detail_id=property_id,
            published=True,
            saved=False
        )
        
        # Add all related records to session
        db_session.add_all([
            address, price, customer, location, 
            mis_info, status
        ])
        
        # Add images
        for i in range(1, 8):  # Add 7 images
            image = ApiPropertyDetailImage(
                api_property_detail_id=property_id,
                url=f"https://example.com/luxury_image{i}.jpg",
                caption=f"Luxury Property Image {i}",
                order_index=i
            )
            db_session.add(image)
            
        # Add floorplans
        for i in range(1, 4):  # Add 3 floorplans
            floorplan = ApiPropertyDetailFloorplan(
                api_property_detail_id=property_id,
                url=f"https://example.com/luxury_floorplan{i}.jpg",
                caption=f"Floor {i}",
                type="FLOORPLAN",
                order_index=i
            )
            db_session.add(floorplan)
            
        # Add mapping info
        dfp_ad_info = ApiPropertyDetailDfpAdInfo(
            api_property_detail_id=property_id,
            channel="SALE",
            targeting={"premium": True, "featured": True}
        )
        db_session.add(dfp_ad_info)
        
        await db_session.commit()
        
        # Act - Query the property with all its relationships
        result = await db_session.execute(
            select(ApiPropertyDetails).where(ApiPropertyDetails.id == property_id)
        )
        saved_property = result.scalars().first()
        
        # Assert - Check property and all relationships
        assert saved_property is not None
        assert saved_property.id == property_id
        
        # Check base properties
        assert saved_property.bedrooms == 6
        assert len(saved_property.key_features) == 5
        assert "Swimming Pool" in saved_property.key_features
        
        # Check relationships
        assert saved_property.address is not None
        assert saved_property.address.display_address == "Luxury Villa, Test Boulevard"
        
        assert saved_property.price is not None
        assert saved_property.price.display_price == "£1,250,000"
        
        assert saved_property.customer is not None
        assert saved_property.customer.branch_name == "Luxury Real Estate"
        
        assert saved_property.location is not None
        assert float(saved_property.location.latitude) == pytest.approx(52.4068)
        
        assert saved_property.dfp_ad_info is not None
        assert saved_property.dfp_ad_info.targeting["premium"] is True
        
        # Check collections
        assert len(saved_property.images) == 7
        assert len(saved_property.floorplans) == 3


# data_capture_rightmove_service/tests/unit/__init__.py
"""
Unit test package for data_capture_rightmove_service.
"""


# data_capture_rightmove_service/tests/integration/__init__.py
"""
Integration test package for data_capture_rightmove_service.
"""


# data_capture_rightmove_service/tests/integration/test_model_integration.py
"""
Integration tests for models in the data_capture_rightmove_service.
Tests the interaction between models and service layers.
"""
import uuid
import pytest
import logging
from decimal import Decimal
from datetime import datetime, timezone

from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.models.properties_details_v2 import (
    ApiPropertiesDetailsV2,
    ApiPropertiesDetailsV2Misinfo,
    ApiPropertiesDetailsV2Price,
    ApiPropertiesDetailsV2Status,
    ApiPropertiesDetailsV2Features
)
from data_capture_rightmove_service.models.property_details import (
    ApiPropertyDetails,
    ApiPropertyDetailAddress,
    ApiPropertyDetailPrice
)

# Set up logger
logger = logging.getLogger(__name__)


class TestModelIntegration:
    """Test integration between models and service-level operations."""
    
    @pytest.mark.asyncio
    async def test_property_search_integration(self, db_session, seed_properties_details_v2):
        """Test searching for properties with complex criteria."""
        # Seed multiple properties with different characteristics
        await seed_properties_details_v2(
            db_session=db_session,
            property_id=1001,
            with_relations=True,
            price=250000,
            bedrooms=2,
            property_type="FLAT"
        )
        
        await seed_properties_details_v2(
            db_session=db_session,
            property_id=1002,
            with_relations=True,
            price=350000,
            bedrooms=3,
            property_type="SEMI_DETACHED"
        )
        
        await seed_properties_details_v2(
            db_session=db_session,
            property_id=1003,
            with_relations=True,
            price=450000,
            bedrooms=4,
            property_type="DETACHED"
        )
        
        await seed_properties_details_v2(
            db_session=db_session,
            property_id=1004,
            with_relations=True,
            price=300000,
            bedrooms=2,
            property_type="TERRACED"
        )
        
        # Simulate service-layer search operation
        # This mimics what a real service would do when searching for properties
        
        # Example: Find properties with 2 bedrooms under 300k
        query = (
            select(ApiPropertiesDetailsV2)
            .join(ApiPropertiesDetailsV2Price, 
                  ApiPropertiesDetailsV2.id == ApiPropertiesDetailsV2Price.api_property_id)
            .where(ApiPropertiesDetailsV2.bedrooms == 2)
            .where(ApiPropertiesDetailsV2Price.amount <= 300000)
        )
        
        result = await db_session.execute(query)
        matching_properties = result.scalars().all()
        
        # Should match properties 1001 and 1004
        assert len(matching_properties) == 2
        property_ids = [p.id for p in matching_properties]
        assert 1001 in property_ids
        assert 1004 in property_ids
        
        # Example: Find properties that are houses (not flats) over 300k
        query = (
            select(ApiPropertiesDetailsV2)
            .join(ApiPropertiesDetailsV2Price, 
                  ApiPropertiesDetailsV2.id == ApiPropertiesDetailsV2Price.api_property_id)
            .where(ApiPropertiesDetailsV2.property_type != "FLAT")
            .where(ApiPropertiesDetailsV2Price.amount > 300000)
        )
        
        result = await db_session.execute(query)
        matching_properties = result.scalars().all()
        
        # Should match properties 1002 and 1003
        assert len(matching_properties) == 2
        property_ids = [p.id for p in matching_properties]
        assert 1002 in property_ids
        assert 1003 in property_ids
    
    @pytest.mark.asyncio
    async def test_updating_property_with_relations(self, db_session, seed_properties_details_v2):
        """Test updating a property and its related records."""
        # Seed an initial property
        property_id = await seed_properties_details_v2(
            db_session=db_session,
            with_relations=True,
            price=275000,
            bedrooms=3,
            property_type="SEMI_DETACHED"
        )
        
        # Simulate service-layer update operation
        # First, retrieve the property with relations
        query = (
            select(ApiPropertiesDetailsV2)
            .where(ApiPropertiesDetailsV2.id == property_id)
        )
        result = await db_session.execute(query)
        property_to_update = result.scalars().first()
        
        # Now update various aspects of the property
        property_to_update.bedrooms = 4  # Bedroom addition
        property_to_update.summary = "Updated property summary with renovation"
        property_to_update.property_sub_type = "SEMI_DETACHED_HOUSE"
        
        # Update related price
        price_query = (
            select(ApiPropertiesDetailsV2Price)
            .where(ApiPropertiesDetailsV2Price.api_property_id == property_id)
        )
        price_result = await db_session.execute(price_query)
        price_record = price_result.scalars().first()
        
        # Increase price due to renovations
        original_price = price_record.amount
        price_record.amount = original_price + 50000
        price_record.qualifier = "Guide Price"
        
        # Add features if they don't exist
        features_query = (
            select(ApiPropertiesDetailsV2Features)
            .where(ApiPropertiesDetailsV2Features.api_property_id == property_id)
        )
        features_result = await db_session.execute(features_query)
        features = features_result.scalars().first()
        
        if features:
            # Update existing features
            features.bullets = ["Newly Renovated", "Extended Kitchen", "Garden", "Off-Street Parking"]
            features.summary = "Beautiful semi-detached house with recent renovations and extension"
        else:
            # Create new features record
            new_features = ApiPropertiesDetailsV2Features(
                api_property_id=property_id,
                bullets=["Newly Renovated", "Extended Kitchen", "Garden", "Off-Street Parking"],
                summary="Beautiful semi-detached house with recent renovations and extension"
            )
            db_session.add(new_features)
        
        # Update status to reflect changes
        status_query = (
            select(ApiPropertiesDetailsV2Status)
            .where(ApiPropertiesDetailsV2Status.api_property_id == property_id)
        )
        status_result = await db_session.execute(status_query)
        status = status_result.scalars().first()
        
        if status:
            # Ensure status is updated and published
            status.published = True
            status.display_status = "FOR_SALE"
        
        # Commit all changes
        await db_session.commit()
        
        # Verify changes persisted correctly
        # Reload property from database
        query = (
            select(ApiPropertiesDetailsV2)
            .where(ApiPropertiesDetailsV2.id == property_id)
        )
        result = await db_session.execute(query)
        updated_property = result.scalars().first()
        
        # Check base property updates
        assert updated_property.bedrooms == 4  # Was 3
        assert updated_property.summary == "Updated property summary with renovation"
        assert updated_property.property_sub_type == "SEMI_DETACHED_HOUSE"
        
        # Check price updates
        assert updated_property.price.amount == original_price + 50000
        assert updated_property.price.qualifier == "Guide Price"
        
        # Check features
        assert updated_property.features is not None
        assert len(updated_property.features.bullets) == 4
        assert "Newly Renovated" in updated_property.features.bullets
        
        # Check status
        assert updated_property.status.published is True
        assert updated_property.status.display_status == "FOR_SALE"
    
    @pytest.mark.asyncio
    async def test_aggregate_queries(self, db_session, seed_properties_details_v2):
        """Test performing aggregate queries on the property models."""
        # Seed multiple properties with different prices
        property_ids = []
        for i in range(10):
            # Create properties with varying prices based on bedrooms
            bedrooms = (i % 4) + 1
            price = 200000 + (bedrooms * 50000) + (i * 10000)
            
            # Alternate property types
            property_type = ["FLAT", "TERRACED", "SEMI_DETACHED", "DETACHED"][i % 4]
            
            property_id = await seed_properties_details_v2(
                db_session=db_session,
                with_relations=True,
                price=price,
                bedrooms=bedrooms,
                property_type=property_type
            )
            property_ids.append(property_id)
        
        # Compute average price by bedrooms - simulating an analytics query
        query = (
            select(
                ApiPropertiesDetailsV2.bedrooms,
                func.avg(ApiPropertiesDetailsV2Price.amount).label("avg_price"),
                func.count().label("count")
            )
            .join(ApiPropertiesDetailsV2Price, 
                  ApiPropertiesDetailsV2.id == ApiPropertiesDetailsV2Price.api_property_id)
            .group_by(ApiPropertiesDetailsV2.bedrooms)
            .order_by(ApiPropertiesDetailsV2.bedrooms)
        )
        
        result = await db_session.execute(query)
        stats_by_bedroom = result.all()
        
        # Assert aggregation results
        assert len(stats_by_bedroom) == 4  # Should have data for 1-4 bedrooms
        
        # Verify that bedroom counts are 1, 2, 3, 4
        bedrooms = [r[0] for r in stats_by_bedroom]
        assert sorted(bedrooms) == [1, 2, 3, 4]
        
        # Verify that average prices increase with bedroom count
        avg_prices = [r[1] for r in stats_by_bedroom]
        for i in range(1, len(avg_prices)):
            assert avg_prices[i] > avg_prices[i-1]  # Prices should increase with bedrooms
        
        # Compute distribution by property type
        type_query = (
            select(
                ApiPropertiesDetailsV2.property_type,
                func.count().label("count")
            )
            .group_by(ApiPropertiesDetailsV2.property_type)
            .order_by(func.count().desc())
        )
        
        result = await db_session.execute(type_query)
        distribution_by_type = result.all()
        
        # Should have entries for all property types
        property_types = [r[0] for r in distribution_by_type]
        assert set(property_types) == set(["FLAT", "TERRACED", "SEMI_DETACHED", "DETACHED"])
        
        # Each type should have a similar count (2-3 each)
        counts = [r[1] for r in distribution_by_type]
        assert all(count >= 2 for count in counts)
        assert sum(counts) == 10  # Total 10 properties


# data_capture_rightmove_service/tests/utils/test_url_parsing.py
"""
Tests for the url_parsing utility module.
"""
import pytest

from data_capture_rightmove_service.utils.url_parsing import (
    extract_rightmove_property_id,
    is_valid_rightmove_url,
    determine_rightmove_api_endpoints,
)


class TestRightmoveUrlParsing:
    """Test suite for Rightmove URL parsing functions."""

    @pytest.mark.parametrize(
        "url,expected_id",
        [
            # Valid URLs with IDs
            ("https://www.rightmove.co.uk/properties/154508327", 154508327),
            ("https://www.rightmove.co.uk/properties/154508327#/?channel=RES_LET", 154508327),
            ("https://www.rightmove.co.uk/properties/123456789?param=value", 123456789),
            ("http://rightmove.co.uk/properties/123", 123),
            # Invalid URLs or no ID
            (None, None),
            ("", None),
            ("https://www.example.com", None),
            ("https://www.rightmove.co.uk/for-sale/property-12345.html", None),
            ("https://www.rightmove.co.uk/properties/", None),
            ("https://www.rightmove.co.uk/properties/invalid", None),
        ],
    )
    def test_extract_rightmove_property_id(self, url, expected_id):
        """Test extracting property IDs from various URLs."""
        assert extract_rightmove_property_id(url) == expected_id

    @pytest.mark.parametrize(
        "url,expected_result",
        [
            # Valid URLs
            ("https://www.rightmove.co.uk/properties/154508327", True),
            ("https://www.rightmove.co.uk/properties/154508327#/?channel=RES_LET", True),
            ("http://rightmove.co.uk/properties/123", True),
            # Invalid URLs
            (None, False),
            ("", False),
            ("https://www.example.com", False),
            ("https://www.rightmove.co.uk/for-sale/property-12345.html", False),
            ("https://www.rightmove.co.uk/properties/", False),
            ("https://www.rightmove.co.uk/properties/invalid", False),
        ],
    )
    def test_is_valid_rightmove_url(self, url, expected_result):
        """Test validating Rightmove property URLs."""
        assert is_valid_rightmove_url(url) == expected_result

    @pytest.mark.parametrize(
        "url,expected_primary,expected_secondary",
        [
            # For-sale URLs should prioritize property-for-sale endpoint
            (
                "https://www.rightmove.co.uk/property-for-sale/property-123456789.html",
                "property_for_sale",
                "properties_details",
            ),
            (
                "https://www.rightmove.co.uk/properties/123456789#/?channel=for-sale",
                "property_for_sale", 
                "properties_details"
            ),
            # Regular property URLs should prioritize properties_details endpoint
            (
                "https://www.rightmove.co.uk/properties/123456789",
                "properties_details",
                "property_for_sale",
            ),
            (None, "properties_details", "property_for_sale"),
        ],
    )
    def test_determine_rightmove_api_endpoints(self, url, expected_primary, expected_secondary):
        """Test determining which API endpoints to use based on URL structure."""
        primary, secondary = determine_rightmove_api_endpoints(url)
        assert primary == expected_primary
        assert secondary == expected_secondary


# data_capture_rightmove_service/tests/fixtures/db.py
"""
Database fixtures for testing.
"""
import asyncio
import os
from typing import AsyncGenerator, Generator

import pytest
from sqlalchemy import text
from sqlalchemy.ext.asyncio import (
    AsyncSession, 
    create_async_engine, 
    async_sessionmaker
)

# Import from service config to respect environment variable format
from data_capture_rightmove_service import config

# Following our standardized variable naming convention with service-specific prefixes
# Use test database to avoid interfering with development database
SQLALCHEMY_TEST_DATABASE_URL = (
    f"postgresql+asyncpg://{config.RIGHTMOVE_SERVICE_DB_USER}:{config.RIGHTMOVE_SERVICE_DB_PASSWORD}"
    f"@{config.RIGHTMOVE_SERVICE_DB_HOST}:{config.RIGHTMOVE_SERVICE_DB_PORT}"
    f"/{config.RIGHTMOVE_SERVICE_DB_NAME}_test"
)

# Create async engine and session for testing
test_engine = create_async_engine(
    SQLALCHEMY_TEST_DATABASE_URL,
    echo=False,
    connect_args={"server_settings": {"search_path": "rightmove,public"}}
)

TestAsyncSessionLocal = async_sessionmaker(
    test_engine,
    expire_on_commit=False,
    class_=AsyncSession
)


@pytest.fixture
async def event_loop() -> Generator:
    """Create an instance of the default event loop for each test case."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest.fixture
async def setup_test_database() -> AsyncGenerator:
    """
    Setup a test database by creating tables and setting up the schema.
    This follows the pattern used in auth_service for test database setup.
    """
    # Create tables and set up schema
    async with test_engine.begin() as conn:
        # Create the rightmove schema if it doesn't exist
        await conn.execute(text("CREATE SCHEMA IF NOT EXISTS rightmove;"))
        
        # Import and create tables based on models
        from data_capture_rightmove_service.models.base import Base
        from data_capture_rightmove_service.models.properties_details_v2 import ApiPropertiesDetailsV2
        from data_capture_rightmove_service.models.property_details import ApiPropertyDetails
        
        # Create all tables in the metadata
        await conn.run_sync(Base.metadata.create_all)
    
    yield
    
    # Teardown - Drop all tables
    async with test_engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)


@pytest.fixture
async def db_session(setup_test_database) -> AsyncGenerator[AsyncSession, None]:
    """
    Create a fresh session for each test, then roll back all the changes.
    Follows the same pattern as auth_service for transaction isolation.
    """
    async with TestAsyncSessionLocal() as session:
        yield session
        await session.rollback()


# data_capture_rightmove_service/tests/fixtures/__init__.py
"""
Test fixtures package for data_capture_rightmove_service.
"""


# data_capture_rightmove_service/tests/fixtures/helpers.py
"""
Helper functions and fixtures for testing the data_capture_rightmove_service.
"""
import uuid
import random
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple

import pytest
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.models.properties_details_v2 import (
    ApiPropertiesDetailsV2,
    ApiPropertiesDetailsV2Misinfo,
    ApiPropertiesDetailsV2Price,
    ApiPropertiesDetailsV2Status
)
from data_capture_rightmove_service.models.property_details import (
    ApiPropertyDetails,
    ApiPropertyDetailAddress,
    ApiPropertyDetailPrice,
    ApiPropertyDetailCustomer
)


@pytest.fixture
async def seed_properties_details_v2():
    """
    Helper fixture to seed a Rightmove properties details v2 record with optional related entities.
    """
    async def _seed_property(
        db_session: AsyncSession, 
        property_id: int = None, 
        with_relations: bool = True,
        price: int = None,
        bedrooms: int = None,
        property_type: str = None
    ) -> int:
        """
        Seed a test properties_details_v2 record.
        
        Args:
            db_session: The database session
            property_id: Optional property ID to use (BigInt)
            with_relations: Whether to create related records too
            price: Optional specific price to set
            bedrooms: Optional specific bedroom count
            property_type: Optional specific property type
            
        Returns:
            The ID of the created property
        """
        if property_id is None:
            property_id = random.randint(10000000, 99999999)
        
        if bedrooms is None:
            bedrooms = random.randint(1, 5)
            
        if property_type is None:
            property_type = random.choice([
                "FLAT", "TERRACED", "SEMI_DETACHED", "DETACHED", "BUNGALOW", "LAND"
            ])
            
        if price is None:
            price = random.randint(100000, 1000000)
        
        # Create main property record
        property_record = ApiPropertiesDetailsV2(
            id=property_id,
            transaction_type="SALE",
            bedrooms=bedrooms,
            property_type=property_type,
            summary=f"Test property with {bedrooms} bedrooms",
            address=f"{property_id} Test Street, Testville",
            super_id=uuid.uuid4()
        )
        db_session.add(property_record)
        await db_session.flush()
        
        if with_relations:
            # Add misinfo relation
            misinfo = ApiPropertiesDetailsV2Misinfo(
                api_property_id=property_id,
                branch_id=random.randint(1000, 9999),
                brand_plus=random.choice([True, False]),
                featured_property=random.choice([True, False]), 
                channel="BUY",
                super_id=uuid.uuid4()
            )
            db_session.add(misinfo)
            
            # Add price relation
            price_record = ApiPropertiesDetailsV2Price(
                api_property_id=property_id,
                amount=price,
                currency_code="GBP",
                frequency=None,
                qualifier=random.choice([
                    "Guide Price", "Offers Over", "Fixed Price", "From"
                ]),
                super_id=uuid.uuid4()
            )
            db_session.add(price_record)
            
            # Add status relation
            status = ApiPropertiesDetailsV2Status(
                api_property_id=property_id,
                display_status="FOR_SALE",
                published=True,
                can_display_photos=True,
                can_display_floorplans=True,
                super_id=uuid.uuid4()
            )
            db_session.add(status)
            
        await db_session.commit()
        return property_id
    
    return _seed_property


@pytest.fixture
async def seed_property_details():
    """
    Helper fixture to seed a Rightmove property details record with optional related entities.
    """
    async def _seed_property(
        db_session: AsyncSession, 
        property_id: int = None, 
        with_relations: bool = True,
        location: Dict[str, float] = None,
        features: List[str] = None
    ) -> int:
        """
        Seed a test property_details record.
        
        Args:
            db_session: The database session
            property_id: Optional property ID to use (BigInt)
            with_relations: Whether to create related records too
            location: Optional dict with latitude/longitude
            features: Optional list of property features
            
        Returns:
            The ID of the created property
        """
        if property_id is None:
            property_id = random.randint(10000000, 99999999)
            
        if features is None:
            features = ["Garden", "Parking", "Central Heating"]
            
        if location is None:
            # Default to central London area
            location = {
                "latitude": 51.5074 + (random.random() - 0.5) / 10,  # Add small random variation
                "longitude": -0.1278 + (random.random() - 0.5) / 10
            }
        
        # Create main property record
        property_record = ApiPropertyDetails(
            id=property_id,
            transaction_type="SALE",
            bedrooms=random.randint(1, 5),
            key_features=features,
            business_for_sale=False,
            commercial=False,
            super_id=uuid.uuid4()
        )
        db_session.add(property_record)
        await db_session.flush()
        
        if with_relations:
            # Add address
            address = ApiPropertyDetailAddress(
                api_property_detail_id=property_id,
                display_address=f"{random.randint(1, 999)} Test Road, Testington",
                country_code="GB",
                outcode=f"TE{random.randint(1, 20)}",
                incode=f"{random.randint(1, 9)}AB",
                super_id=uuid.uuid4()
            )
            db_session.add(address)
            
            # Add price record
            price = ApiPropertyDetailPrice(
                api_property_detail_id=property_id,
                currency_code="GBP",
                display_price=f"£{random.randint(100, 999)},000",
                super_id=uuid.uuid4()
            )
            db_session.add(price)
            
            # Add customer
            customer = ApiPropertyDetailCustomer(
                api_property_detail_id=property_id,
                branch_id=random.randint(1000, 9999),
                branch_name=f"Test Branch {random.randint(1, 50)}",
                company_name="Test Property Company Ltd",
                super_id=uuid.uuid4()
            )
            db_session.add(customer)
            
        await db_session.commit()
        return property_id
    
    return _seed_property


@pytest.fixture
def generate_property_data():
    """
    Helper to generate realistic property data for testing without database persistence.
    """
    def _generate_data(
        transaction_type: str = "SALE",
        property_type: str = None,
        bedrooms: int = None
    ) -> Dict[str, Any]:
        """
        Generate sample property data.
        
        Args:
            transaction_type: Type of transaction (SALE or RENT)
            property_type: Type of property
            bedrooms: Number of bedrooms
            
        Returns:
            Dict with property data
        """
        if property_type is None:
            property_type = random.choice([
                "FLAT", "TERRACED", "SEMI_DETACHED", "DETACHED", "BUNGALOW"
            ])
            
        if bedrooms is None:
            bedrooms = random.randint(1, 5)
            
        # Base property data
        town = random.choice(["London", "Manchester", "Birmingham", "Leeds", "Liverpool"])
        postcode = f"{random.choice(['SW', 'NW', 'SE', 'NE', 'W', 'E'])}{random.randint(1, 20)} {random.randint(1, 9)}AB"
        
        # Price based on property type and bedrooms
        base_price = {
            "FLAT": 200000,
            "TERRACED": 250000,
            "SEMI_DETACHED": 350000,
            "DETACHED": 450000,
            "BUNGALOW": 300000,
        }.get(property_type, 300000)
        
        # Add price per bedroom
        price = base_price + (bedrooms * 50000)
        
        # Add location randomization
        price = price + random.randint(-50000, 50000)
        
        # Generate property data
        property_data = {
            "id": random.randint(10000000, 99999999),
            "transaction_type": transaction_type,
            "property_type": property_type,
            "property_sub_type": f"{property_type}_HOUSE" if property_type != "FLAT" else "FLAT_APARTMENT",
            "bedrooms": bedrooms,
            "bathrooms": min(bedrooms, random.randint(1, 3)),
            "address": f"{random.randint(1, 999)} Test Street, {town}",
            "display_address": f"Test Street, {town}",
            "summary": f"A {'stunning' if random.random() > 0.5 else 'beautiful'} {bedrooms} bedroom {property_type.lower()}",
            "description": f"This {property_type.lower()} offers spacious accommodation with {bedrooms} bedrooms, located in a popular area of {town}.",
            "price": {
                "amount": price,
                "currency_code": "GBP",
                "display_price": f"£{price:,}",
                "qualifier": random.choice(["Guide Price", "Offers Over", "Fixed Price"])
            },
            "location": {
                "latitude": 51.5074 + (random.random() - 0.5),
                "longitude": -0.1278 + (random.random() - 0.5),
            },
            "postcode": postcode,
            "added_date": (datetime.now() - timedelta(days=random.randint(1, 30))).isoformat(),
            "features": [
                "Gas Central Heating",
                "Double Glazing",
                f"{bedrooms} Bedrooms",
                "Garden" if random.random() > 0.3 else "Balcony",
                "Parking" if random.random() > 0.5 else "Garage"
            ]
        }
        
        return property_data
        
    return _generate_data


# data_capture_rightmove_service/tests/fixtures/mocks.py
"""
Mock objects and fixtures for testing.
"""
import json
import random
from typing import Dict, Any, List
import pytest
from unittest.mock import MagicMock, AsyncMock


class MockResponse:
    """Mock HTTP response for testing API requests."""
    
    def __init__(self, status_code=200, json_data=None, text=None, headers=None):
        self.status_code = status_code
        self._json_data = json_data
        self.text = text or json.dumps(json_data) if json_data else ""
        self.headers = headers or {}
        self.content = self.text.encode() if self.text else b""
    
    async def json(self):
        return self._json_data
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass


class MockHTTPClient:
    """Mock HTTP client for testing external API calls."""
    
    def __init__(self, responses=None):
        """
        Initialize with predefined responses or empty.
        
        Args:
            responses: Dict mapping URLs to responses
        """
        self.responses = responses or {}
        self.requests = []  # Store request history
    
    async def get(self, url, **kwargs):
        """Mock GET request."""
        self.requests.append({"method": "GET", "url": url, "kwargs": kwargs})
        
        if url in self.responses:
            return self.responses[url]
        
        # Default response if URL not specified
        return MockResponse(status_code=404, json_data={"error": "Not Found"})
    
    async def post(self, url, **kwargs):
        """Mock POST request."""
        self.requests.append({"method": "POST", "url": url, "kwargs": kwargs})
        
        if url in self.responses:
            return self.responses[url]
        
        # Default response if URL not specified
        return MockResponse(status_code=404, json_data={"error": "Not Found"})


class MockRightmoveAPI:
    """
    Mock Rightmove API client for testing without external dependencies.
    """
    def __init__(self, responses=None):
        self.responses = responses or {}
        self.calls = []
        
    async def fetch_property_details(self, property_id):
        """Mock property details fetch."""
        self.calls.append({
            "method": "fetch_property_details",
            "property_id": property_id
        })
        
        # Check if we have a predefined response for this property_id
        key = f"property_details:{property_id}"
        if key in self.responses:
            return self.responses[key]
            
        # Generate a random response
        property_type = random.choice([
            "FLAT", "TERRACED", "SEMI_DETACHED", "DETACHED", "BUNGALOW"
        ])
        bedrooms = random.randint(1, 5)
        
        # Generate mock response with essential fields
        mock_response = {
            "id": property_id,
            "transactionType": "SALE",
            "propertyType": property_type,
            "bedrooms": bedrooms,
            "address": f"{property_id} Test Street, Testville",
            "price": {
                "amount": random.randint(100000, 1000000),
                "currencyCode": "GBP",
                "displayPrice": "£450,000"
            },
            "location": {
                "latitude": 51.5074 + (random.random() - 0.5),
                "longitude": -0.1278 + (random.random() - 0.5)
            }
        }
        return mock_response
        
    async def fetch_properties_list(self, location=None, min_price=None, max_price=None, 
                                    min_bedrooms=None, max_bedrooms=None, page=1):
        """Mock properties list fetch."""
        self.calls.append({
            "method": "fetch_properties_list",
            "location": location,
            "min_price": min_price,
            "max_price": max_price,
            "min_bedrooms": min_bedrooms,
            "max_bedrooms": max_bedrooms,
            "page": page
        })
        
        # Check if we have a predefined response for this query
        query_key = f"properties_list:{location}:{min_price}-{max_price}:{min_bedrooms}-{max_bedrooms}:{page}"
        if query_key in self.responses:
            return self.responses[query_key]
            
        # Generate random number of properties (5-20)
        num_properties = random.randint(5, 20)
        properties = []
        
        for _ in range(num_properties):
            property_id = random.randint(10000000, 99999999)
            property_type = random.choice([
                "FLAT", "TERRACED", "SEMI_DETACHED", "DETACHED", "BUNGALOW"
            ])
            bedrooms = min_bedrooms if min_bedrooms else random.randint(1, 5)
            if max_bedrooms:
                bedrooms = min(bedrooms, max_bedrooms)
                
            price = random.randint(min_price or 100000, max_price or 1000000)
            
            properties.append({
                "id": property_id,
                "transactionType": "SALE",
                "propertyType": property_type,
                "bedrooms": bedrooms,
                "displayAddress": f"Property {property_id}, {location or 'Test Location'}",
                "price": {
                    "amount": price,
                    "currencyCode": "GBP"
                }
            })
            
        mock_response = {
            "properties": properties,
            "resultCount": num_properties,
            "pageNumber": page,
            "totalPages": 5
        }
        return mock_response


@pytest.fixture
def mock_http_client():
    """Fixture that provides a mock HTTP client."""
    return MockHTTPClient()


@pytest.fixture
def mock_rightmove_api():
    """Fixture that provides a mock Rightmove API client."""
    return MockRightmoveAPI()


class MockCrud:
    """Mock CRUD operations for testing service layers without DB dependencies."""
    
    def __init__(self):
        self.calls = []
        self.returns = {}
        
    def set_return(self, method_name, value):
        """Set the return value for a specific method."""
        self.returns[method_name] = value
        
    def get_property_by_id(self, property_id):
        """Mock getting a property by ID."""
        self.calls.append({
            "method": "get_property_by_id",
            "property_id": property_id
        })
        return self.returns.get("get_property_by_id")
    
    async def create_property(self, property_data):
        """Mock creating a property."""
        self.calls.append({
            "method": "create_property",
            "property_data": property_data
        })
        return self.returns.get("create_property", property_data)
    
    async def update_property(self, property_id, property_data):
        """Mock updating a property."""
        self.calls.append({
            "method": "update_property",
            "property_id": property_id,
            "property_data": property_data
        })
        return self.returns.get("update_property", property_data)


@pytest.fixture
def mock_crud():
    """Fixture that provides a mock CRUD service."""
    return MockCrud()


# data_capture_rightmove_service/scripts/verify_property_data.py
#!/usr/bin/env python3
"""
Database verification script for Rightmove property data.
This script queries the database for a specific property ID and displays all related data.

Usage:
    python scripts/verify_property_data.py [property_id]
    
If property_id is not provided, the script will list the latest 10 properties.
"""

import argparse
import asyncio
import os
import sys
from typing import Dict, List, Optional, Union

from sqlalchemy import func, select, text
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from tabulate import tabulate

# Add project root to path for imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.models.properties_details import (
    ApiPropertiesDetailsV2,
    ApiPropertiesDetailsV2Branch,
    ApiPropertiesDetailsV2Floorplan,
    ApiPropertiesDetailsV2Location,
    ApiPropertiesDetailsV2Photo,
    ApiPropertiesDetailsV2Price,
)
from data_capture_rightmove_service.models.property_details import (
    ApiPropertyDetails,
    ApiPropertyDetailCustomer,
    ApiPropertyDetailFloorplan,
    ApiPropertyDetailImage,
    ApiPropertyDetailPrice,
)


class DataVerifier:
    """Database verification tool for Rightmove property data."""
    
    def __init__(self):
        """Initialize the database connection."""
        self.engine = create_async_engine(settings.DATABASE_URL)
        self.async_session = sessionmaker(
            self.engine, class_=AsyncSession, expire_on_commit=False
        )
    
    async def list_recent_properties(self, limit: int = 10) -> None:
        """List the most recent properties stored in the database."""
        print(f"📋 Listing the {limit} most recent properties...\n")
        
        async with self.async_session() as session:
            # Get recent properties from properties_details_v2
            result = await session.execute(
                select(ApiPropertiesDetailsV2)
                .order_by(ApiPropertiesDetailsV2.created_at.desc())
                .limit(limit)
            )
            properties_details = result.scalars().all()
            
            # Get recent properties from property_details
            result = await session.execute(
                select(ApiPropertyDetails)
                .order_by(ApiPropertyDetails.created_at.desc())
                .limit(limit)
            )
            property_details = result.scalars().all()
            
            # Combine and deduplicate by property_id
            all_properties = {}
            
            for prop in properties_details:
                all_properties[prop.id] = {
                    "property_id": prop.id,
                    "super_id": prop.super_id,
                    "created_at": prop.created_at,
                    "source": "properties_details",
                    "bedrooms": prop.bedrooms,
                    "address": prop.address,
                }
            
            for prop in property_details:
                if prop.property_id not in all_properties:
                    all_properties[prop.property_id] = {
                        "property_id": prop.property_id,
                        "super_id": prop.super_id,
                        "created_at": prop.created_at,
                        "source": "property_details",
                        "bedrooms": prop.bedrooms,
                        "address": prop.display_address,
                    }
                else:
                    # Already have this property from properties_details, mark as both
                    all_properties[prop.property_id]["source"] = "both"
            
            # Convert to list and sort by created_at
            properties_list = list(all_properties.values())
            properties_list.sort(key=lambda x: x["created_at"], reverse=True)
            
            # Display as table
            table_data = [
                [
                    p["property_id"],
                    p["super_id"],
                    p["created_at"].strftime("%Y-%m-%d %H:%M:%S"),
                    p["source"],
                    p.get("bedrooms", "N/A"),
                    p.get("address", "N/A")[:50],  # Truncate long addresses
                ]
                for p in properties_list[:limit]
            ]
            
            headers = ["Property ID", "Super ID", "Created At", "Source", "Bedrooms", "Address"]
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
            print("\nUse a property ID from this list with this script to see full details.")
    
    async def verify_property(self, property_id: int) -> None:
        """Verify and display all data for a specific property ID."""
        print(f"🔍 Verifying property with ID: {property_id}\n")
        
        async with self.async_session() as session:
            await self._verify_properties_details(session, property_id)
            await self._verify_property_details(session, property_id)
    
    async def _verify_properties_details(self, session: AsyncSession, property_id: int) -> None:
        """Verify data in the properties_details_v2 tables."""
        print("📊 PROPERTIES_DETAILS_V2 DATA")
        print("=" * 80)
        
        # Check main record
        result = await session.execute(
            select(ApiPropertiesDetailsV2).where(ApiPropertiesDetailsV2.id == property_id)
        )
        main_record = result.scalar_one_or_none()
        
        if not main_record:
            print("❌ No record found in ApiPropertiesDetailsV2")
            return
        
        print(f"✅ Main record found (created: {main_record.created_at})")
        print(f"  - Super ID: {main_record.super_id}")
        print(f"  - Transaction Type: {main_record.transaction_type}")
        print(f"  - Channel: {main_record.channel}")
        print(f"  - Bedrooms: {main_record.bedrooms}")
        print(f"  - Bathrooms: {main_record.bathrooms}")
        print(f"  - Address: {main_record.address}")
        print(f"  - Property URL: {main_record.property_url}")
        
        if main_record.key_features:
            print("\n🔑 Key Features:")
            for feature in main_record.key_features:
                print(f"  - {feature}")
        
        # Check branch info
        result = await session.execute(
            select(ApiPropertiesDetailsV2Branch).where(ApiPropertiesDetailsV2Branch.api_property_id == property_id)
        )
        branch = result.scalar_one_or_none()
        
        print("\n🏢 Branch Information:")
        if branch:
            print(f"  - Branch ID: {branch.branch_id}")
            print(f"  - Name: {branch.name}")
            print(f"  - Company: {branch.company_name}")
            print(f"  - Address: {branch.address}")
        else:
            print("  ❌ No branch information found")
        
        # Check price info
        result = await session.execute(
            select(ApiPropertiesDetailsV2Price).where(ApiPropertiesDetailsV2Price.api_property_id == property_id)
        )
        price = result.scalar_one_or_none()
        
        print("\n💰 Price Information:")
        if price:
            print(f"  - Primary Price: {price.primary_price}")
            print(f"  - Secondary Price: {price.secondary_price}")
        else:
            print("  ❌ No price information found")
        
        # Check location info
        result = await session.execute(
            select(ApiPropertiesDetailsV2Location).where(ApiPropertiesDetailsV2Location.api_property_id == property_id)
        )
        location = result.scalar_one_or_none()
        
        print("\n📍 Location Information:")
        if location:
            print(f"  - Latitude: {location.latitude}")
            print(f"  - Longitude: {location.longitude}")
        else:
            print("  ❌ No location information found")
        
        # Check photos
        result = await session.execute(
            select(func.count()).select_from(ApiPropertiesDetailsV2Photo).where(
                ApiPropertiesDetailsV2Photo.api_property_id == property_id
            )
        )
        photo_count = result.scalar_one()
        
        print(f"\n📸 Photos: {photo_count}")
        if photo_count > 0:
            result = await session.execute(
                select(ApiPropertiesDetailsV2Photo).where(
                    ApiPropertiesDetailsV2Photo.api_property_id == property_id
                ).limit(3)
            )
            photos = result.scalars().all()
            for i, photo in enumerate(photos):
                print(f"  - Photo {i+1}: {photo.caption}")
                print(f"    URL: {photo.url}")
            
            if photo_count > 3:
                print(f"    ... and {photo_count - 3} more photos")
        
        # Check floorplans
        result = await session.execute(
            select(func.count()).select_from(ApiPropertiesDetailsV2Floorplan).where(
                ApiPropertiesDetailsV2Floorplan.api_property_id == property_id
            )
        )
        floorplan_count = result.scalar_one()
        
        print(f"\n📝 Floorplans: {floorplan_count}")
        if floorplan_count > 0:
            result = await session.execute(
                select(ApiPropertiesDetailsV2Floorplan).where(
                    ApiPropertiesDetailsV2Floorplan.api_property_id == property_id
                )
            )
            floorplans = result.scalars().all()
            for i, floorplan in enumerate(floorplans):
                print(f"  - Floorplan {i+1}: {floorplan.url}")
    
    async def _verify_property_details(self, session: AsyncSession, property_id: int) -> None:
        """Verify data in the property_details tables."""
        print("\n\n📊 PROPERTY_DETAILS DATA")
        print("=" * 80)
        
        # Check main record
        result = await session.execute(
            select(ApiPropertyDetails).where(ApiPropertyDetails.property_id == property_id)
        )
        main_record = result.scalar_one_or_none()
        
        if not main_record:
            print("❌ No record found in ApiPropertyDetails")
            return
        
        db_id = main_record.id
        
        print(f"✅ Main record found (created: {main_record.created_at})")
        print(f"  - Super ID: {main_record.super_id}")
        print(f"  - Property Type: {main_record.property_type}")
        print(f"  - Property Subtype: {main_record.property_subtype}")
        print(f"  - Bedrooms: {main_record.bedrooms}")
        print(f"  - Bathrooms: {main_record.bathrooms}")
        print(f"  - Display Address: {main_record.display_address}")
        print(f"  - Summary: {main_record.summary}")
        print(f"  - Property URL: {main_record.property_url}")
        
        if main_record.features:
            print("\n🔑 Features:")
            for feature in main_record.features:
                print(f"  - {feature}")
        
        # Check price info
        result = await session.execute(
            select(ApiPropertyDetailPrice).where(ApiPropertyDetailPrice.api_property_detail_id == db_id)
        )
        price = result.scalar_one_or_none()
        
        print("\n💰 Price Information:")
        if price:
            print(f"  - Display Price: {price.display_price}")
            print(f"  - Price Qualifier: {price.price_qualifier}")
            print(f"  - Currency Code: {price.currency_code}")
        else:
            print("  ❌ No price information found")
        
        # Check customer info
        result = await session.execute(
            select(ApiPropertyDetailCustomer).where(ApiPropertyDetailCustomer.api_property_detail_id == db_id)
        )
        customer = result.scalar_one_or_none()
        
        print("\n🏢 Customer Information:")
        if customer:
            print(f"  - Branch ID: {customer.branch_id}")
            print(f"  - Branch Name: {customer.branch_name}")
            print(f"  - Company Name: {customer.company_name}")
        else:
            print("  ❌ No customer information found")
        
        # Check images
        result = await session.execute(
            select(func.count()).select_from(ApiPropertyDetailImage).where(
                ApiPropertyDetailImage.api_property_detail_id == db_id
            )
        )
        image_count = result.scalar_one()
        
        print(f"\n📸 Images: {image_count}")
        if image_count > 0:
            result = await session.execute(
                select(ApiPropertyDetailImage).where(
                    ApiPropertyDetailImage.api_property_detail_id == db_id
                ).limit(3)
            )
            images = result.scalars().all()
            for i, image in enumerate(images):
                print(f"  - Image {i+1}: {image.caption}")
                print(f"    URL: {image.url}")
            
            if image_count > 3:
                print(f"    ... and {image_count - 3} more images")
        
        # Check floorplans
        result = await session.execute(
            select(func.count()).select_from(ApiPropertyDetailFloorplan).where(
                ApiPropertyDetailFloorplan.api_property_detail_id == db_id
            )
        )
        floorplan_count = result.scalar_one()
        
        print(f"\n📝 Floorplans: {floorplan_count}")
        if floorplan_count > 0:
            result = await session.execute(
                select(ApiPropertyDetailFloorplan).where(
                    ApiPropertyDetailFloorplan.api_property_detail_id == db_id
                )
            )
            floorplans = result.scalars().all()
            for i, floorplan in enumerate(floorplans):
                print(f"  - Floorplan {i+1}: {floorplan.caption if floorplan.caption else 'No caption'}")
                print(f"    URL: {floorplan.url}")
    
    async def close(self) -> None:
        """Close the database connection."""
        await self.engine.dispose()


async def main() -> None:
    """Main entry point for the script."""
    parser = argparse.ArgumentParser(description="Verify Rightmove property data in the database")
    parser.add_argument("property_id", nargs="?", type=int, help="Property ID to verify")
    args = parser.parse_args()
    
    verifier = DataVerifier()
    
    try:
        if args.property_id:
            await verifier.verify_property(args.property_id)
        else:
            await verifier.list_recent_properties()
    finally:
        await verifier.close()


if __name__ == "__main__":
    asyncio.run(main())


# data_capture_rightmove_service/scripts/setup_database.sh
#!/bin/bash

# ==============================================================================
# Data Capture Rightmove Service Development Environment Setup Script
# ==============================================================================
# This script automates the entire process of setting up the local development
# environment. It ensures a clean slate by dropping and re-creating the
# databases before running migrations and starting the service.
#
# Prerequisite:
#   - Docker and Docker Compose are installed.
#   - The Supabase stack for the 'paservices' project is running.
#     (Run `supabase start` from the project's root directory).
#
# Usage:
#   ./setup_database.sh
# ==============================================================================

# Exit immediately if a command exits with a non-zero status.
set -e

# --- Configuration ---
DEV_COMPOSE_FILE="docker-compose.dev.yml"
ROOT_PROJECT_DIR=".." # Assumes this script is run from inside the service directory
SUPABASE_DB_CONTAINER="supabase_db_paservices"
DEV_DB_NAME="data_capture_rightmove_dev_db"
TEST_DB_NAME="data_capture_rightmove_test_db"
SCHEMA_DUMP_FILE="sql/rightmove_schema.sql"

# --- Helper Functions ---
print_header() {
  echo ""
  echo "=============================================================================="
  echo "=> $1"
  echo "=============================================================================="
}

# --- Main Logic ---

# Step 1: Verify Supabase is running by checking for the DB container
print_header "Step 1: Verifying Supabase stack is running"
if ! docker ps --format '{{.Names}}' | grep -q "^${SUPABASE_DB_CONTAINER}$"; then
  echo "❌ ERROR: The Supabase container '${SUPABASE_DB_CONTAINER}' is not running."
  echo "Please navigate to the project root ('paservices') and run 'supabase start'."
  exit 1
fi
echo "✅ Supabase container '${SUPABASE_DB_CONTAINER}' is running."


# Step 2: Drop existing databases and create fresh ones for development and testing
# This ensures a completely clean environment for every run.
print_header "Step 2: Re-creating databases '${DEV_DB_NAME}' and '${TEST_DB_NAME}' (dropping if they exist)"

# First, clean up old databases with previous names (if they exist)
echo "Cleaning up old databases with previous names..."
docker exec "${SUPABASE_DB_CONTAINER}" psql -U postgres -c "DROP DATABASE IF EXISTS rightmove_dev_db WITH (FORCE);"
docker exec "${SUPABASE_DB_CONTAINER}" psql -U postgres -c "DROP DATABASE IF EXISTS rightmove_test_db WITH (FORCE);"
echo "✅ Old databases cleaned up."

# Using `DROP DATABASE IF EXISTS ... WITH (FORCE)` terminates any active connections
# and prevents errors if the database doesn't exist, making the script robust.
docker exec "${SUPABASE_DB_CONTAINER}" psql -U postgres -c "DROP DATABASE IF EXISTS ${DEV_DB_NAME} WITH (FORCE);"
docker exec "${SUPABASE_DB_CONTAINER}" psql -U postgres -c "CREATE DATABASE ${DEV_DB_NAME};"
echo "✅ Development database '${DEV_DB_NAME}' re-created."

docker exec "${SUPABASE_DB_CONTAINER}" psql -U postgres -c "DROP DATABASE IF EXISTS ${TEST_DB_NAME} WITH (FORCE);"
docker exec "${SUPABASE_DB_CONTAINER}" psql -U postgres -c "CREATE DATABASE ${TEST_DB_NAME};"
echo "✅ Test database '${TEST_DB_NAME}' re-created."


# Step 3: Drop all tables in the rightmove schema if it exists
print_header "Step 3: Dropping existing tables in rightmove schema"

# Drop all tables in the rightmove schema
DROP_SCHEMA_SQL="DROP SCHEMA IF EXISTS rightmove CASCADE; CREATE SCHEMA rightmove;"
docker exec -i "${SUPABASE_DB_CONTAINER}" psql -U postgres -d "${DEV_DB_NAME}" -c "${DROP_SCHEMA_SQL}"
docker exec -i "${SUPABASE_DB_CONTAINER}" psql -U postgres -d "${TEST_DB_NAME}" -c "${DROP_SCHEMA_SQL}"
echo "✅ Schema 'rightmove' reset."

# First check if there are any existing migration files
MIGRATION_DIR="alembic/versions"
if [ -n "$(ls -A ${MIGRATION_DIR} 2>/dev/null)" ]; then
    echo "Removing existing migration files to ensure clean generation..."
    rm -f ${MIGRATION_DIR}/*.py
    echo "✅ Existing migration files removed."
fi

# We first need to build the service container to run commands in it
docker-compose -f "${DEV_COMPOSE_FILE}" build data_capture_rightmove_service_dev

# Generate a migration that will create all tables based on SQLAlchemy models
echo "Generating migration from SQLAlchemy models..."
docker-compose -f "${DEV_COMPOSE_FILE}" run --rm data_capture_rightmove_service_dev alembic revision --autogenerate -m "initial schema with all tables"
echo "✅ Migration file generated from SQLAlchemy models."

# Step 4: Apply the Alembic migration to create all tables
print_header "Step 4: Applying Alembic migration to create all tables"
docker-compose -f "${DEV_COMPOSE_FILE}" run --rm data_capture_rightmove_service_dev alembic upgrade head
echo "✅ Tables created via Alembic migration."

# Step 5: Apply custom SQL for any elements not captured in SQLAlchemy models
print_header "Step 5: Applying additional SQL customizations"
echo "Note: This step is for any SQL that can't be represented in SQLAlchemy models"
echo "      (like custom types, functions, procedures, etc.)"

# Apply any custom SQL elements that might not be captured in SQLAlchemy models
# Uncomment and modify if needed
# (cd "${ROOT_PROJECT_DIR}" && docker exec -i "${SUPABASE_DB_CONTAINER}" psql -U postgres -d "${DEV_DB_NAME}" < "data_capture_rightmove_service/sql/custom_elements.sql")
# (cd "${ROOT_PROJECT_DIR}" && docker exec -i "${SUPABASE_DB_CONTAINER}" psql -U postgres -d "${TEST_DB_NAME}" < "data_capture_rightmove_service/sql/custom_elements.sql")
echo "✅ No custom SQL elements needed at this time."

print_header "Setup Complete!"
echo "Your development environment is ready."
echo "You can now run tests with: docker-compose -f ${DEV_COMPOSE_FILE} run --rm data_capture_rightmove_service_dev pytest"

# data_capture_rightmove_service/scripts/setup_test_env.sh
#!/bin/bash

# ==============================================================================
# Data Capture Rightmove Service Test Environment Setup Script
# ==============================================================================
# This script automates the entire process of setting up the test environment,
# from creating databases to running migrations and preparing for tests.
#
# Prerequisite:
#   - Docker and Docker Compose are installed.
#
# Usage:
#   ./setup_test_env.sh
# ==============================================================================

# Exit immediately if a command exits with a non-zero status.
set -e

# --- Configuration ---
TEST_COMPOSE_FILE="docker-compose.test.yml"

# --- Helper Functions ---
print_header() {
  echo ""
  echo "=============================================================================="
  echo "=> $1"
  echo "=============================================================================="
}

print_header "Rightmove Data Capture Service Test Environment Setup"
echo -e "Setting up test environment in ${YELLOW}$SERVICE_ROOT${NC}\n"

# --- Main Logic ---

# Step 1: Check for env.test file
print_header "Step 1: Checking for env.test file"
if [ ! -f "env.test" ]; then
  echo "❌ ERROR: env.test file not found."
  echo "Please create an env.test file with the necessary environment variables."
  exit 1
fi
echo "✅ env.test file found."

# Step 2: Start Postgres and Redis containers for testing
print_header "Step 2: Starting PostgreSQL and Redis containers for testing"
echo "Starting test infrastructure containers..."
docker-compose -f "${TEST_COMPOSE_FILE}" up -d postgres_test redis_test
echo "✅ Test infrastructure containers started."

# Step 3: Wait for PostgreSQL to be ready
print_header "Step 3: Waiting for PostgreSQL to be ready"
MAX_RETRIES=30
RETRY_COUNT=0
echo "Checking PostgreSQL readiness..."

while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
  if docker-compose -f "${TEST_COMPOSE_FILE}" exec postgres_test pg_isready -U postgres &>/dev/null; then
    echo "✅ PostgreSQL is ready!"
    break
  fi
  echo "Waiting for PostgreSQL to start... ($((RETRY_COUNT + 1))/$MAX_RETRIES)"
  RETRY_COUNT=$((RETRY_COUNT + 1))
  sleep 2
done

if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
  echo "❌ ERROR: PostgreSQL failed to start within the allocated time."
  exit 1
fi

# Step 4: Create the schema for the database
print_header "Step 4: Creating 'rightmove' schema in the test database"
docker-compose -f "${TEST_COMPOSE_FILE}" exec postgres_test psql -U postgres -d rightmove_test -c "CREATE SCHEMA IF NOT EXISTS rightmove;"
echo "✅ Schema created or already exists."

# Step 5: Run Alembic migrations to create test tables
print_header "Step 5: Running Alembic migrations for test database"
# We need to build the test container first
docker-compose -f "${TEST_COMPOSE_FILE}" build data_capture_rightmove_test
# Now run the migrations
docker-compose -f "${TEST_COMPOSE_FILE}" run --rm data_capture_rightmove_test alembic upgrade head
echo "✅ Alembic migrations applied to test database."

print_header "Test Setup Complete!"
echo "Your test environment is ready."
echo "To run tests, use: docker-compose -f ${TEST_COMPOSE_FILE} run --rm data_capture_rightmove_test pytest"


# data_capture_rightmove_service/scripts/integration_test.py
#!/usr/bin/env python3
"""
Integration test script for testing the property data capture service with real Rightmove URLs.
This script sends requests to the service API and verifies the responses and database records.

Usage:
    python scripts/integration_test.py

Environment variables:
    DATA_CAPTURE_RIGHTMOVE_SERVICE_API_URL: The base URL for the service API (default: http://localhost:8000)
    RIGHTMOVE_TEST_URL: A test Rightmove property URL to use
"""

import asyncio
import json
import os
import sys
import uuid
from typing import Dict, Optional

import httpx
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

# Add project root to path for imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.models.properties_details import (
    ApiPropertiesDetailsV2,
)
from data_capture_rightmove_service.models.property_details import ApiPropertyDetails
from data_capture_rightmove_service.utils.url_parsing import (
    extract_rightmove_property_id,
)

# Configuration
API_URL = os.environ.get(
    "DATA_CAPTURE_RIGHTMOVE_SERVICE_API_URL", "http://localhost:8003"
)
TEST_URL = os.environ.get(
    "RIGHTMOVE_TEST_URL", "https://www.rightmove.co.uk/properties/154508327"
)


class IntegrationTester:
    """Integration tester for the property data capture service."""

    def __init__(self):
        """Initialize the tester."""
        self.client = httpx.AsyncClient(base_url=API_URL, timeout=60.0)
        self.engine = create_async_engine(settings.DATABASE_URL)
        self.async_session = sessionmaker(
            self.engine, class_=AsyncSession, expire_on_commit=False
        )
        self.property_id = None
        self.super_ids = []

    async def setup(self):
        """Set up the test environment."""
        print(f"🔵 Setting up integration test for {API_URL}")
        print(f"🔵 Using test URL: {TEST_URL}")

        # Extract property ID from the URL for validation
        self.property_id = extract_rightmove_property_id(TEST_URL)
        if not self.property_id:
            print("❌ Failed to extract property ID from test URL")
            sys.exit(1)

        print(f"🔵 Extracted property ID: {self.property_id}")

    async def validate_url(self) -> bool:
        """Test the URL validation endpoint."""
        print("\n🔍 Testing URL validation endpoint...")

        try:
            response = await self.client.get(
                f"/properties/validate-url", params={"url": TEST_URL}
            )

            if response.status_code != 200:
                print(f"❌ URL validation failed with status {response.status_code}")
                print(f"Response: {response.text}")
                return False

            data = response.json()
            print(f"✅ URL validation successful: {json.dumps(data, indent=2)}")

            if not data.get("valid"):
                print("❌ URL was reported as invalid")
                return False

            if data.get("property_id") != self.property_id:
                print(
                    f"❌ Property ID mismatch: {data.get('property_id')} vs {self.property_id}"
                )
                return False

            return True

        except Exception as e:
            print(f"❌ Exception during URL validation: {e}")
            return False

    async def fetch_combined_data(self) -> bool:
        """Test the combined data fetch endpoint."""
        print("\n🔍 Testing combined data fetch endpoint...")

        try:
            # Generate a test super_id
            test_super_id = uuid.uuid4()

            response = await self.client.post(
                "/properties/fetch/combined",
                json={
                    "property_url": TEST_URL,
                    "super_id": str(test_super_id),
                    "description": "Integration test",
                },
            )

            if response.status_code != 200:
                print(f"❌ Combined fetch failed with status {response.status_code}")
                print(f"Response: {response.text}")
                return False

            data = response.json()
            print(f"✅ Combined fetch successful")
            print(f"Results: {len(data.get('results', []))} API endpoints processed")

            # Store super_ids for database verification
            self.super_ids = [
                uuid.UUID(result["super_id"])
                for result in data.get("results", [])
                if result.get("super_id")
            ]

            # Verify both API endpoints were called and data was stored
            if len(data.get("results", [])) != 2:
                print(f"❌ Expected 2 API results, got {len(data.get('results', []))}")
                return False

            # Check all results for success
            all_success = all(
                result.get("stored", False) for result in data.get("results", [])
            )
            if not all_success:
                print("❌ Not all data was stored successfully")
                for result in data.get("results", []):
                    if not result.get("stored"):
                        print(
                            f"  - {result.get('api_endpoint')}: {result.get('message')}"
                        )
                return False

            print(f"✅ All data stored successfully")
            return True

        except Exception as e:
            print(f"❌ Exception during combined fetch: {e}")
            return False

    async def verify_database_records(self) -> bool:
        """Verify that data was properly stored in the database."""
        print("\n🔍 Verifying database records...")

        if not self.property_id:
            print("❌ Missing property ID for verification")
            return False

        if not self.super_ids:
            print("❌ Missing super IDs for verification")
            return False

        try:
            async with self.async_session() as session:
                # Check properties_details table
                result = await session.execute(
                    select(ApiPropertiesDetailsV2).where(
                        ApiPropertiesDetailsV2.id == self.property_id
                    )
                )
                properties_details = result.scalar_one_or_none()

                if not properties_details:
                    print(
                        f"❌ No record found in ApiPropertiesDetailsV2 for ID {self.property_id}"
                    )
                    return False

                print(f"✅ Found properties_details record for ID {self.property_id}")

                # Check property_details table
                result = await session.execute(
                    select(ApiPropertyDetails).where(
                        ApiPropertyDetails.property_id == self.property_id
                    )
                )
                property_details = result.scalar_one_or_none()

                if not property_details:
                    print(
                        f"❌ No record found in ApiPropertyDetails for ID {self.property_id}"
                    )
                    return False

                print(f"✅ Found property_details record for ID {self.property_id}")

                # Verify that all necessary data was stored
                await self._verify_data_completeness(session, self.property_id)

                return True

        except Exception as e:
            print(f"❌ Exception during database verification: {e}")
            return False

    async def _verify_data_completeness(
        self, session: AsyncSession, property_id: int
    ) -> None:
        """Verify that all necessary data fields are populated in the database."""
        try:
            # Verify properties_details record has related entities
            # Check for branch info
            result = await session.execute(
                "SELECT COUNT(*) FROM properties_details_v2_branch WHERE api_property_id = :pid",
                {"pid": property_id},
            )
            branch_count = result.scalar_one()
            print(f"  - Branch records: {branch_count}")

            # Check for price info
            result = await session.execute(
                "SELECT COUNT(*) FROM properties_details_v2_price WHERE api_property_id = :pid",
                {"pid": property_id},
            )
            price_count = result.scalar_one()
            print(f"  - Price records: {price_count}")

            # Check for location info
            result = await session.execute(
                "SELECT COUNT(*) FROM properties_details_v2_location WHERE api_property_id = :pid",
                {"pid": property_id},
            )
            location_count = result.scalar_one()
            print(f"  - Location records: {location_count}")

            # Check for photos
            result = await session.execute(
                "SELECT COUNT(*) FROM properties_details_v2_photo WHERE api_property_id = :pid",
                {"pid": property_id},
            )
            photo_count = result.scalar_one()
            print(f"  - Photo records: {photo_count}")

            # Check for floorplans
            result = await session.execute(
                "SELECT COUNT(*) FROM properties_details_v2_floorplan WHERE api_property_id = :pid",
                {"pid": property_id},
            )
            floorplan_count = result.scalar_one()
            print(f"  - Floorplan records: {floorplan_count}")

            # Verify property_details record has related entities
            # Check for customer info
            result = await session.execute(
                "SELECT COUNT(*) FROM property_detail_customer WHERE api_property_detail_id = "
                "(SELECT id FROM property_details WHERE property_id = :pid)",
                {"pid": property_id},
            )
            customer_count = result.scalar_one()
            print(f"  - Customer records: {customer_count}")

            # Check for images
            result = await session.execute(
                "SELECT COUNT(*) FROM property_detail_image WHERE api_property_detail_id = "
                "(SELECT id FROM property_details WHERE property_id = :pid)",
                {"pid": property_id},
            )
            image_count = result.scalar_one()
            print(f"  - Image records: {image_count}")

            # Check for floorplans
            result = await session.execute(
                "SELECT COUNT(*) FROM property_detail_floorplan WHERE api_property_detail_id = "
                "(SELECT id FROM property_details WHERE property_id = :pid)",
                {"pid": property_id},
            )
            detail_floorplan_count = result.scalar_one()
            print(f"  - Detail floorplan records: {detail_floorplan_count}")

        except Exception as e:
            print(f"❌ Exception during data completeness check: {e}")

    async def run(self) -> None:
        """Run the integration tests."""
        try:
            await self.setup()

            # Step 1: Validate URL endpoint
            url_valid = await self.validate_url()
            if not url_valid:
                print("❌ URL validation test failed")
                return

            # Step 2: Test combined fetch endpoint
            fetch_success = await self.fetch_combined_data()
            if not fetch_success:
                print("❌ Combined fetch test failed")
                return

            # Step 3: Verify database records
            db_verified = await self.verify_database_records()
            if not db_verified:
                print("❌ Database verification failed")
                return

            print("\n✅ All tests passed successfully!")

        except Exception as e:
            print(f"❌ Integration test failed with unexpected error: {e}")
        finally:
            await self.client.aclose()
            await self.engine.dispose()


if __name__ == "__main__":
    tester = IntegrationTester()
    asyncio.run(tester.run())


# data_capture_rightmove_service/alembic/script.py.mako
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision = ${repr(up_revision)}
down_revision = ${repr(down_revision)}
branch_labels = ${repr(branch_labels)}
depends_on = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}


# data_capture_rightmove_service/alembic/env.py
"""
Alembic environment module for database migrations.
"""

import asyncio
import os
import sys
from logging.config import fileConfig

from alembic import context
from sqlalchemy import pool
from sqlalchemy.engine import Connection
from sqlalchemy.ext.asyncio import async_engine_from_config

# models. The Dockerfile sets PYTHONPATH=/app/src, which means we can import the package directly.
# Import all model modules here to ensure they are registered with
# SQLAlchemy's metadata before 'autogenerate' runs.
from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.db import Base

# The 'noqa' comments prevent linters from complaining about an unused wildcard import.
from data_capture_rightmove_service.models import *  # noqa: F401, F403

# --- Alembic Config ---
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

config.set_main_option("sqlalchemy.url", str(settings.DATABASE_URL))

# Set target_metadata to our SQLAlchemy Base.metadata for autogenerate support
target_metadata = Base.metadata


def include_object(object, name, type_, reflected, compare_to):
    """
    Tells Alembic to only pay attention to objects within our 'rightmove' schema.
    This prevents it from trying to manage tables in other schemas (e.g., 'public').
    """
    if type_ == "table" and object.schema != target_metadata.schema:
        return False
    return True


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        include_schemas=True,  # Required for schema support
        include_object=include_object,  # Use our schema filter
        compare_type=True,  # Compare column types
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection):
    """Run the actual migrations within a connection context."""
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        include_schemas=True,  # Required for schema support
        include_object=include_object,  # Use our schema filter
        compare_type=True,  # Compare column types
    )

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations() -> None:
    """In this scenario we need to create an Engine and associate a connection with the context."""
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


if context.is_offline_mode():
    run_migrations_offline()
else:
    asyncio.run(run_async_migrations())


# data_capture_rightmove_service/alembic/versions/bad9982f7e68_initial_schema_with_all_tables.py
"""initial schema with all tables

Revision ID: bad9982f7e68
Revises: 
Create Date: 2025-07-03 02:09:35.447046

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'bad9982f7e68'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('api_properties_details_v2',
    sa.Column('snapshot_id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('id', sa.BigInteger(), nullable=False),
    sa.Column('transaction_type', sa.String(length=50), nullable=True),
    sa.Column('channel', sa.String(length=50), nullable=True),
    sa.Column('bedrooms', sa.Integer(), nullable=True),
    sa.Column('bathrooms', sa.Integer(), nullable=True),
    sa.Column('address', sa.Text(), nullable=True),
    sa.Column('contact_method', sa.String(length=50), nullable=True),
    sa.Column('property_disclaimer', sa.Text(), nullable=True),
    sa.Column('property_phrase', sa.String(length=255), nullable=True),
    sa.Column('full_description', sa.Text(), nullable=True),
    sa.Column('listing_update_reason', sa.String(length=255), nullable=True),
    sa.Column('property_url', sa.Text(), nullable=True),
    sa.Column('school_checker_url', sa.Text(), nullable=True),
    sa.Column('lettings_info', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('property_display_type', sa.String(length=100), nullable=True),
    sa.Column('telephone_number', sa.String(length=50), nullable=True),
    sa.Column('saved', sa.Boolean(), nullable=True),
    sa.Column('sold_prices_url', sa.Text(), nullable=True),
    sa.Column('market_info_url', sa.Text(), nullable=True),
    sa.Column('note', sa.Text(), nullable=True),
    sa.Column('link_to_glossary', sa.Text(), nullable=True),
    sa.Column('enquired_timestamp', sa.TIMESTAMP(timezone=True), nullable=True),
    sa.Column('key_features', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('tags', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('virtual_tours', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.PrimaryKeyConstraint('snapshot_id', name=op.f('pk_api_properties_details_v2')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_id'), 'api_properties_details_v2', ['id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_super_id'), 'api_properties_details_v2', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_details',
    sa.Column('snapshot_id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('id', sa.BigInteger(), nullable=False),
    sa.Column('affordable_buying_scheme', sa.Boolean(), nullable=True),
    sa.Column('ai_location_info', sa.Text(), nullable=True),
    sa.Column('bathrooms', sa.Integer(), nullable=True),
    sa.Column('bedrooms', sa.Integer(), nullable=True),
    sa.Column('business_for_sale', sa.Boolean(), nullable=True),
    sa.Column('channel', sa.String(length=50), nullable=True),
    sa.Column('commercial', sa.Boolean(), nullable=True),
    sa.Column('country_guide', sa.Text(), nullable=True),
    sa.Column('enc_id', sa.Text(), nullable=True),
    sa.Column('fees_apply', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('lettings', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('property_sub_type', sa.Text(), nullable=True),
    sa.Column('show_school_info', sa.Boolean(), nullable=True),
    sa.Column('sold_property_type', sa.String(length=100), nullable=True),
    sa.Column('terms_of_use', sa.Text(), nullable=True),
    sa.Column('transaction_type', sa.String(length=50), nullable=True),
    sa.Column('brochures', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('commercial_use_classes', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('epc_graphs', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('key_features', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('nearest_airports', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('rooms', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('sizings', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('tags', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.PrimaryKeyConstraint('snapshot_id', name=op.f('pk_api_property_details')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_details_id'), 'api_property_details', ['id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_details_super_id'), 'api_property_details', ['super_id'], unique=False, schema='rightmove')
    op.create_table('scrape_events',
    sa.Column('id', sa.BigInteger(), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.Column('rightmove_property_id', sa.BigInteger(), nullable=True),
    sa.Column('event_type', sa.Enum('REQUEST_RECEIVED', 'API_CALL_ATTEMPT', 'API_CALL_SUCCESS', 'API_CALL_FAILURE', 'DATA_PARSED_SUCCESS', 'DATA_PARSED_FAILURE', 'DATA_STORED_SUCCESS', 'DATA_STORED_FAILURE', name='scrapeeventtypeenum'), nullable=False),
    sa.Column('event_timestamp', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('source_service_name', sa.Text(), nullable=True),
    sa.Column('api_endpoint_called', sa.Text(), nullable=True),
    sa.Column('http_status_code', sa.Integer(), nullable=True),
    sa.Column('error_code', sa.Text(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('payload', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('response_item_count', sa.Integer(), nullable=True),
    sa.Column('response_null_item_count', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_scrape_events')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_scrape_events_event_type'), 'scrape_events', ['event_type'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_scrape_events_rightmove_property_id'), 'scrape_events', ['rightmove_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_scrape_events_super_id'), 'scrape_events', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_analytics_info',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('branch_id', sa.String(length=50), nullable=True),
    sa.Column('property_id', sa.String(length=50), nullable=True),
    sa.Column('online_viewing', sa.String(length=10), nullable=True),
    sa.Column('image_count', sa.String(length=10), nullable=True),
    sa.Column('floorplan_count', sa.String(length=10), nullable=True),
    sa.Column('beds', sa.String(length=10), nullable=True),
    sa.Column('postcode', sa.String(length=20), nullable=True),
    sa.Column('property_type', sa.String(length=100), nullable=True),
    sa.Column('property_sub_type', sa.String(length=100), nullable=True),
    sa.Column('added', sa.String(length=20), nullable=True),
    sa.Column('price', sa.String(length=50), nullable=True),
    sa.Column('tenure', sa.String(length=100), nullable=True),
    sa.Column('bathrooms', sa.String(length=10), nullable=True),
    sa.Column('shared_ownership', sa.String(length=10), nullable=True),
    sa.Column('electricity', sa.String(length=50), nullable=True),
    sa.Column('broadband', sa.String(length=50), nullable=True),
    sa.Column('water', sa.String(length=50), nullable=True),
    sa.Column('sewerage', sa.String(length=50), nullable=True),
    sa.Column('heating', sa.String(length=50), nullable=True),
    sa.Column('accessibility', sa.String(length=50), nullable=True),
    sa.Column('parking', sa.String(length=50), nullable=True),
    sa.Column('garden', sa.String(length=50), nullable=True),
    sa.Column('flood_history', sa.String(length=50), nullable=True),
    sa.Column('flood_defences', sa.String(length=50), nullable=True),
    sa.Column('flood_risk', sa.String(length=50), nullable=True),
    sa.Column('listed', sa.String(length=50), nullable=True),
    sa.Column('restrictions', sa.String(length=50), nullable=True),
    sa.Column('private_access', sa.String(length=50), nullable=True),
    sa.Column('public_access', sa.String(length=50), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_analytics_info_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_analytics_info')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_analytics_info_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_analytics_info_api_property_id'), 'api_properties_details_v2_analytics_info', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_analytics_info_super_id'), 'api_properties_details_v2_analytics_info', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_branch',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('identifier', sa.Integer(), nullable=True),
    sa.Column('name', sa.String(length=255), nullable=True),
    sa.Column('brand_name', sa.String(length=255), nullable=True),
    sa.Column('display_name', sa.String(length=255), nullable=True),
    sa.Column('address', sa.Text(), nullable=True),
    sa.Column('logo', sa.Text(), nullable=True),
    sa.Column('developer', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_branch_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_branch')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_branch_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_branch_api_property_id'), 'api_properties_details_v2_branch', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_branch_super_id'), 'api_properties_details_v2_branch', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_brochure',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('title', sa.String(length=255), nullable=True),
    sa.Column('show_brochure_lead', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_brochure_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_brochure')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_brochure_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_brochure_api_property_id'), 'api_properties_details_v2_brochure', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_brochure_super_id'), 'api_properties_details_v2_brochure', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_epcs',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('caption', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_epcs_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_epcs')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_epcs_api_property_id'), 'api_properties_details_v2_epcs', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_epcs_super_id'), 'api_properties_details_v2_epcs', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_features',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('electricity', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('broadband', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('water', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('sewerage', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('heating', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('accessibility', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('parking', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('garden', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_features_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_features')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_features_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_features_api_property_id'), 'api_properties_details_v2_features', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_features_super_id'), 'api_properties_details_v2_features', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_floorplans',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('thumbnail_url', sa.Text(), nullable=True),
    sa.Column('caption', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_floorplans_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_floorplans')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_floorplans_api_property_id'), 'api_properties_details_v2_floorplans', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_floorplans_super_id'), 'api_properties_details_v2_floorplans', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_local_tax',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('type', sa.String(length=100), nullable=True),
    sa.Column('status', sa.Text(), nullable=True),
    sa.Column('value', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_local_tax_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_local_tax')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_local_tax_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_local_tax_api_property_id'), 'api_properties_details_v2_local_tax', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_local_tax_super_id'), 'api_properties_details_v2_local_tax', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_location',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('pin_type', sa.String(length=100), nullable=True),
    sa.Column('latitude', sa.Numeric(precision=10, scale=8), nullable=True),
    sa.Column('longitude', sa.Numeric(precision=11, scale=8), nullable=True),
    sa.Column('map_preview_url', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_location_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_location')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_location_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_location_api_property_id'), 'api_properties_details_v2_location', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_location_super_id'), 'api_properties_details_v2_location', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_mis_info',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('branch_id', sa.Integer(), nullable=True),
    sa.Column('offer_advert_stamp_type_id', sa.Text(), nullable=True),
    sa.Column('brand_plus', sa.Boolean(), nullable=True),
    sa.Column('featured_property', sa.Boolean(), nullable=True),
    sa.Column('channel', sa.String(length=50), nullable=True),
    sa.Column('premium_display', sa.Boolean(), nullable=True),
    sa.Column('premium_display_stamp_id', sa.Text(), nullable=True),
    sa.Column('country_code', sa.String(length=10), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_mis_info_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_mis_info')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_mis_info_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_mis_info_api_property_id'), 'api_properties_details_v2_mis_info', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_mis_info_super_id'), 'api_properties_details_v2_mis_info', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_mortgage',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('price', sa.BigInteger(), nullable=True),
    sa.Column('property_type_alias', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_mortgage_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_mortgage')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_mortgage_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_mortgage_api_property_id'), 'api_properties_details_v2_mortgage', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_mortgage_super_id'), 'api_properties_details_v2_mortgage', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_photos',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('thumbnail_url', sa.Text(), nullable=True),
    sa.Column('max_size_url', sa.Text(), nullable=True),
    sa.Column('caption', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_photos_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_photos')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_photos_api_property_id'), 'api_properties_details_v2_photos', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_photos_super_id'), 'api_properties_details_v2_photos', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_price',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('primary_price', sa.String(length=100), nullable=True),
    sa.Column('secondary_price', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_price_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_price')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_price_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_price_api_property_id'), 'api_properties_details_v2_price', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_price_super_id'), 'api_properties_details_v2_price', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_sales_info',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('tenure_type', sa.String(length=100), nullable=True),
    sa.Column('tenure_display_type', sa.String(length=100), nullable=True),
    sa.Column('ground_rent', sa.Text(), nullable=True),
    sa.Column('annual_service_charge', sa.Text(), nullable=True),
    sa.Column('estate_charge', sa.Text(), nullable=True),
    sa.Column('length_of_lease', sa.Text(), nullable=True),
    sa.Column('shared_ownership_percentage', sa.Text(), nullable=True),
    sa.Column('shared_ownership_rent', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_sales_info_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_sales_info')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_sales_info_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_sales_info_api_property_id'), 'api_properties_details_v2_sales_info', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_sales_info_super_id'), 'api_properties_details_v2_sales_info', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_size',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('primary_size', sa.String(length=100), nullable=True),
    sa.Column('secondary_size', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_size_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_size')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_size_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_size_api_property_id'), 'api_properties_details_v2_size', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_size_super_id'), 'api_properties_details_v2_size', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_stamp_duty',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('country', sa.String(length=100), nullable=True),
    sa.Column('price', sa.BigInteger(), nullable=True),
    sa.Column('buyer_type', sa.Text(), nullable=True),
    sa.Column('result', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_stamp_duty_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_stamp_duty')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_stamp_duty_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_stamp_duty_api_property_id'), 'api_properties_details_v2_stamp_duty', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_stamp_duty_super_id'), 'api_properties_details_v2_stamp_duty', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_stations',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('station', sa.String(length=255), nullable=True),
    sa.Column('distance', sa.Numeric(precision=8, scale=2), nullable=True),
    sa.Column('type', sa.String(length=50), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_stations_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_stations')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_stations_api_property_id'), 'api_properties_details_v2_stations', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_stations_super_id'), 'api_properties_details_v2_stations', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_status',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('available', sa.Boolean(), nullable=True),
    sa.Column('label', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_properties_details_v2.snapshot_id'], name=op.f('fk_api_properties_details_v2_status_api_property_snapshot_id_api_properties_details_v2'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_status')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_properties_details_v2_status_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_status_api_property_id'), 'api_properties_details_v2_status', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_status_super_id'), 'api_properties_details_v2_status', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_addresses',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('country_code', sa.String(length=10), nullable=True),
    sa.Column('delivery_point_id', sa.BigInteger(), nullable=True),
    sa.Column('display_address', sa.Text(), nullable=True),
    sa.Column('incode', sa.String(length=10), nullable=True),
    sa.Column('outcode', sa.String(length=10), nullable=True),
    sa.Column('uk_country', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_addresses_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_addresses')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_addresses_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_addresses_api_property_id'), 'api_property_detail_addresses', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_addresses_super_id'), 'api_property_detail_addresses', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_broadbands',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('broadband_checker_url', sa.Text(), nullable=True),
    sa.Column('disclaimer', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_broadbands_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_broadbands')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_broadbands_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_broadbands_api_property_id'), 'api_property_detail_broadbands', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_broadbands_super_id'), 'api_property_detail_broadbands', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_contact_infos',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('contact_method', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_contact_infos_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_contact_infos')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_contact_infos_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_contact_infos_api_property_id'), 'api_property_detail_contact_infos', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_contact_infos_super_id'), 'api_property_detail_contact_infos', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_customers',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('banner_ad', sa.Text(), nullable=True),
    sa.Column('branch_display_name', sa.String(length=255), nullable=True),
    sa.Column('branch_id', sa.Integer(), nullable=True),
    sa.Column('branch_name', sa.String(length=255), nullable=True),
    sa.Column('build_to_rent', sa.Boolean(), nullable=True),
    sa.Column('build_to_rent_benefits', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('commercial', sa.Boolean(), nullable=True),
    sa.Column('company_name', sa.String(length=255), nullable=True),
    sa.Column('company_trading_name', sa.String(length=255), nullable=True),
    sa.Column('customer_banner_ad_profile_url', sa.Text(), nullable=True),
    sa.Column('customer_mpu_ad_profile_url', sa.Text(), nullable=True),
    sa.Column('customer_profile_url', sa.Text(), nullable=True),
    sa.Column('customer_properties_url', sa.Text(), nullable=True),
    sa.Column('display_address', sa.Text(), nullable=True),
    sa.Column('is_new_home_developer', sa.Boolean(), nullable=True),
    sa.Column('logo_path', sa.Text(), nullable=True),
    sa.Column('mpu_ad', sa.Text(), nullable=True),
    sa.Column('show_brochure_lead_modal', sa.Boolean(), nullable=True),
    sa.Column('spotlight', sa.Text(), nullable=True),
    sa.Column('valuation_form_url', sa.Text(), nullable=True),
    sa.Column('video_enabled', sa.Boolean(), nullable=True),
    sa.Column('video_url', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_customers_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_customers')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_customers_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_customers_api_property_id'), 'api_property_detail_customers', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_customers_super_id'), 'api_property_detail_customers', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_dfp_ad_infos',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('channel', sa.String(length=50), nullable=True),
    sa.Column('targeting', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_dfp_ad_infos_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_dfp_ad_infos')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_dfp_ad_infos_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_dfp_ad_infos_api_property_id'), 'api_property_detail_dfp_ad_infos', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_dfp_ad_infos_super_id'), 'api_property_detail_dfp_ad_infos', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_floorplans',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('caption', sa.String(length=255), nullable=True),
    sa.Column('type', sa.String(length=50), nullable=True),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_floorplans_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_floorplans')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_floorplans_api_property_id'), 'api_property_detail_floorplans', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_floorplans_super_id'), 'api_property_detail_floorplans', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_images',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('caption', sa.String(length=255), nullable=True),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_images_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_images')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_images_api_property_id'), 'api_property_detail_images', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_images_super_id'), 'api_property_detail_images', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_industry_affiliations',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('image_path', sa.Text(), nullable=True),
    sa.Column('name', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_industry_affiliations_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_industry_affiliations')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_industry_affiliations_api_property_id'), 'api_property_detail_industry_affiliations', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_industry_affiliations_super_id'), 'api_property_detail_industry_affiliations', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_info_reel_items',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('primary_text', sa.Text(), nullable=True),
    sa.Column('secondary_text', sa.Text(), nullable=True),
    sa.Column('title', sa.Text(), nullable=True),
    sa.Column('tooltip_text', sa.Text(), nullable=True),
    sa.Column('type', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_info_reel_items_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_info_reel_items')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_info_reel_items_api_property_id'), 'api_property_detail_info_reel_items', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_info_reel_items_super_id'), 'api_property_detail_info_reel_items', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_listing_history',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('listing_update_reason', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_listing_history_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_listing_history')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_listing_history_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_listing_history_api_property_id'), 'api_property_detail_listing_history', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_listing_history_super_id'), 'api_property_detail_listing_history', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_living_costs',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('annual_ground_rent', sa.Text(), nullable=True),
    sa.Column('annual_service_charge', sa.Text(), nullable=True),
    sa.Column('council_tax_band', sa.String(length=10), nullable=True),
    sa.Column('council_tax_exempt', sa.Boolean(), nullable=True),
    sa.Column('council_tax_included', sa.Boolean(), nullable=True),
    sa.Column('domestic_rates', sa.Text(), nullable=True),
    sa.Column('ground_rent_percentage_increase', sa.Text(), nullable=True),
    sa.Column('ground_rent_review_period_in_years', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_living_costs_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_living_costs')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_living_costs_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_living_costs_api_property_id'), 'api_property_detail_living_costs', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_living_costs_super_id'), 'api_property_detail_living_costs', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_locations',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('circle_radius_on_map', sa.Integer(), nullable=True),
    sa.Column('latitude', sa.Numeric(precision=10, scale=8), nullable=True),
    sa.Column('longitude', sa.Numeric(precision=11, scale=8), nullable=True),
    sa.Column('pin_type', sa.String(length=50), nullable=True),
    sa.Column('show_map', sa.Boolean(), nullable=True),
    sa.Column('zoom_level', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_locations_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_locations')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_locations_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_locations_api_property_id'), 'api_property_detail_locations', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_locations_super_id'), 'api_property_detail_locations', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_mis_infos',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('branch_id', sa.Integer(), nullable=True),
    sa.Column('brand_plus', sa.Boolean(), nullable=True),
    sa.Column('featured_property', sa.Boolean(), nullable=True),
    sa.Column('offer_advert_stamp_type_id', sa.Text(), nullable=True),
    sa.Column('premium_display', sa.Boolean(), nullable=True),
    sa.Column('premium_display_stamp_id', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_mis_infos_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_mis_infos')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_mis_infos_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_mis_infos_api_property_id'), 'api_property_detail_mis_infos', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_mis_infos_super_id'), 'api_property_detail_mis_infos', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_mortgage_calculators',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('price', sa.BigInteger(), nullable=True),
    sa.Column('property_type_alias', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_mortgage_calculators_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_mortgage_calculators')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_mortgage_calculators_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_mortgage_calculators_api_property_id'), 'api_property_detail_mortgage_calculators', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_mortgage_calculators_super_id'), 'api_property_detail_mortgage_calculators', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_nearest_stations',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('distance', sa.Numeric(precision=18, scale=16), nullable=True),
    sa.Column('name', sa.Text(), nullable=True),
    sa.Column('unit', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_nearest_stations_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_nearest_stations')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_nearest_stations_api_property_id'), 'api_property_detail_nearest_stations', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_nearest_stations_super_id'), 'api_property_detail_nearest_stations', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_prices',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('display_price_qualifier', sa.String(length=255), nullable=True),
    sa.Column('exchange_rate', sa.Text(), nullable=True),
    sa.Column('message', sa.Text(), nullable=True),
    sa.Column('price_per_sq_ft', sa.String(length=100), nullable=True),
    sa.Column('primary_price', sa.String(length=100), nullable=True),
    sa.Column('secondary_price', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_prices_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_prices')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_prices_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_prices_api_property_id'), 'api_property_detail_prices', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_prices_super_id'), 'api_property_detail_prices', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_property_urls',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('nearby_sold_properties_url', sa.Text(), nullable=True),
    sa.Column('similar_properties_url', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_property_urls_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_property_urls')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_property_urls_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_property_urls_api_property_id'), 'api_property_detail_property_urls', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_property_urls_super_id'), 'api_property_detail_property_urls', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_shared_ownerships',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('ownership_percentage', sa.Numeric(precision=10, scale=4), nullable=True),
    sa.Column('rent_frequency', sa.String(length=100), nullable=True),
    sa.Column('rent_price', sa.Numeric(precision=12, scale=2), nullable=True),
    sa.Column('shared_ownership', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_shared_ownerships_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_shared_ownerships')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_shared_ownerships_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_shared_ownerships_api_property_id'), 'api_property_detail_shared_ownerships', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_shared_ownerships_super_id'), 'api_property_detail_shared_ownerships', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_static_map_img_urls',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('static_map_img_url_desktop_large', sa.Text(), nullable=True),
    sa.Column('static_map_img_url_desktop_small', sa.Text(), nullable=True),
    sa.Column('static_map_img_url_mobile', sa.Text(), nullable=True),
    sa.Column('static_map_img_url_tablet', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_static_map_img_urls_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_static_map_img_urls')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_static_map_img_urls_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_static_map_img_urls_api_property_id'), 'api_property_detail_static_map_img_urls', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_static_map_img_urls_super_id'), 'api_property_detail_static_map_img_urls', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_status',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('archived', sa.Boolean(), nullable=True),
    sa.Column('published', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_status_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_status')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_status_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_status_api_property_id'), 'api_property_detail_status', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_status_super_id'), 'api_property_detail_status', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_street_views',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('heading', sa.Text(), nullable=True),
    sa.Column('latitude', sa.Numeric(precision=10, scale=8), nullable=True),
    sa.Column('longitude', sa.Numeric(precision=11, scale=8), nullable=True),
    sa.Column('pitch', sa.Text(), nullable=True),
    sa.Column('zoom', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_street_views_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_street_views')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_street_views_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_street_views_api_property_id'), 'api_property_detail_street_views', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_street_views_super_id'), 'api_property_detail_street_views', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_tenures',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('message', sa.Text(), nullable=True),
    sa.Column('tenure_type', sa.String(length=100), nullable=True),
    sa.Column('years_remaining_on_lease', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_tenures_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_tenures')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_tenures_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_tenures_api_property_id'), 'api_property_detail_tenures', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_tenures_super_id'), 'api_property_detail_tenures', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_texts',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('auction_fees_disclaimer', sa.Text(), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('disclaimer', sa.Text(), nullable=True),
    sa.Column('guide_price_disclaimer', sa.Text(), nullable=True),
    sa.Column('new_homes_brochure_disclaimer', sa.Text(), nullable=True),
    sa.Column('page_title', sa.Text(), nullable=True),
    sa.Column('property_phrase', sa.String(length=255), nullable=True),
    sa.Column('reserve_price_disclaimer', sa.Text(), nullable=True),
    sa.Column('share_description', sa.Text(), nullable=True),
    sa.Column('share_text', sa.Text(), nullable=True),
    sa.Column('short_description', sa.Text(), nullable=True),
    sa.Column('static_map_disclaimer_text', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['api_property_snapshot_id'], ['rightmove.api_property_details.snapshot_id'], name=op.f('fk_api_property_detail_texts_api_property_snapshot_id_api_property_details'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_texts')),
    sa.UniqueConstraint('api_property_snapshot_id', name=op.f('uq_api_property_detail_texts_api_property_snapshot_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_texts_api_property_id'), 'api_property_detail_texts', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_texts_super_id'), 'api_property_detail_texts', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_brochure_items',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('brochure_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('caption', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['brochure_id'], ['rightmove.api_properties_details_v2_brochure.id'], name=op.f('fk_api_properties_details_v2_brochure_items_brochure_id_api_properties_details_v2_brochure'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_brochure_items')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_brochure_items_api_property_id'), 'api_properties_details_v2_brochure_items', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_brochure_items_api_property_snapshot_id'), 'api_properties_details_v2_brochure_items', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_brochure_items_super_id'), 'api_properties_details_v2_brochure_items', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_feature_obligations',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('feature_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('listed', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('restrictions', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('private_access', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('public_access', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['feature_id'], ['rightmove.api_properties_details_v2_features.id'], name=op.f('fk_api_properties_details_v2_feature_obligations_feature_id_api_properties_details_v2_features'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_feature_obligations')),
    sa.UniqueConstraint('feature_id', name=op.f('uq_api_properties_details_v2_feature_obligations_feature_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_feature_obligations_api_property_snapshot_id'), 'api_properties_details_v2_feature_obligations', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_feature_obligations_super_id'), 'api_properties_details_v2_feature_obligations', ['super_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_feature_obligations_api_property_id'), 'api_properties_details_v2_feature_obligations', ['api_property_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_feature_risks',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('feature_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('flood_history', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('flood_defences', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('flood_risk', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['feature_id'], ['rightmove.api_properties_details_v2_features.id'], name=op.f('fk_api_properties_details_v2_feature_risks_feature_id_api_properties_details_v2_features'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_feature_risks')),
    sa.UniqueConstraint('feature_id', name=op.f('uq_api_properties_details_v2_feature_risks_feature_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_feature_risks_api_property_id'), 'api_properties_details_v2_feature_risks', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_feature_risks_api_property_snapshot_id'), 'api_properties_details_v2_feature_risks', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_feature_risks_super_id'), 'api_properties_details_v2_feature_risks', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_properties_details_v2_location_street_view',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('location_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('latitude', sa.Numeric(precision=10, scale=8), nullable=True),
    sa.Column('longitude', sa.Numeric(precision=11, scale=8), nullable=True),
    sa.Column('heading', sa.Text(), nullable=True),
    sa.Column('pitch', sa.Text(), nullable=True),
    sa.Column('zoom', sa.Text(), nullable=True),
    sa.Column('url', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['location_id'], ['rightmove.api_properties_details_v2_location.id'], name=op.f('fk_api_properties_details_v2_location_street_view_location_id_api_properties_details_v2_location'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_properties_details_v2_location_street_view')),
    sa.UniqueConstraint('location_id', name=op.f('uq_api_properties_details_v2_location_street_view_location_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_location_street_view_api_property_id'), 'api_properties_details_v2_location_street_view', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_location_street_view_super_id'), 'api_properties_details_v2_location_street_view', ['super_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_properties_details_v2_location_street_view_api_property_snapshot_id'), 'api_properties_details_v2_location_street_view', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_contact_info_telephone_numbers',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('contact_info_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('disclaimer_description', sa.Text(), nullable=True),
    sa.Column('disclaimer_text', sa.Text(), nullable=True),
    sa.Column('disclaimer_title', sa.Text(), nullable=True),
    sa.Column('international_number', sa.String(length=50), nullable=True),
    sa.Column('local_number', sa.String(length=50), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['contact_info_id'], ['rightmove.api_property_detail_contact_infos.id'], name=op.f('fk_api_property_detail_contact_info_telephone_numbers_contact_info_id_api_property_detail_contact_infos'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_contact_info_telephone_numbers')),
    sa.UniqueConstraint('contact_info_id', name=op.f('uq_api_property_detail_contact_info_telephone_numbers_contact_info_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_contact_info_telephone_numbers_super_id'), 'api_property_detail_contact_info_telephone_numbers', ['super_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_contact_info_telephone_numbers_api_property_snapshot_id'), 'api_property_detail_contact_info_telephone_numbers', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_contact_info_telephone_numbers_api_property_id'), 'api_property_detail_contact_info_telephone_numbers', ['api_property_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_customer_descriptions',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('customer_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('is_truncated', sa.Boolean(), nullable=True),
    sa.Column('truncated_description_html', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['customer_id'], ['rightmove.api_property_detail_customers.id'], name=op.f('fk_api_property_detail_customer_descriptions_customer_id_api_property_detail_customers'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_customer_descriptions')),
    sa.UniqueConstraint('customer_id', name=op.f('uq_api_property_detail_customer_descriptions_customer_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_descriptions_api_property_snapshot_id'), 'api_property_detail_customer_descriptions', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_descriptions_api_property_id'), 'api_property_detail_customer_descriptions', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_descriptions_super_id'), 'api_property_detail_customer_descriptions', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_customer_development_infos',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('customer_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('site_plan_uri', sa.Text(), nullable=True),
    sa.Column('microsite_features', sa.ARRAY(sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['customer_id'], ['rightmove.api_property_detail_customers.id'], name=op.f('fk_api_property_detail_customer_development_infos_customer_id_api_property_detail_customers'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_customer_development_infos')),
    sa.UniqueConstraint('customer_id', name=op.f('uq_api_property_detail_customer_development_infos_customer_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_development_infos_api_property_snapshot_id'), 'api_property_detail_customer_development_infos', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_development_infos_super_id'), 'api_property_detail_customer_development_infos', ['super_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_development_infos_api_property_id'), 'api_property_detail_customer_development_infos', ['api_property_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_customer_products',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('customer_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('has_microsite', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['customer_id'], ['rightmove.api_property_detail_customers.id'], name=op.f('fk_api_property_detail_customer_products_customer_id_api_property_detail_customers'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_customer_products')),
    sa.UniqueConstraint('customer_id', name=op.f('uq_api_property_detail_customer_products_customer_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_products_api_property_snapshot_id'), 'api_property_detail_customer_products', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_products_api_property_id'), 'api_property_detail_customer_products', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_customer_products_super_id'), 'api_property_detail_customer_products', ['super_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_floorplan_resized_floorplan_urls',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('floorplan_id', sa.Integer(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('size_296x197', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['floorplan_id'], ['rightmove.api_property_detail_floorplans.id'], name=op.f('fk_api_property_detail_floorplan_resized_floorplan_urls_floorplan_id_api_property_detail_floorplans'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_floorplan_resized_floorplan_urls')),
    sa.UniqueConstraint('floorplan_id', name=op.f('uq_api_property_detail_floorplan_resized_floorplan_urls_floorplan_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_floorplan_resized_floorplan_urls_super_id'), 'api_property_detail_floorplan_resized_floorplan_urls', ['super_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_floorplan_resized_floorplan_urls_api_property_snapshot_id'), 'api_property_detail_floorplan_resized_floorplan_urls', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_floorplan_resized_floorplan_urls_api_property_id'), 'api_property_detail_floorplan_resized_floorplan_urls', ['api_property_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_image_resized_image_urls',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('image_id', sa.Integer(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('size_135x100', sa.Text(), nullable=True),
    sa.Column('size_476x317', sa.Text(), nullable=True),
    sa.Column('size_656x437', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['image_id'], ['rightmove.api_property_detail_images.id'], name=op.f('fk_api_property_detail_image_resized_image_urls_image_id_api_property_detail_images'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_image_resized_image_urls')),
    sa.UniqueConstraint('image_id', name=op.f('uq_api_property_detail_image_resized_image_urls_image_id')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_image_resized_image_urls_api_property_snapshot_id'), 'api_property_detail_image_resized_image_urls', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_image_resized_image_urls_super_id'), 'api_property_detail_image_resized_image_urls', ['super_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_image_resized_image_urls_api_property_id'), 'api_property_detail_image_resized_image_urls', ['api_property_id'], unique=False, schema='rightmove')
    op.create_table('api_property_detail_nearest_station_types',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('station_id', sa.Integer(), nullable=False),
    sa.Column('api_property_snapshot_id', sa.BigInteger(), nullable=False),
    sa.Column('api_property_id', sa.BigInteger(), nullable=False),
    sa.Column('type', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('super_id', sa.UUID(), nullable=False),
    sa.ForeignKeyConstraint(['station_id'], ['rightmove.api_property_detail_nearest_stations.id'], name=op.f('fk_api_property_detail_nearest_station_types_station_id_api_property_detail_nearest_stations'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_api_property_detail_nearest_station_types')),
    schema='rightmove'
    )
    op.create_index(op.f('ix_rightmove_api_property_detail_nearest_station_types_api_property_snapshot_id'), 'api_property_detail_nearest_station_types', ['api_property_snapshot_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_nearest_station_types_api_property_id'), 'api_property_detail_nearest_station_types', ['api_property_id'], unique=False, schema='rightmove')
    op.create_index(op.f('ix_rightmove_api_property_detail_nearest_station_types_super_id'), 'api_property_detail_nearest_station_types', ['super_id'], unique=False, schema='rightmove')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_rightmove_api_property_detail_nearest_station_types_super_id'), table_name='api_property_detail_nearest_station_types', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_nearest_station_types_api_property_id'), table_name='api_property_detail_nearest_station_types', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_nearest_station_types_api_property_snapshot_id'), table_name='api_property_detail_nearest_station_types', schema='rightmove')
    op.drop_table('api_property_detail_nearest_station_types', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_image_resized_image_urls_api_property_id'), table_name='api_property_detail_image_resized_image_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_image_resized_image_urls_super_id'), table_name='api_property_detail_image_resized_image_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_image_resized_image_urls_api_property_snapshot_id'), table_name='api_property_detail_image_resized_image_urls', schema='rightmove')
    op.drop_table('api_property_detail_image_resized_image_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_floorplan_resized_floorplan_urls_api_property_id'), table_name='api_property_detail_floorplan_resized_floorplan_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_floorplan_resized_floorplan_urls_api_property_snapshot_id'), table_name='api_property_detail_floorplan_resized_floorplan_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_floorplan_resized_floorplan_urls_super_id'), table_name='api_property_detail_floorplan_resized_floorplan_urls', schema='rightmove')
    op.drop_table('api_property_detail_floorplan_resized_floorplan_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_products_super_id'), table_name='api_property_detail_customer_products', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_products_api_property_id'), table_name='api_property_detail_customer_products', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_products_api_property_snapshot_id'), table_name='api_property_detail_customer_products', schema='rightmove')
    op.drop_table('api_property_detail_customer_products', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_development_infos_api_property_id'), table_name='api_property_detail_customer_development_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_development_infos_super_id'), table_name='api_property_detail_customer_development_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_development_infos_api_property_snapshot_id'), table_name='api_property_detail_customer_development_infos', schema='rightmove')
    op.drop_table('api_property_detail_customer_development_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_descriptions_super_id'), table_name='api_property_detail_customer_descriptions', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_descriptions_api_property_id'), table_name='api_property_detail_customer_descriptions', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customer_descriptions_api_property_snapshot_id'), table_name='api_property_detail_customer_descriptions', schema='rightmove')
    op.drop_table('api_property_detail_customer_descriptions', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_contact_info_telephone_numbers_api_property_id'), table_name='api_property_detail_contact_info_telephone_numbers', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_contact_info_telephone_numbers_api_property_snapshot_id'), table_name='api_property_detail_contact_info_telephone_numbers', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_contact_info_telephone_numbers_super_id'), table_name='api_property_detail_contact_info_telephone_numbers', schema='rightmove')
    op.drop_table('api_property_detail_contact_info_telephone_numbers', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_location_street_view_api_property_snapshot_id'), table_name='api_properties_details_v2_location_street_view', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_location_street_view_super_id'), table_name='api_properties_details_v2_location_street_view', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_location_street_view_api_property_id'), table_name='api_properties_details_v2_location_street_view', schema='rightmove')
    op.drop_table('api_properties_details_v2_location_street_view', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_feature_risks_super_id'), table_name='api_properties_details_v2_feature_risks', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_feature_risks_api_property_snapshot_id'), table_name='api_properties_details_v2_feature_risks', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_feature_risks_api_property_id'), table_name='api_properties_details_v2_feature_risks', schema='rightmove')
    op.drop_table('api_properties_details_v2_feature_risks', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_feature_obligations_api_property_id'), table_name='api_properties_details_v2_feature_obligations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_feature_obligations_super_id'), table_name='api_properties_details_v2_feature_obligations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_feature_obligations_api_property_snapshot_id'), table_name='api_properties_details_v2_feature_obligations', schema='rightmove')
    op.drop_table('api_properties_details_v2_feature_obligations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_brochure_items_super_id'), table_name='api_properties_details_v2_brochure_items', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_brochure_items_api_property_snapshot_id'), table_name='api_properties_details_v2_brochure_items', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_brochure_items_api_property_id'), table_name='api_properties_details_v2_brochure_items', schema='rightmove')
    op.drop_table('api_properties_details_v2_brochure_items', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_texts_super_id'), table_name='api_property_detail_texts', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_texts_api_property_id'), table_name='api_property_detail_texts', schema='rightmove')
    op.drop_table('api_property_detail_texts', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_tenures_super_id'), table_name='api_property_detail_tenures', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_tenures_api_property_id'), table_name='api_property_detail_tenures', schema='rightmove')
    op.drop_table('api_property_detail_tenures', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_street_views_super_id'), table_name='api_property_detail_street_views', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_street_views_api_property_id'), table_name='api_property_detail_street_views', schema='rightmove')
    op.drop_table('api_property_detail_street_views', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_status_super_id'), table_name='api_property_detail_status', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_status_api_property_id'), table_name='api_property_detail_status', schema='rightmove')
    op.drop_table('api_property_detail_status', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_static_map_img_urls_super_id'), table_name='api_property_detail_static_map_img_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_static_map_img_urls_api_property_id'), table_name='api_property_detail_static_map_img_urls', schema='rightmove')
    op.drop_table('api_property_detail_static_map_img_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_shared_ownerships_super_id'), table_name='api_property_detail_shared_ownerships', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_shared_ownerships_api_property_id'), table_name='api_property_detail_shared_ownerships', schema='rightmove')
    op.drop_table('api_property_detail_shared_ownerships', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_property_urls_super_id'), table_name='api_property_detail_property_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_property_urls_api_property_id'), table_name='api_property_detail_property_urls', schema='rightmove')
    op.drop_table('api_property_detail_property_urls', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_prices_super_id'), table_name='api_property_detail_prices', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_prices_api_property_id'), table_name='api_property_detail_prices', schema='rightmove')
    op.drop_table('api_property_detail_prices', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_nearest_stations_super_id'), table_name='api_property_detail_nearest_stations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_nearest_stations_api_property_id'), table_name='api_property_detail_nearest_stations', schema='rightmove')
    op.drop_table('api_property_detail_nearest_stations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_mortgage_calculators_super_id'), table_name='api_property_detail_mortgage_calculators', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_mortgage_calculators_api_property_id'), table_name='api_property_detail_mortgage_calculators', schema='rightmove')
    op.drop_table('api_property_detail_mortgage_calculators', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_mis_infos_super_id'), table_name='api_property_detail_mis_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_mis_infos_api_property_id'), table_name='api_property_detail_mis_infos', schema='rightmove')
    op.drop_table('api_property_detail_mis_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_locations_super_id'), table_name='api_property_detail_locations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_locations_api_property_id'), table_name='api_property_detail_locations', schema='rightmove')
    op.drop_table('api_property_detail_locations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_living_costs_super_id'), table_name='api_property_detail_living_costs', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_living_costs_api_property_id'), table_name='api_property_detail_living_costs', schema='rightmove')
    op.drop_table('api_property_detail_living_costs', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_listing_history_super_id'), table_name='api_property_detail_listing_history', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_listing_history_api_property_id'), table_name='api_property_detail_listing_history', schema='rightmove')
    op.drop_table('api_property_detail_listing_history', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_info_reel_items_super_id'), table_name='api_property_detail_info_reel_items', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_info_reel_items_api_property_id'), table_name='api_property_detail_info_reel_items', schema='rightmove')
    op.drop_table('api_property_detail_info_reel_items', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_industry_affiliations_super_id'), table_name='api_property_detail_industry_affiliations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_industry_affiliations_api_property_id'), table_name='api_property_detail_industry_affiliations', schema='rightmove')
    op.drop_table('api_property_detail_industry_affiliations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_images_super_id'), table_name='api_property_detail_images', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_images_api_property_id'), table_name='api_property_detail_images', schema='rightmove')
    op.drop_table('api_property_detail_images', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_floorplans_super_id'), table_name='api_property_detail_floorplans', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_floorplans_api_property_id'), table_name='api_property_detail_floorplans', schema='rightmove')
    op.drop_table('api_property_detail_floorplans', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_dfp_ad_infos_super_id'), table_name='api_property_detail_dfp_ad_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_dfp_ad_infos_api_property_id'), table_name='api_property_detail_dfp_ad_infos', schema='rightmove')
    op.drop_table('api_property_detail_dfp_ad_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customers_super_id'), table_name='api_property_detail_customers', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_customers_api_property_id'), table_name='api_property_detail_customers', schema='rightmove')
    op.drop_table('api_property_detail_customers', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_contact_infos_super_id'), table_name='api_property_detail_contact_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_contact_infos_api_property_id'), table_name='api_property_detail_contact_infos', schema='rightmove')
    op.drop_table('api_property_detail_contact_infos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_broadbands_super_id'), table_name='api_property_detail_broadbands', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_broadbands_api_property_id'), table_name='api_property_detail_broadbands', schema='rightmove')
    op.drop_table('api_property_detail_broadbands', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_addresses_super_id'), table_name='api_property_detail_addresses', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_detail_addresses_api_property_id'), table_name='api_property_detail_addresses', schema='rightmove')
    op.drop_table('api_property_detail_addresses', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_status_super_id'), table_name='api_properties_details_v2_status', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_status_api_property_id'), table_name='api_properties_details_v2_status', schema='rightmove')
    op.drop_table('api_properties_details_v2_status', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_stations_super_id'), table_name='api_properties_details_v2_stations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_stations_api_property_id'), table_name='api_properties_details_v2_stations', schema='rightmove')
    op.drop_table('api_properties_details_v2_stations', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_stamp_duty_super_id'), table_name='api_properties_details_v2_stamp_duty', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_stamp_duty_api_property_id'), table_name='api_properties_details_v2_stamp_duty', schema='rightmove')
    op.drop_table('api_properties_details_v2_stamp_duty', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_size_super_id'), table_name='api_properties_details_v2_size', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_size_api_property_id'), table_name='api_properties_details_v2_size', schema='rightmove')
    op.drop_table('api_properties_details_v2_size', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_sales_info_super_id'), table_name='api_properties_details_v2_sales_info', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_sales_info_api_property_id'), table_name='api_properties_details_v2_sales_info', schema='rightmove')
    op.drop_table('api_properties_details_v2_sales_info', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_price_super_id'), table_name='api_properties_details_v2_price', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_price_api_property_id'), table_name='api_properties_details_v2_price', schema='rightmove')
    op.drop_table('api_properties_details_v2_price', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_photos_super_id'), table_name='api_properties_details_v2_photos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_photos_api_property_id'), table_name='api_properties_details_v2_photos', schema='rightmove')
    op.drop_table('api_properties_details_v2_photos', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_mortgage_super_id'), table_name='api_properties_details_v2_mortgage', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_mortgage_api_property_id'), table_name='api_properties_details_v2_mortgage', schema='rightmove')
    op.drop_table('api_properties_details_v2_mortgage', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_mis_info_super_id'), table_name='api_properties_details_v2_mis_info', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_mis_info_api_property_id'), table_name='api_properties_details_v2_mis_info', schema='rightmove')
    op.drop_table('api_properties_details_v2_mis_info', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_location_super_id'), table_name='api_properties_details_v2_location', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_location_api_property_id'), table_name='api_properties_details_v2_location', schema='rightmove')
    op.drop_table('api_properties_details_v2_location', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_local_tax_super_id'), table_name='api_properties_details_v2_local_tax', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_local_tax_api_property_id'), table_name='api_properties_details_v2_local_tax', schema='rightmove')
    op.drop_table('api_properties_details_v2_local_tax', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_floorplans_super_id'), table_name='api_properties_details_v2_floorplans', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_floorplans_api_property_id'), table_name='api_properties_details_v2_floorplans', schema='rightmove')
    op.drop_table('api_properties_details_v2_floorplans', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_features_super_id'), table_name='api_properties_details_v2_features', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_features_api_property_id'), table_name='api_properties_details_v2_features', schema='rightmove')
    op.drop_table('api_properties_details_v2_features', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_epcs_super_id'), table_name='api_properties_details_v2_epcs', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_epcs_api_property_id'), table_name='api_properties_details_v2_epcs', schema='rightmove')
    op.drop_table('api_properties_details_v2_epcs', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_brochure_super_id'), table_name='api_properties_details_v2_brochure', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_brochure_api_property_id'), table_name='api_properties_details_v2_brochure', schema='rightmove')
    op.drop_table('api_properties_details_v2_brochure', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_branch_super_id'), table_name='api_properties_details_v2_branch', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_branch_api_property_id'), table_name='api_properties_details_v2_branch', schema='rightmove')
    op.drop_table('api_properties_details_v2_branch', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_analytics_info_super_id'), table_name='api_properties_details_v2_analytics_info', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_analytics_info_api_property_id'), table_name='api_properties_details_v2_analytics_info', schema='rightmove')
    op.drop_table('api_properties_details_v2_analytics_info', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_scrape_events_super_id'), table_name='scrape_events', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_scrape_events_rightmove_property_id'), table_name='scrape_events', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_scrape_events_event_type'), table_name='scrape_events', schema='rightmove')
    op.drop_table('scrape_events', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_details_super_id'), table_name='api_property_details', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_property_details_id'), table_name='api_property_details', schema='rightmove')
    op.drop_table('api_property_details', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_super_id'), table_name='api_properties_details_v2', schema='rightmove')
    op.drop_index(op.f('ix_rightmove_api_properties_details_v2_id'), table_name='api_properties_details_v2', schema='rightmove')
    op.drop_table('api_properties_details_v2', schema='rightmove')
    # ### end Alembic commands ###


# data_capture_rightmove_service/src/__init__.py


# data_capture_rightmove_service/src/data_capture_rightmove_service/db.py
from typing import AsyncGenerator

import sqlalchemy.util.concurrency as _concurrency

_concurrency._not_implemented = lambda *args, **kwargs: None

from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.ext.asyncio import (
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)
from sqlalchemy.orm import declarative_base
from sqlalchemy.pool import NullPool

from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.utils.logging_config import logger

# --- 1. Centralized Configuration Access ---
DATABASE_URL = settings.DATABASE_URL

# --- 2. Optimized Engine Configuration ---
# All engine and pool settings are consolidated here for clarity.
# These settings are chosen for a balance of performance and resilience,
# especially in a containerized environment like Docker or Kubernetes.

# Adjust configuration for cloud vs. local database
is_cloud_db = "supabase.com" in DATABASE_URL
logger.info(f"Initializing database connection with psycopg3 driver: {DATABASE_URL}")
logger.info(f"Database type detected: {'Cloud' if is_cloud_db else 'Local'}")

# Setup cloud-optimized connection arguments
connect_args = {
    "application_name": "data_capture_rightmove_service",
    # For psycopg v3, we use options parameter instead of server_settings
    "options": "-c timezone=UTC"
    + (
        "" if settings.ENVIRONMENT == "testing" else " -c statement_timeout=30000"
    ),  # Increased timeout for cloud
    # --- BEGIN FIX ---
    # Disable the driver's implicit prepared statement cache. This is the recommended
    # setting when using a transaction-pooling connection pooler like PgBouncer.
    # It prevents "prepared statement already exists" errors on reused connections.
    "prepare_threshold": None,
    # --- END FIX ---
}

# Add SSL settings for cloud databases
if is_cloud_db:
    connect_args.update(
        {
            "sslmode": "require",
        }
    )

    # Reduced pool size for cloud connections to prevent connection saturation
    pool_size = 5
    max_overflow = 10
    pool_recycle = 300  # More aggressive connection recycling for cloud
    pool_timeout = 60  # Longer timeout for cloud connections
else:
    # Local database can have more generous settings
    pool_size = 10
    max_overflow = 20
    pool_recycle = 1800
    pool_timeout = 30

engine: AsyncEngine = create_async_engine(
    DATABASE_URL,
    # Log SQL statements in DEBUG mode only
    echo=settings.LOGGING_LEVEL.upper() == "DEBUG",
    # --- CRITICAL OPTIMIZATION ---
    # This is the most important setting for resilience. It runs a simple 'SELECT 1'
    # on a connection before it's checked out from the pool. If the connection is dead,
    # it's discarded and a new one is established. This eliminates most connection errors.
    pool_pre_ping=True,  # Helps with connection resilience
    poolclass=NullPool,  # Recommended for serverless/async environments
    # Connection arguments passed directly to the psycopg v3 driver
    connect_args=connect_args,
)

# --- 3. Standard Session Factory ---
AsyncSessionLocal = async_sessionmaker(
    bind=engine,
    class_=AsyncSession,
    autocommit=False,
    autoflush=False,
    expire_on_commit=False,
)

# --- 4. Declarative Base ---
# All SQLAlchemy models will inherit from this Base.
Base = declarative_base()
Base.metadata.schema = "rightmove"


# --- 5. Simplified and Robust Session Dependency ---
async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """
    FastAPI dependency that provides a transactional, auto-closing database session.

    This standard pattern ensures that:
    1. A new session is created for each request.
    2. The session is always closed, preventing connection leaks.
    3. Any database errors during the request cause a rollback, ensuring data integrity.
    """
    session = AsyncSessionLocal()
    try:
        # Yield the session to the route handler.
        yield session
        # If the route handler finishes without errors, commit the transaction.
        await session.commit()
    except SQLAlchemyError as e:
        # If a database-related error occurs, roll back all changes.
        logger.error(f"Database transaction failed: {e}", exc_info=True)
        await session.rollback()
        # Re-raise the exception to be handled by FastAPI's error handlers.
        raise
    finally:
        # Always close the session to release the connection back to the pool.
        await session.close()


# data_capture_rightmove_service/src/data_capture_rightmove_service/config.py
"""
Configuration module for the Data Capture Rightmove Service.
"""

import os
from enum import Enum
from typing import Any, List, Optional

from pydantic import Field, field_validator
from pydantic_settings import BaseSettings, SettingsConfigDict


class Environment(str, Enum):
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"


class Settings(BaseSettings):
    """
    Settings for the Data Capture Rightmove Service.
    Loads environment variables, with fallbacks to default values where appropriate.
    All environment variables are prefixed with DATA_CAPTURE_RIGHTMOVE_SERVICE_.
    """

    # Core service settings
    ENVIRONMENT: Environment = Field(
        Environment.DEVELOPMENT,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_ENVIRONMENT",
        description="Application environment",
    )
    ROOT_PATH: str = Field(
        "/api/v1",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_ROOT_PATH",
        description="API root path for reverse proxies",
    )
    LOGGING_LEVEL: str = Field(
        "INFO",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_LOGGING_LEVEL",
        description="Logging level",
    )

    # Database configuration
    DATABASE_URL: str = Field(
        ...,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL",
        description="PostgreSQL connection string",
    )

    SUPABASE_URL: str = Field(..., alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_URL")
    SUPABASE_ANON_KEY: str = Field(
        ..., alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_ANON_KEY"
    )
    SUPABASE_SERVICE_ROLE_KEY: str = Field(
        ..., alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPABASE_SERVICE_ROLE_KEY"
    )

    # Auth Service connection
    AUTH_SERVICE_URL: str = Field(
        "http://auth_service:8000/api/v1",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_AUTH_SERVICE_URL",
        description="Auth Service URL for token acquisition",
    )

    # Super ID Service connection
    SUPER_ID_SERVICE_URL: str = Field(
        "http://super_id_service:8000/api/v1",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_SUPER_ID_SERVICE_URL",
        description="Super ID Service URL for UUID generation",
    )

    # JWT configuration for auth with other services
    M2M_CLIENT_ID: str = Field(
        ...,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_ID",
        description="Client ID for machine-to-machine authentication",
    )
    M2M_CLIENT_SECRET: str = Field(
        ...,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_M2M_CLIENT_SECRET",
        description="Client Secret for machine-to-machine authentication",
    )

    # RapidAPI configuration
    RAPID_API_KEY: str = Field(
        ...,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_KEY",
        description="RapidAPI key for accessing Rightmove API",
    )
    RAPID_API_HOST: str = Field(
        "uk-real-estate-rightmove.p.rapidapi.com",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_RAPID_API_HOST",
        description="RapidAPI host for Rightmove API",
    )

    # Rate limiting
    RATE_LIMIT_REQUESTS_PER_MINUTE: int = Field(
        30,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_RATE_LIMIT_REQUESTS_PER_MINUTE",
        description="Rate limit for API requests per minute",
    )

    # Redis configuration (for rate limiting and caching)
    REDIS_URL: str = Field(
        "redis://localhost:6379/0",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_REDIS_URL",
        description="Redis URL for caching and rate limiting",
    )

    # CORS settings
    CORS_ALLOW_ORIGINS: List[str] = Field(
        default_factory=lambda: ["*"],
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_CORS_ALLOW_ORIGINS",
        description="List of origins that are allowed to make cross-origin requests",
    )

    # Rightmove API endpoints
    RIGHTMOVE_API_PROPERTIES_DETAILS_ENDPOINT: str = Field(
        "/properties/details",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTIES_DETAILS_ENDPOINT",
        description="Rightmove API endpoint for property details",
    )
    RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT: str = Field(
        "/buy/property-for-sale",
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT",
        description="Rightmove API endpoint for property for sale",
    )

    # Data fetch configuration
    BATCH_SIZE: int = Field(
        10,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_BATCH_SIZE",
        description="Number of properties to fetch in a batch",
    )
    FETCH_INTERVAL_SECONDS: int = Field(
        3600,
        alias="DATA_CAPTURE_RIGHTMOVE_SERVICE_FETCH_INTERVAL_SECONDS",
        description="Interval between data fetch operations in seconds",
    )

    @field_validator("DATABASE_URL")
    def validate_database_url(cls, v: str, info: Any) -> str:
        # Add any database URL validation logic here if needed
        return v

    def is_production(self) -> bool:
        return self.ENVIRONMENT == Environment.PRODUCTION

    def is_development(self) -> bool:
        return self.ENVIRONMENT == Environment.DEVELOPMENT

    def is_testing(self) -> bool:
        return self.ENVIRONMENT == Environment.TESTING

    model_config = SettingsConfigDict(
        env_file=".env", env_file_encoding="utf-8", case_sensitive=False, extra="ignore"
    )


# Create a global instance of the settings
settings = Settings()


# data_capture_rightmove_service/src/data_capture_rightmove_service/__init__.py


# data_capture_rightmove_service/src/data_capture_rightmove_service/supabase_client.py
import asyncio

from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.utils.logging_config import logger
from supabase._async.client import AsyncClient as AsyncSupabaseClient
from supabase._async.client import create_client as create_async_supabase_client

# Global instances for both clients
_global_async_supabase_client: AsyncSupabaseClient | None = None
_global_admin_supabase_client: AsyncSupabaseClient | None = None


async def init_supabase_clients():
    """
    Initializes the global Supabase clients.
    This function should be called once at application startup.
    """
    global _global_async_supabase_client, _global_admin_supabase_client

    if _global_async_supabase_client and _global_admin_supabase_client:
        logger.info("Supabase clients already initialized.")
        return

    url = settings.SUPABASE_URL
    anon_key = settings.SUPABASE_ANON_KEY
    service_key = settings.SUPABASE_SERVICE_ROLE_KEY

    if not all([url, anon_key, service_key]):
        logger.error("Supabase URL, Anon Key, or Service Role Key is not configured.")
        raise ValueError("Supabase configuration is incomplete.")

    # --- Initialize Regular Client (with anon key) ---
    logger.info(f"Initializing Supabase AsyncClient with URL: {url[:20]}...")
    try:
        _global_async_supabase_client = await create_async_supabase_client(
            url, anon_key
        )
        logger.info("Supabase AsyncClient initialized successfully.")
    except Exception as e:
        logger.error(f"Failed to initialize Supabase client: {e}", exc_info=True)
        _global_async_supabase_client = None
        raise

    # --- Initialize Admin Client (with service role key) ---
    logger.info("Initializing Supabase Admin Client...")
    try:
        _global_admin_supabase_client = await create_async_supabase_client(
            url, service_key
        )
        logger.info("Supabase Admin Client initialized successfully.")
    except Exception as e:
        logger.error(f"Failed to initialize Supabase Admin client: {e}", exc_info=True)
        _global_admin_supabase_client = None
        raise


async def close_supabase_clients():
    """
    Closes the global Supabase clients by clearing the references.
    This function should be called once at application shutdown.
    """
    global _global_async_supabase_client, _global_admin_supabase_client
    if _global_async_supabase_client or _global_admin_supabase_client:
        logger.info("Closing Supabase clients...")
        _global_async_supabase_client = None
        _global_admin_supabase_client = None
        logger.info("Supabase client references cleared.")


def get_supabase_client() -> AsyncSupabaseClient:
    """
    FastAPI dependency to get the globally initialized anonymous Supabase client.
    """
    if _global_async_supabase_client is None:
        logger.error("Supabase client accessed before initialization.")
        raise RuntimeError("Supabase client not available. Check application lifespan.")
    return _global_async_supabase_client


def get_supabase_admin_client() -> AsyncSupabaseClient:
    """
    FastAPI dependency to get the globally initialized admin (service_role) Supabase client.
    """
    if _global_admin_supabase_client is None:
        logger.error("Supabase admin client accessed before initialization.")
        raise RuntimeError(
            "Supabase admin client not available. Check application lifespan."
        )
    return _global_admin_supabase_client


# data_capture_rightmove_service/src/data_capture_rightmove_service/main.py
"""
Main application entry point for the Data Capture Rightmove Service.
"""

import time
from contextlib import asynccontextmanager

from fastapi import Depends, FastAPI, HTTPException, Request
from fastapi.exceptions import RequestValidationError
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from slowapi import _rate_limit_exceeded_handler
from slowapi.errors import RateLimitExceeded
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.routers.health_router import router as health_router
from data_capture_rightmove_service.routers.property_router import (
    router as property_router,
)
from data_capture_rightmove_service.supabase_client import init_supabase_clients
from data_capture_rightmove_service.utils.logging_config import (
    configure_logging,
    logger,
)
from data_capture_rightmove_service.utils.rate_limiting import limiter
from data_capture_rightmove_service.utils.security import validate_token

# Configure logging using our custom configuration
configure_logging()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Application lifecycle manager with robust initialization and shutdown.

    Handles startup and shutdown sequences with proper error handling.
    """
    logger.info("Application startup sequence initiated.")

    # Initialize app-wide resources and connections
    try:
        await init_supabase_clients()
        logger.info("Supabase clients initialized successfully")
    except Exception as e:
        logger.error(
            f"Failed to initialize Supabase clients: {e.__class__.__name__}: {str(e)}"
        )

    # Initialize startup timestamp for health checks
    app.state.startup_time = time.time()
    logger.info("Application startup complete.")

    # Yield control back to the application
    yield

    # Application Shutdown
    logger.info("Application shutdown sequence initiated.")
    logger.info("Application shutdown complete.")


# Initialize FastAPI app with lifespan
app = FastAPI(
    title="Data Capture Rightmove Service",
    description=(
        "Service for fetching property data from Rightmove via RapidAPI "
        "and storing it in a structured database."
    ),
    version="0.1.0",
    root_path=settings.ROOT_PATH,
    lifespan=lifespan,
)


# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ALLOW_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Add rate limiter middleware
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)


# Include routers
app.include_router(health_router, tags=["Health"])
app.include_router(property_router, tags=["Properties"])


# Add exception handlers
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """Custom HTTP exception handler for consistent error responses."""
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail, "error_type": "HTTPException"},
    )


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Validation exception handler for consistent error responses."""
    return JSONResponse(
        status_code=422,
        content={"detail": str(exc), "error_type": "ValidationError"},
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Global exception handler for consistent error responses."""
    logger.error(f"Unhandled exception: {str(exc)}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "detail": "Internal server error.",
            "error_type": str(type(exc).__name__),
        },
    )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "data_capture_rightmove_service.main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.is_development(),
        log_level=settings.LOGGING_LEVEL.lower(),
    )


# data_capture_rightmove_service/src/data_capture_rightmove_service/routers/__init__.py
"""
API routers for the Data Capture Rightmove Service.
"""

from data_capture_rightmove_service.routers.health_router import router as health_router
from data_capture_rightmove_service.routers.property_router import router as property_router

__all__ = ['health_router', 'property_router']


# data_capture_rightmove_service/src/data_capture_rightmove_service/routers/property_router.py
"""
Router for property data operations, including fetching from Rightmove API and storing in database.
"""

import asyncio
import uuid
from typing import Dict, List, Optional

import httpx
from fastapi import (
    APIRouter,
    BackgroundTasks,
    Depends,
    HTTPException,
    Query,
    Request,
    Security,
)
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
from pydantic import BaseModel, Field
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.clients.rightmove_api_client import (
    rightmove_api_client,
)
from data_capture_rightmove_service.clients.super_id_service_client import (
    super_id_service_client,
)
from data_capture_rightmove_service.crud import event_crud
from data_capture_rightmove_service.crud.properties_details import (
    get_all_property_ids,
    get_property_details_by_id,
    store_properties_details,
)
from data_capture_rightmove_service.crud.property_details import (
    get_all_property_sale_ids,
    get_property_sale_details_by_id,
    store_property_details,
)
from data_capture_rightmove_service.db import AsyncSessionLocal, get_db
from data_capture_rightmove_service.models.scrape_event import ScrapeEventTypeEnum
from data_capture_rightmove_service.schemas.common import MessageResponse
from data_capture_rightmove_service.schemas.property_data import (
    FetchBatchRequest,
    FetchBatchResponse,
    FetchPropertyDetailsRequest,
    FetchPropertyResponse,
    PropertyDetailsStorageResponse,
    PropertySearchRequest,
)
from data_capture_rightmove_service.utils.data_completeness import analyze_response
from data_capture_rightmove_service.utils.logging_config import logger
from data_capture_rightmove_service.utils.security import requires_scope, validate_token
from data_capture_rightmove_service.utils.url_parsing import (
    extract_rightmove_property_id,
    is_valid_rightmove_url,
)

router = APIRouter(prefix="/properties", tags=["Properties"])


class PropertyUrlResponse(BaseModel):
    """Response for property URL validation and extraction"""

    url: str = Field(..., description="The URL that was checked")
    valid: bool = Field(..., description="Whether the URL is valid")
    property_id: Optional[int] = Field(
        None, description="Extracted property ID if valid"
    )
    message: str = Field(..., description="Message describing the result")


class CombinedPropertyResponseItem(BaseModel):
    """Response item for a single API call in the combined fetch endpoint"""

    api_endpoint: str = Field(..., description="The API endpoint that was called")
    property_id: int = Field(..., description="The property ID")
    super_id: uuid.UUID = Field(..., description="Super ID for tracking purposes")
    stored: bool = Field(..., description="Whether the data was stored successfully")
    message: str = Field(..., description="Success or error message")


class CombinedPropertyResponse(BaseModel):
    """Response for the combined fetch endpoint"""

    property_id: int = Field(..., description="The property ID")
    property_url: Optional[str] = Field(
        None, description="The property URL if provided"
    )
    results: List[CombinedPropertyResponseItem] = Field(
        ..., description="Results from each API call"
    )


@router.post("/fetch/combined", response_model=CombinedPropertyResponse)
async def fetch_combined_property_data(
    request: FetchPropertyDetailsRequest,
    db: AsyncSession = Depends(get_db),
) -> CombinedPropertyResponse:
    """
    Combined endpoint to fetch data from multiple Rightmove API endpoints and store in database.

    This endpoint orchestrates calls to two Rightmove API endpoints and handles the storage
    of their responses in the database. It provides a comprehensive response with details
    from both API calls, including success/failure status for each step in the process.

    Args:
        request: Property details request containing URL or ID and optional super_id
        db: Database session from dependency injection

    Returns:
        CombinedPropertyResponse with results from each endpoint

    Raises:
        HTTPException: If the property ID cannot be determined or other critical errors occur
    """
    # Extract and validate the property ID from URL or direct ID input
    try:
        # Try to extract property ID from URL if provided, otherwise use direct property_id
        extracted_id = (
            extract_rightmove_property_id(request.property_url)
            if request.property_url
            else None
        )
        if not extracted_id and not request.property_id:
            raise HTTPException(
                status_code=400,
                detail="Either a valid Rightmove property URL or property ID must be provided",
            )

        property_id = int(extracted_id or request.property_id)
        logger.info(
            f"Processing property ID: {property_id} from URL: {request.property_url}"
        )
    except (ValueError, TypeError) as e:
        logger.error(f"Failed to parse property ID: {str(e)}")
        raise HTTPException(
            status_code=400, detail=f"Invalid property ID format: {str(e)}"
        )

    # Obtain or use provided super_id for tracking this request chain
    try:
        if request.super_id:
            super_id = request.super_id
            logger.info(
                f"Using provided Super ID: {super_id} for property ID: {property_id}"
            )
        else:
            super_id = await super_id_service_client.create_super_id(
                description=f"Rightmove data capture for property ID: {property_id}"
            )
            logger.info(
                f"Generated Super ID: {super_id} for property ID: {property_id}"
            )
    except HTTPException as e:
        # If super_id service is unavailable, raise the exception to the client
        logger.error(f"Super ID service error: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail=f"Super ID service is required but unavailable: {str(e)}",
        )

    # Log the initial request event
    try:
        await event_crud.log_scrape_event(
            db,
            super_id,
            ScrapeEventTypeEnum.REQUEST_RECEIVED,
            rightmove_property_id=property_id,
            payload=request.model_dump(mode="json"),
        )
    except Exception as e:
        logger.error(f"Failed to log initial request event: {str(e)}")
        # Explicitly roll back transaction to prevent PendingRollbackError
        try:
            await db.rollback()
            logger.info("Rolled back transaction after failed event logging")
        except Exception as rollback_error:
            logger.error(f"Failed to roll back transaction: {str(rollback_error)}")
        # Continue with processing even if logging fails

    results = []

    # Define the endpoints to call and their respective storage functions
    endpoints = {
        "properties/details": (
            rightmove_api_client.get_property_details,
            store_properties_details,
        ),
        "buy/property-for-sale/detail": (
            rightmove_api_client.get_property_for_sale_details,
            store_property_details,
        ),
    }

    for endpoint, (api_call, store_func) in endpoints.items():
        raw_data = None
        stored_successfully = False
        message = ""

        # Step 1: Log API call attempt
        try:
            logger.info(
                f"Calling Rightmove API endpoint: {endpoint} for property ID: {property_id}"
            )
            await event_crud.log_scrape_event(
                db,
                super_id,
                ScrapeEventTypeEnum.API_CALL_ATTEMPT,
                rightmove_property_id=property_id,
                api_endpoint_called=endpoint,
            )
        except Exception as e:
            logger.error(f"Failed to log API call attempt: {str(e)}")
            # Roll back transaction to prevent PendingRollbackError
            try:
                await db.rollback()
                logger.info(
                    f"Rolled back transaction after failed API call attempt logging"
                )
            except Exception as rollback_error:
                logger.error(f"Failed to roll back transaction: {str(rollback_error)}")
            # Continue with API call even if logging fails

        # Step 2: Make API call
        try:
            raw_data = await api_call(str(property_id))

            # Log successful API call
            if raw_data:
                # Analyze the response for data completeness
                item_count, null_count = analyze_response(raw_data)
                logger.info(
                    f"Received data from {endpoint}: {item_count} items, {null_count} null values"
                )

                # Log successful API call
                try:
                    await event_crud.log_scrape_event(
                        db,
                        super_id,
                        ScrapeEventTypeEnum.API_CALL_SUCCESS,
                        rightmove_property_id=property_id,
                        api_endpoint_called=endpoint,
                        http_status_code=200,
                        payload=raw_data,
                        response_item_count=item_count,
                        response_null_item_count=null_count,
                    )
                except Exception as e:
                    logger.error(f"Failed to log API success: {str(e)}")
                    # Roll back transaction to prevent PendingRollbackError
                    try:
                        await db.rollback()
                    except Exception as rollback_error:
                        logger.error(
                            f"Failed to roll back transaction: {str(rollback_error)}"
                        )
                    # Continue with storage even if logging fails
            else:
                message = "API returned empty response"
                logger.warning(
                    f"{message} for endpoint {endpoint} and property ID {property_id}"
                )
                try:
                    await event_crud.log_scrape_event(
                        db,
                        super_id,
                        ScrapeEventTypeEnum.API_CALL_SUCCESS_EMPTY,
                        rightmove_property_id=property_id,
                        api_endpoint_called=endpoint,
                    )
                except Exception as e:
                    logger.error(f"Failed to log empty API response: {str(e)}")
                    # Roll back transaction to prevent PendingRollbackError
                    try:
                        await db.rollback()
                        logger.info(
                            "Rolled back transaction after failed empty API logging"
                        )
                    except Exception as rollback_error:
                        logger.error(
                            f"Failed to roll back transaction: {str(rollback_error)}"
                        )

                results.append(
                    CombinedPropertyResponseItem(
                        api_endpoint=endpoint,
                        property_id=property_id,
                        super_id=super_id,
                        stored=False,
                        message=message,
                    )
                )
                continue  # Skip to the next endpoint

        except Exception as api_error:
            # Handle API call failure
            error_message = str(api_error)
            logger.error(f"API call to {endpoint} failed: {error_message}")

            # Log API call failure
            try:
                await event_crud.log_scrape_event(
                    db,
                    super_id,
                    ScrapeEventTypeEnum.API_CALL_FAILURE,
                    rightmove_property_id=property_id,
                    api_endpoint_called=endpoint,
                    error_code="API_ERROR",
                    error_message=error_message,
                )
            except Exception as log_error:
                logger.error(f"Failed to log API call failure: {str(log_error)}")
                # Roll back transaction to prevent PendingRollbackError
                try:
                    await db.rollback()
                    logger.info(
                        "Rolled back transaction after failed API failure logging"
                    )
                except Exception as rollback_error:
                    logger.error(
                        f"Failed to roll back transaction: {str(rollback_error)}"
                    )

            results.append(
                CombinedPropertyResponseItem(
                    api_endpoint=endpoint,
                    property_id=property_id,
                    super_id=super_id,
                    stored=False,
                    message=f"API call failed: {error_message}",
                )
            )
            continue  # Skip to next endpoint

        # Step 3: Store data in the database if API call was successful
        if raw_data:
            try:
                logger.info(
                    f"Storing data from {endpoint} in database for property ID: {property_id}"
                )
                stored_successfully, message = await store_func(db, raw_data, super_id)

                if stored_successfully:
                    logger.info(f"Successfully stored {endpoint} data: {message}")
                    # Log storage success
                    try:
                        await event_crud.log_scrape_event(
                            db,
                            super_id,
                            ScrapeEventTypeEnum.DATA_STORED_SUCCESS,
                            rightmove_property_id=property_id,
                            api_endpoint_called=endpoint,
                        )
                    except Exception as log_error:
                        logger.error(
                            f"Failed to log successful storage: {str(log_error)}"
                        )
                        # Explicitly roll back to prevent PendingRollbackError
                        await db.rollback()
                else:
                    logger.warning(f"Failed to store data: {message}")
                    # This is not an exception but a controlled failure response from storage function
                    try:
                        await event_crud.log_scrape_event(
                            db,
                            super_id,
                            ScrapeEventTypeEnum.DATA_STORED_FAILURE,
                            rightmove_property_id=property_id,
                            api_endpoint_called=endpoint,
                            error_code="STORAGE_ERROR",
                            error_message=message,
                        )
                    except Exception as log_error:
                        logger.error(f"Failed to log storage failure: {str(log_error)}")
                        # Explicitly roll back to prevent PendingRollbackError
                        await db.rollback()

            except Exception as storage_error:
                # Handle unexpected database storage errors
                error_message = str(storage_error)
                logger.error(
                    f"Exception during database storage for {endpoint}: {error_message}"
                )
                stored_successfully = False
                message = f"Failed to store data: {error_message}"

                # Explicitly roll back the transaction to prevent PendingRollbackError
                try:
                    await db.rollback()
                    logger.info(
                        f"Successfully rolled back transaction after storage error"
                    )
                except Exception as rollback_error:
                    logger.error(
                        f"Failed to roll back transaction: {str(rollback_error)}"
                    )

                # Log storage failure
                try:
                    await event_crud.log_scrape_event(
                        db,
                        super_id,
                        ScrapeEventTypeEnum.DATA_STORED_FAILURE,
                        rightmove_property_id=property_id,
                        api_endpoint_called=endpoint,
                        error_code="STORAGE_ERROR",
                        error_message=error_message,
                    )
                except Exception as log_error:
                    logger.error(f"Failed to log storage failure: {str(log_error)}")
                    # Try to roll back again if logging failed
                    try:
                        await db.rollback()
                    except Exception:
                        pass

            # Add result for this endpoint
            results.append(
                CombinedPropertyResponseItem(
                    api_endpoint=endpoint,
                    property_id=property_id,
                    super_id=super_id,
                    stored=stored_successfully,
                    message=message,
                )
            )

    logger.info(
        f"Completed processing for property ID {property_id}, endpoints processed: {len(results)}"
    )
    return CombinedPropertyResponse(
        property_id=property_id,
        property_url=request.property_url,
        results=results,
    )


@router.get("/validate-url", response_model=PropertyUrlResponse)
async def validate_property_url(
    url: str = Query(..., description="Rightmove property URL to validate")
):
    """
    Validate a Rightmove property URL and extract the property ID.

    This endpoint is useful for client applications to check if a URL is valid
    and to extract the property ID before submitting the URL for processing.
    """
    try:
        # Check if URL is valid
        if not is_valid_rightmove_url(url):
            return PropertyUrlResponse(
                url=url,
                valid=False,
                property_id=None,
                message="Invalid Rightmove property URL",
            )

        # Extract property ID
        property_id = extract_rightmove_property_id(url)
        if not property_id:
            return PropertyUrlResponse(
                url=url,
                valid=False,
                property_id=None,
                message="Could not extract property ID from URL",
            )

        return PropertyUrlResponse(
            url=url,
            valid=True,
            property_id=property_id,
            message=f"Successfully extracted property ID: {property_id}",
        )
    except Exception as e:
        logger.error(f"Error validating property URL: {str(e)}")
        return PropertyUrlResponse(
            url=url,
            valid=False,
            property_id=None,
            message=f"Error processing URL: {str(e)}",
        )


@router.post("/fetch/details", response_model=PropertyDetailsStorageResponse)
async def fetch_property_details(
    request: FetchPropertyDetailsRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
) -> PropertyDetailsStorageResponse:
    """
    Fetch property details from Rightmove API and store in database.
    Uses the properties/details endpoint.

    Either property_id or property_url must be provided.
    If property_url is provided, the property_id will be extracted from it.
    """
    try:
        # Extract property ID if URL is provided
        property_id = request.property_id
        if not property_id and request.property_url:
            property_id = extract_rightmove_property_id(request.property_url)
            if not property_id:
                raise HTTPException(
                    status_code=400,
                    detail=f"Failed to extract property ID from URL: {request.property_url}",
                )
        elif not property_id:
            raise HTTPException(
                status_code=400,
                detail="Either property_id or property_url must be provided",
            )

        # Use provided super_id or create a new one
        super_id = request.super_id
        if not super_id:
            description = (
                request.description
                or f"Rightmove property details fetch for property ID: {property_id}"
            )
            super_id = await super_id_service_client.create_super_id(
                description=description
            )

        # Fetch from Rightmove API
        property_data = await rightmove_api_client.get_property_details(
            str(property_id)
        )

        if not property_data:
            raise HTTPException(
                status_code=404,
                detail=f"Property details not found for ID: {property_id}",
            )

        # Store in database
        success, message = await store_properties_details(db, property_data, super_id)

        return PropertyDetailsStorageResponse(
            property_id=property_id,
            super_id=super_id,
            stored=success,
            message=message,
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching property details: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to fetch and store property details: {str(e)}",
        )


@router.post("/fetch/property-for-sale", response_model=PropertyDetailsStorageResponse)
async def fetch_property_for_sale_details(
    request: FetchPropertyDetailsRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
) -> PropertyDetailsStorageResponse:
    """
    Fetch property for sale details from Rightmove API and store in database.
    Uses the property-for-sale/detail endpoint.

    Either property_id or property_url must be provided.
    If property_url is provided, the property_id will be extracted from it.
    """
    try:
        # Extract property ID if URL is provided
        property_id = request.property_id
        if not property_id and request.property_url:
            property_id = extract_rightmove_property_id(request.property_url)
            if not property_id:
                raise HTTPException(
                    status_code=400,
                    detail=f"Failed to extract property ID from URL: {request.property_url}",
                )
        elif not property_id:
            raise HTTPException(
                status_code=400,
                detail="Either property_id or property_url must be provided",
            )

        # Use provided super_id or create a new one
        super_id = request.super_id
        if not super_id:
            description = (
                request.description
                or f"Rightmove property for sale fetch for property ID: {property_id}"
            )
            super_id = await super_id_service_client.create_super_id(
                description=description
            )

        # Fetch from Rightmove API
        property_data = await rightmove_api_client.get_property_for_sale_details(
            str(property_id)
        )

        if not property_data:
            raise HTTPException(
                status_code=404,
                detail=f"Property for sale details not found for ID: {property_id}",
            )

        # Store in database
        success, message = await store_property_details(db, property_data, super_id)

        return PropertyDetailsStorageResponse(
            property_id=property_id,
            super_id=super_id,
            stored=success,
            message=message,
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching property for sale details: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to fetch and store property for sale details: {str(e)}",
        )


@router.post("/fetch/batch", response_model=FetchBatchResponse)
async def fetch_batch_properties(
    request: FetchBatchRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
) -> FetchBatchResponse:
    """
    Fetch multiple properties in a batch operation.
    This endpoint processes property IDs in parallel for faster batch processing.
    """
    if not request.property_ids:
        raise HTTPException(status_code=400, detail="No property IDs provided")

    if len(request.property_ids) > 50:
        raise HTTPException(
            status_code=400, detail="Maximum batch size is 50 properties"
        )

    # Get a batch ID (super_id) for tracking this batch operation
    batch_id = await super_id_service_client.create_super_id(
        description=f"Rightmove batch property fetch ({request.api_type}) for {len(request.property_ids)} properties"
    )

    # Define the processing function based on API type
    if request.api_type == "properties_details":
        process_func = process_property_details
    elif request.api_type == "property_for_sale":
        process_func = process_property_for_sale
    else:
        raise HTTPException(status_code=400, detail="Invalid API type specified")

    # Process properties in parallel
    tasks = []
    for property_id in request.property_ids:
        tasks.append(process_func(property_id, db))

    # Wait for all tasks to complete
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Process results
    successful = 0
    failed = 0
    property_results = []

    for result in results:
        if isinstance(result, Exception):
            # Handle exception case
            failed += 1
            logger.error(f"Error in batch processing: {str(result)}")
            property_results.append(
                FetchPropertyResponse(
                    property_id=0,  # Unknown property ID
                    super_id=uuid.UUID(int=0),  # Placeholder UUID
                    status="failed",
                    message=f"Error: {str(result)}",
                )
            )
        else:
            # Handle successful case
            property_id, super_id, status, message = result
            if status == "success":
                successful += 1
            else:
                failed += 1

            property_results.append(
                FetchPropertyResponse(
                    property_id=property_id,
                    super_id=super_id,
                    status=status,
                    message=message,
                )
            )

    return FetchBatchResponse(
        batch_id=batch_id,
        total=len(request.property_ids),
        successful=successful,
        failed=failed,
        results=property_results,
    )


async def process_property_details(property_id: int, db: AsyncSession) -> tuple:
    """Process a single property using the properties/details endpoint."""
    try:
        # Get a super_id for tracking this request
        super_id = await super_id_service_client.create_super_id(
            description=f"Rightmove property details fetch for property ID: {property_id}"
        )

        # Fetch from Rightmove API
        property_data = await rightmove_api_client.get_property_details(
            str(property_id)
        )

        if not property_data:
            return (
                property_id,
                super_id,
                "failed",
                f"Property details not found for ID: {property_id}",
            )

        # Store in database
        success, message = await store_properties_details(db, property_data, super_id)

        status = "success" if success else "failed"
        return property_id, super_id, status, message

    except HTTPException as http_e:
        # If this is a Super ID service exception, log and propagate it
        if http_e.status_code == 503 and "Super ID service" in str(http_e):
            logger.error(
                f"Super ID service unavailable while processing property ID {property_id}: {str(http_e)}"
            )
            raise http_e
        # For other HTTP exceptions, log and return failure
        logger.error(
            f"HTTP error processing property details for ID {property_id}: {str(http_e)}"
        )
        raise http_e
    except Exception as e:
        logger.error(
            f"Error processing property details for ID {property_id}: {str(e)}"
        )
        # Don't generate local UUID - propagate error instead
        raise HTTPException(
            status_code=500,
            detail=f"Failed to process property details for ID {property_id}: {str(e)}",
        )


async def process_property_for_sale(property_id: int, db: AsyncSession) -> tuple:
    """Process a single property using the property-for-sale/detail endpoint."""
    try:
        # Get a super_id for tracking this request
        super_id = await super_id_service_client.create_super_id(
            description=f"Rightmove property for sale fetch for property ID: {property_id}"
        )

        # Fetch from Rightmove API
        property_data = await rightmove_api_client.get_property_for_sale_details(
            str(property_id)
        )

        if not property_data:
            return (
                property_id,
                super_id,
                "failed",
                f"Property for sale details not found for ID: {property_id}",
            )

        # Store in database
        success, message = await store_property_details(db, property_data, super_id)

        status = "success" if success else "failed"
        return property_id, super_id, status, message

    except HTTPException as http_e:
        # If this is a Super ID service exception, log and propagate it
        if http_e.status_code == 503 and "Super ID service" in str(http_e):
            logger.error(
                f"Super ID service unavailable while processing property ID {property_id}: {str(http_e)}"
            )
            raise http_e
        # For other HTTP exceptions, log and return failure
        logger.error(
            f"HTTP error processing property for sale for ID {property_id}: {str(http_e)}"
        )
        raise http_e
    except Exception as e:
        logger.error(
            f"Error processing property for sale for ID {property_id}: {str(e)}"
        )
        # Don't generate local UUID - propagate error instead
        raise HTTPException(
            status_code=500,
            detail=f"Failed to process property for sale details for ID {property_id}: {str(e)}",
        )


@router.get("/details/{property_id}", response_model=Dict)
async def get_property_details(
    property_id: int, db: AsyncSession = Depends(get_db)
) -> Dict:
    """
    Get property details from the database by ID.
    Uses data from the properties/details endpoint.
    """
    property_data = await get_property_details_by_id(db, property_id)
    if not property_data:
        raise HTTPException(
            status_code=404, detail=f"Property details not found for ID: {property_id}"
        )
    return property_data


@router.get("/property-for-sale/{property_id}", response_model=Dict)
async def get_property_for_sale(
    property_id: int, db: AsyncSession = Depends(get_db)
) -> Dict:
    """
    Get property for sale details from the database by ID.
    Uses data from the property-for-sale/detail endpoint.
    """
    property_data = await get_property_sale_details_by_id(db, property_id)
    if not property_data:
        raise HTTPException(
            status_code=404,
            detail=f"Property for sale details not found for ID: {property_id}",
        )
    return property_data


@router.post("/search", response_model=Dict)
async def search_properties(
    search_request: PropertySearchRequest,
    background_tasks: BackgroundTasks,
    store_results: bool = Query(
        False, description="Whether to store search results in the database"
    ),
) -> Dict:
    """
    Search for properties using the Rightmove API.
    Optionally store the results in the database if store_results is True.
    """
    try:
        # Call the Rightmove API search endpoint
        search_results = await rightmove_api_client.search_properties_for_sale(
            location=search_request.location,
            min_price=search_request.min_price,
            max_price=search_request.max_price,
            min_bedrooms=search_request.min_bedrooms,
            max_bedrooms=search_request.max_bedrooms,
            property_type=search_request.property_type,
            radius=search_request.radius,
            page_number=search_request.page_number,
            page_size=search_request.page_size,
        )

        # If store_results is True, store each property in the database
        if store_results and "properties" in search_results:
            # This should be done as a background task to not block the response
            background_tasks.add_task(
                store_search_results, search_results.get("properties", [])
            )

        return search_results

    except Exception as e:
        logger.error(f"Error searching properties: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"Failed to search properties: {str(e)}"
        )


async def store_search_results(properties: List[Dict]) -> None:
    """Store search results in the database as a background task."""
    async with AsyncSession(bind=db_engine) as db:
        for property_data in properties:
            try:
                # Get property ID from the data
                property_id = property_data.get("id")
                if not property_id:
                    logger.warning("Property data missing ID, skipping")
                    continue

                try:
                    # Get a super_id for tracking this property
                    super_id = await super_id_service_client.create_super_id(
                        description=f"Rightmove search result for property ID: {property_id}"
                    )
                except HTTPException as http_e:
                    # If Super ID service fails, log the error and skip this property
                    logger.error(
                        f"Super ID service error for property ID {property_id}: {str(http_e)}"
                    )
                    # Skip this property but continue with others in the batch
                    continue

                # Store in database - pick the right function based on available data
                if "propertySubType" in property_data:
                    # This looks like the property-for-sale format
                    await store_property_details(db, property_data, super_id)
                else:
                    # Try the properties/details format
                    await store_properties_details(db, property_data, super_id)

            except Exception as e:
                logger.error(f"Error storing search result: {str(e)}")
                # Continue with next property, don't fail the entire batch


@router.get("/ids", response_model=List[int])
async def list_property_ids(
    limit: int = Query(100, le=1000),
    offset: int = Query(0, ge=0),
    api_type: str = Query(
        "properties_details",
        description="API type: 'properties_details' or 'property_for_sale'",
    ),
    db: AsyncSession = Depends(get_db),
) -> List[int]:
    """
    List property IDs stored in the database.
    Supports pagination with limit and offset parameters.
    """
    if api_type == "properties_details":
        return await get_all_property_ids(db, limit, offset)
    elif api_type == "property_for_sale":
        return await get_all_property_sale_ids(db, limit, offset)
    else:
        raise HTTPException(status_code=400, detail="Invalid API type specified")


# data_capture_rightmove_service/src/data_capture_rightmove_service/routers/health_router.py
"""
Health check endpoints for monitoring service status.
"""

import os
import time
from datetime import datetime

from fastapi import APIRouter, Depends, Request, Security
from fastapi.security import HTTPBearer
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession
from supabase._async.client import AsyncClient as AsyncSupabaseClient

from data_capture_rightmove_service.clients.auth_service_client import (
    auth_service_client,
)
from data_capture_rightmove_service.clients.super_id_service_client import (
    super_id_service_client,
)
from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.db import get_db
from data_capture_rightmove_service.schemas.common import (
    ComponentHealth,
    HealthCheckResponse,
    HealthStatus,
)
from data_capture_rightmove_service.utils.logging_config import logger
from data_capture_rightmove_service.utils.security import validate_token

router = APIRouter(tags=["Health"])

# Track app startup time for uptime monitoring
start_time = time.time()


@router.get("/health", response_model=HealthCheckResponse)
async def health_check(
    request: Request,
    db: AsyncSession = Depends(get_db),
) -> HealthCheckResponse:
    """
    Basic health check endpoint for the service.
    Can be used by Kubernetes liveness and readiness probes.
    """
    current_time = datetime.utcnow()
    response = {
        "status": HealthStatus.OK,
        "version": "0.1.0",  # TODO: Get from version file
        "timestamp": current_time,
        "components": {"api": {"status": HealthStatus.OK}},
        "uptime_seconds": time.time() - start_time,
    }

    # Check database connectivity
    try:
        result = await db.execute(text("SELECT 1"))
        row = result.scalar()
        if row == 1:
            response["components"]["database"] = {"status": HealthStatus.OK}
        else:
            response["components"]["database"] = {
                "status": HealthStatus.ERROR,
                "message": "Database query returned unexpected result",
            }
            response["status"] = HealthStatus.ERROR
    except Exception as e:
        logger.error(f"Database health check failed: {str(e)}")
        response["components"]["database"] = {
            "status": HealthStatus.ERROR,
            "message": f"Database connection error: {str(e)}",
        }
        response["status"] = HealthStatus.ERROR

    # For Kubernetes probes, we might want to simplify the response
    is_k8s_probe = "kube-probe" in request.headers.get("user-agent", "").lower()

    # If this is a Kubernetes probe and we want to avoid pod restarts during maintenance,
    # we could always return status OK, but log the actual status
    if is_k8s_probe and response["status"] != HealthStatus.OK:
        logger.warning(
            f"Health check failed but reporting OK for K8s probe: {response}"
        )
        # For K8s probes, we still report OK to avoid unnecessary pod restarts
        response["status"] = HealthStatus.OK

    return HealthCheckResponse(**response)


@router.get("/health/detailed", response_model=HealthCheckResponse)
async def detailed_health_check(
    request: Request,
    db: AsyncSession = Depends(get_db),
) -> HealthCheckResponse:
    """
    Detailed health check that tests connectivity to all dependent services.
    This is more thorough than the basic health check and intended for internal monitoring.
    """
    # Start with basic health check
    response = await health_check(request, db)
    response_dict = response.model_dump()

    # Check auth service connectivity
    try:
        # Log the attempt to access auth service
        logger.debug(
            f"Testing auth service connectivity at: {settings.AUTH_SERVICE_URL}"
        )
        # Just test if we can get a token
        token = await auth_service_client.get_token()
        if token:
            response_dict["components"]["auth_service"] = {"status": HealthStatus.OK}
        else:
            response_dict["components"]["auth_service"] = {
                "status": HealthStatus.ERROR,
                "message": "Failed to acquire token from auth service",
            }
            response_dict["status"] = HealthStatus.ERROR
    except Exception as e:
        logger.error(f"Auth service health check failed: {str(e)}")
        response_dict["components"]["auth_service"] = {
            "status": HealthStatus.ERROR,
            "message": f"Auth service error: {str(e)}",
        }
        response_dict["status"] = HealthStatus.ERROR

    # Check super ID service connectivity (only if auth service is OK)
    if (
        response_dict["components"].get("auth_service", {}).get("status")
        == HealthStatus.OK
    ):
        try:
            # Log the attempt to access super_id service
            logger.debug(
                f"Testing super_id service connectivity at: {settings.SUPER_ID_SERVICE_URL}"
            )
            # Create a test super ID
            super_id = await super_id_service_client.create_super_id(
                description="Health check test"
            )
            if super_id:
                response_dict["components"]["super_id_service"] = {
                    "status": HealthStatus.OK
                }
            else:
                response_dict["components"]["super_id_service"] = {
                    "status": HealthStatus.ERROR,
                    "message": "Failed to generate super ID",
                }
                response_dict["status"] = HealthStatus.ERROR
        except Exception as e:
            logger.error(f"Super ID service health check failed: {str(e)}")
            response_dict["components"]["super_id_service"] = {
                "status": HealthStatus.ERROR,
                "message": f"Super ID service error: {str(e)}",
            }
            response_dict["status"] = HealthStatus.ERROR

    # Include environment information
    response_dict["components"]["environment"] = {
        "status": HealthStatus.OK,
        "message": f"Environment: {settings.ENVIRONMENT}",
    }

    # Include process information
    response_dict["components"]["process"] = {
        "status": HealthStatus.OK,
        "message": f"PID: {os.getpid()}",
    }

    return HealthCheckResponse(**response_dict)


# data_capture_rightmove_service/src/data_capture_rightmove_service/clients/rightmove_api_client.py
"""
Rightmove API Client for fetching property data from RapidAPI.
"""

import logging
from typing import Any, Dict, List, Optional

import httpx
from fastapi import HTTPException

from data_capture_rightmove_service.config import settings

logger = logging.getLogger(__name__)


class RightmoveApiClient:
    """
    Client for fetching property data from the Rightmove API via RapidAPI.
    Handles rate limiting, error handling, and response parsing.
    """

    def __init__(self, api_key: str = None, api_host: str = None):
        """
        Initialize the Rightmove API Client.

        Args:
            api_key: RapidAPI key, defaults to the value in settings
            api_host: RapidAPI host, defaults to the value in settings
        """
        self.api_key = api_key or settings.RAPID_API_KEY
        self.api_host = api_host or settings.RAPID_API_HOST
        self.base_url = f"https://{self.api_host}"

        # Default headers for all requests
        self._default_headers = {
            "X-RapidAPI-Key": self.api_key,
            "X-RapidAPI-Host": self.api_host,
        }

    async def _make_request(
        self,
        method: str,
        endpoint: str,
        params: Optional[Dict[str, Any]] = None,
        max_retries: int = 1,
    ) -> Dict[str, Any]:
        """
        Make a request to the Rightmove API with appropriate headers and error handling.

        Args:
            method: HTTP method to use (GET, POST, etc.)
            endpoint: API endpoint to call
            params: Query parameters to include
            max_retries: Maximum number of retries on rate limit errors

        Returns:
            Dict[str, Any]: API response data

        Raises:
            HTTPException: If the API request fails
        """
        url = f"{self.base_url}{endpoint}"
        retries = 0

        while retries <= max_retries:
            try:
                async with httpx.AsyncClient() as client:
                    if method.upper() == "GET":
                        response = await client.get(
                            url,
                            params=params,
                            headers=self._default_headers,
                            timeout=30.0,  # Longer timeout for property data
                        )
                    elif method.upper() == "POST":
                        response = await client.post(
                            url,
                            json=params,
                            headers=self._default_headers,
                            timeout=30.0,
                        )
                    else:
                        raise ValueError(f"Unsupported HTTP method: {method}")

                    # Handle rate limiting
                    if response.status_code == 429:
                        retries += 1
                        if retries > max_retries:
                            logger.error("Rate limit exceeded and max retries reached")
                            raise HTTPException(
                                status_code=429,
                                detail="Rate limit exceeded from RapidAPI Rightmove API",
                            )
                        logger.warning(
                            f"Rate limit hit, retrying {retries}/{max_retries}..."
                        )
                        await asyncio.sleep(1)  # Wait before retrying
                        continue

                    # Handle other errors
                    response.raise_for_status()
                    
                    # Parse the response JSON
                    response_data = response.json()
                    
                    # Log the response structure for debugging
                    logger.debug(f"API Response URL: {url}")
                    logger.debug(f"API Response Status: {response.status_code}")
                    logger.debug(f"API Response Structure - Top-level keys: {list(response_data.keys())}")
                    
                    # Log nested data structure if present
                    if "data" in response_data and isinstance(response_data["data"], dict):
                        logger.debug(f"API Response Nested data keys: {list(response_data['data'].keys())}")
                        
                        # Look for ID fields in the nested data
                        id_fields = ["id", "propertyId", "property_id"]
                        for field in id_fields:
                            if field in response_data["data"]:
                                logger.debug(f"Found ID field '{field}' in data: {response_data['data'][field]}")
                    
                    return response_data

            except httpx.HTTPError as e:
                logger.error(f"HTTP error when calling Rightmove API: {str(e)}")
                if hasattr(e, "response") and e.response is not None:
                    status_code = e.response.status_code
                    try:
                        error_detail = e.response.json()
                        detail = f"Rightmove API error: {error_detail}"
                    except Exception:
                        detail = f"Rightmove API error: {str(e)}"
                else:
                    status_code = 503
                    detail = f"Rightmove API service unavailable: {str(e)}"

                raise HTTPException(status_code=status_code, detail=detail)

            except Exception as e:
                logger.error(f"Unexpected error when calling Rightmove API: {str(e)}")
                raise HTTPException(
                    status_code=500,
                    detail=f"Unexpected error when calling Rightmove API: {str(e)}",
                )

    async def get_property_details(self, property_id: str) -> Dict[str, Any]:
        """
        Get detailed information about a specific property using the properties/details endpoint.

        Args:
            property_id: The Rightmove property ID

        Returns:
            Dict[str, Any]: Property details

        Raises:
            HTTPException: If the API request fails
        """
        endpoint = settings.RIGHTMOVE_API_PROPERTIES_DETAILS_ENDPOINT
        params = {"identifier": property_id}  # Use 'identifier' parameter instead of 'propertyId'

        logger.info(f"Fetching property details for ID: {property_id}")
        return await self._make_request("GET", endpoint, params, max_retries=2)

    async def get_property_for_sale_details(self, property_id: str) -> Dict[str, Any]:
        """
        Get detailed information about a property for sale using the correct endpoint.

        Args:
            property_id: The Rightmove property ID

        Returns:
            Dict[str, Any]: Property details

        Raises:
            HTTPException: If the API request fails
        """
        # The correct endpoint format is /buy/property-for-sale/detail with 'id' parameter
        endpoint = f"{settings.RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT}/detail"
        params = {"id": property_id}  # Use 'id' parameter instead of 'propertyId'

        logger.info(f"Fetching property-for-sale details for ID: {property_id} using endpoint {endpoint}")
        return await self._make_request("GET", endpoint, params, max_retries=2)

    async def search_properties_for_sale(
        self,
        location: str,
        min_price: Optional[int] = None,
        max_price: Optional[int] = None,
        min_bedrooms: Optional[int] = None,
        max_bedrooms: Optional[int] = None,
        property_type: Optional[str] = None,
        radius: Optional[float] = None,
        page_number: int = 0,
        page_size: int = 10,
    ) -> Dict[str, Any]:
        """
        Search for properties for sale based on criteria.

        Args:
            location: Location to search in (e.g., "London")
            min_price: Minimum price
            max_price: Maximum price
            min_bedrooms: Minimum number of bedrooms
            max_bedrooms: Maximum number of bedrooms
            property_type: Type of property (e.g., "FLAT", "HOUSE")
            radius: Search radius in miles
            page_number: Page number for pagination
            page_size: Number of results per page

        Returns:
            Dict[str, Any]: Search results

        Raises:
            HTTPException: If the API request fails
        """
        endpoint = f"{settings.RIGHTMOVE_API_PROPERTY_FOR_SALE_ENDPOINT}"

        # Build query parameters
        params = {
            "locationIdentifier": location,
            "index": page_number,
            "sortType": 6,
            "numberOfPropertiesPerPage": page_size,
        }

        if min_price is not None:
            params["minPrice"] = min_price

        if max_price is not None:
            params["maxPrice"] = max_price

        if min_bedrooms is not None:
            params["minBedrooms"] = min_bedrooms

        if max_bedrooms is not None:
            params["maxBedrooms"] = max_bedrooms

        if property_type is not None:
            params["propertyType"] = property_type

        if radius is not None:
            params["radius"] = radius

        logger.info(f"Searching properties for sale with criteria: {params}")
        return await self._make_request("GET", endpoint, params, max_retries=2)


# Create a global instance of the Rightmove API client
rightmove_api_client = RightmoveApiClient()


# data_capture_rightmove_service/src/data_capture_rightmove_service/clients/__init__.py
"""
Client modules for external service integrations.
"""

from data_capture_rightmove_service.clients.auth_service_client import auth_service_client
from data_capture_rightmove_service.clients.super_id_service_client import super_id_service_client
from data_capture_rightmove_service.clients.rightmove_api_client import rightmove_api_client

__all__ = ['auth_service_client', 'super_id_service_client', 'rightmove_api_client']


# data_capture_rightmove_service/src/data_capture_rightmove_service/clients/super_id_service_client.py
"""
Super ID Service Client for generating and retrieving tracking UUIDs.
"""

import logging
import uuid
from typing import Dict, Optional

import httpx
from fastapi import HTTPException

from data_capture_rightmove_service.clients.auth_service_client import (
    auth_service_client,
)
from data_capture_rightmove_service.config import settings

logger = logging.getLogger(__name__)


class SuperIdServiceClient:
    """
    Client for interacting with the Super ID Service API for UUID generation and tracking.
    """

    def __init__(self, base_url: str = None):
        """
        Initialize the Super ID Service Client.

        Args:
            base_url: Base URL for the Super ID Service API, defaults to the value in settings
        """
        self.base_url = base_url or settings.SUPER_ID_SERVICE_URL
        logger.info(f"Initializing Super ID Service Client with URL: {self.base_url}")

    async def create_super_id(
        self,
        source_service: str = "data_capture_rightmove_service",
        description: str = None,
    ) -> uuid.UUID:
        """
        Generate a new Super ID UUID for tracking purposes.

        Args:
            source_service: The name of the service requesting the Super ID
            description: Optional description of what this Super ID is for

        Returns:
            uuid.UUID: The generated UUID

        Raises:
            HTTPException: If Super ID generation fails
        """
        try:
            # Get auth headers with a valid token
            headers = await auth_service_client.get_auth_header()

            payload = {
                "source_service": source_service,
                "description": description or "Rightmove data capture request",
            }

            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/super_ids",
                    json=payload,
                    headers=headers,
                    timeout=10.0,
                )

                response.raise_for_status()
                data = response.json()

                # Return the UUID from the response
                return uuid.UUID(data["super_id"])

        except httpx.HTTPError as e:
            logger.error(f"Failed to generate Super ID: {str(e)}")
            if isinstance(e, httpx.HTTPStatusError) and e.response.status_code == 401:
                # If unauthorized, try with a fresh token
                try:
                    headers = await auth_service_client.get_auth_header(
                        force_refresh=True
                    )
                    async with httpx.AsyncClient() as client:
                        response = await client.post(
                            f"{self.base_url}/super_ids",
                            json=payload,
                            headers=headers,
                            timeout=10.0,
                        )

                        response.raise_for_status()
                        data = response.json()

                        return uuid.UUID(data["super_id"])
                except httpx.HTTPError as retry_err:
                    logger.error(
                        f"Failed to generate Super ID after token refresh: {str(retry_err)}"
                    )
                    raise HTTPException(
                        status_code=503,
                        detail=f"Super ID service unavailable: {str(retry_err)}",
                    )
            raise HTTPException(
                status_code=503,
                detail=f"Super ID service unavailable: {str(e)}",
            )

    async def get_super_id_info(self, super_id: uuid.UUID) -> Dict:
        """
        Get information about an existing Super ID.

        Args:
            super_id: The UUID to look up

        Returns:
            Dict: Information about the Super ID

        Raises:
            HTTPException: If Super ID lookup fails
        """
        try:
            # Get auth headers with a valid token
            headers = await auth_service_client.get_auth_header()

            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.base_url}/super_ids/{super_id}",
                    headers=headers,
                    timeout=10.0,
                )

                response.raise_for_status()
                return response.json()

        except httpx.HTTPError as e:
            logger.error(f"Failed to get Super ID info: {str(e)}")
            if isinstance(e, httpx.HTTPStatusError) and e.response.status_code == 401:
                # If unauthorized, try with a fresh token
                try:
                    headers = await auth_service_client.get_auth_header(
                        force_refresh=True
                    )
                    async with httpx.AsyncClient() as client:
                        response = await client.get(
                            f"{self.base_url}/super_ids/{super_id}",
                            headers=headers,
                            timeout=10.0,
                        )

                        response.raise_for_status()
                        return response.json()
                except httpx.HTTPError as retry_err:
                    logger.error(
                        f"Failed to get Super ID info after token refresh: {str(retry_err)}"
                    )
                    raise HTTPException(
                        status_code=503,
                        detail=f"Super ID service unavailable: {str(retry_err)}",
                    )
            raise HTTPException(
                status_code=503,
                detail=f"Super ID service unavailable: {str(e)}",
            )


# Create a global instance of the super ID service client
super_id_service_client = SuperIdServiceClient()


# data_capture_rightmove_service/src/data_capture_rightmove_service/clients/auth_service_client.py
"""
Auth Service Client for acquiring M2M tokens to authenticate with other services.
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, Optional

import httpx

from data_capture_rightmove_service.config import settings

logger = logging.getLogger(__name__)


class AuthServiceClient:
    """
    Client for interacting with the Auth Service API for M2M authentication.
    Handles token acquisition and caching to avoid unnecessary API calls.
    """

    def __init__(self, base_url: str = None):
        """
        Initialize the Auth Service Client.

        Args:
            base_url: Base URL for the Auth Service API, defaults to the value in settings
        """
        self.base_url = base_url or settings.AUTH_SERVICE_URL
        self.client_id = settings.M2M_CLIENT_ID
        self.client_secret = settings.M2M_CLIENT_SECRET

        # Token cache
        self._token: Optional[str] = None
        self._token_expiry: Optional[datetime] = None

    async def get_token(self, force_refresh: bool = False) -> str:
        """
        Get an M2M JWT token for authenticating with other services.
        If a valid token exists in the cache, return it, otherwise fetch a new one.

        Args:
            force_refresh: Force token refresh even if the current token is still valid

        Returns:
            str: The JWT token to use for authentication

        Raises:
            HTTPException: If token acquisition fails
        """
        if (
            not force_refresh
            and self._token
            and self._token_expiry
            and datetime.utcnow() < self._token_expiry
        ):
            logger.debug("Using cached auth token.")
            return self._token

        logger.info("Fetching new M2M token from Auth Service")

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/auth/token",
                    json={
                        "client_id": self.client_id,
                        "client_secret": self.client_secret,
                        "grant_type": "client_credentials",  # Required by OAuth2 spec
                    },
                    timeout=10.0,
                )

                response.raise_for_status()
                data = response.json()

                self._token = data["access_token"]
                # Set expiry 1 minute before actual expiry to avoid edge cases
                expires_in = data.get("expires_in", 1800)  # Default to 30 minutes
                self._token_expiry = datetime.utcnow() + timedelta(
                    seconds=expires_in - 60
                )

                logger.info(
                    f"Successfully acquired new M2M token, valid until {self._token_expiry}"
                )
                return self._token
        except httpx.HTTPError as e:
            logger.error(f"Failed to acquire M2M token: {str(e)}")
            # Clear token cache in case of error
            self._token = None
            self._token_expiry = None
            raise

    async def get_auth_header(self, force_refresh: bool = False) -> Dict[str, str]:
        """
        Get the Authorization header with a valid JWT token.

        Args:
            force_refresh: Force token refresh even if the current token is still valid

        Returns:
            Dict[str, str]: Header with Authorization Bearer token
        """
        token = await self.get_token(force_refresh=force_refresh)
        return {"Authorization": f"Bearer {token}"}


# Create a global instance of the auth service client
auth_service_client = AuthServiceClient()


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/property_mapper.py
"""
Utility functions for mapping between API response data and database models
for Rightmove property data.
"""

from typing import Dict, Any, List, Optional


def camel_to_snake(name: str) -> str:
    """Convert camelCase string to snake_case."""
    import re
    return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()


def map_property_data(data: Dict[str, Any], model_class) -> Dict[str, Any]:
    """
    Map API response data to ORM model fields by checking the column attributes.
    
    Args:
        data: API response data (usually in camelCase)
        model_class: The SQLAlchemy model class
    
    Returns:
        Dict with keys matching the ORM model attributes
    """
    result = {}
    
    # Get model attributes and their corresponding column names
    # This maps python attribute names to SQL column names
    model_columns = {}
    for column_attr in model_class.__table__.columns:
        # If there's a specified name in the Column definition, use it
        # Otherwise use the attribute name
        attr_name = column_attr.name
        if hasattr(column_attr, 'name') and getattr(column_attr, 'name') != attr_name:
            sql_name = getattr(column_attr, 'name')
        else:
            sql_name = attr_name
        model_columns[attr_name] = sql_name
    
    # Try different mappings for each field in data
    for key, value in data.items():
        # First check if the key exists directly in model
        if key in model_columns:
            result[key] = value
        # Then try snake_case version of camelCase key
        else:
            snake_key = camel_to_snake(key)
            if snake_key in model_columns:
                result[snake_key] = value
        
    return result


def map_nested_data(data: Dict[str, Any], model_mapping: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    """
    Map nested API response data to ORM models for relationships.
    
    Args:
        data: API response data (usually in camelCase)
        model_mapping: Dict mapping from data keys to model classes
    
    Returns:
        Dict with keys matching the relationship names and values as mapped data
    """
    result = {}
    
    for data_key, model_class in model_mapping.items():
        if data_key in data and data[data_key] is not None:
            result[data_key] = map_property_data(data[data_key], model_class)
    
    return result


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/data_completeness.py
def analyze_response(raw_data: dict | None) -> tuple[int, int]:
    """
    Analyzes a raw API response to count total and null items.

    Returns:
        A tuple of (total_item_count, null_item_count).
    """
    if not isinstance(raw_data, dict) or "data" not in raw_data:
        return 0, 0

    data_content = raw_data.get("data")
    if data_content is None:
        # The entire 'data' object is null
        return 1, 1

    if isinstance(data_content, list):
        total_count = len(data_content)
        null_count = sum(1 for item in data_content if item is None)
        return total_count, null_count

    if isinstance(data_content, dict):
        total_count = len(data_content)
        null_count = sum(1 for value in data_content.values() if value is None)
        return total_count, null_count

    # If data is a single non-null, non-collection value
    return 1, 0


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/rate_limiting.py
"""
Rate limiting configuration for Data Capture Rightmove Service.
"""

from typing import Callable, Optional

from fastapi import Request, Response
from slowapi import Limiter
from slowapi.util import get_remote_address

from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.utils.logging_config import logger


def get_key_function() -> Callable:
    """
    Return the appropriate key function for rate limiting.

    In production, this would use the client IP or API key.
    In development, it uses a fixed value for easier testing.

    Returns:
        A function that extracts the rate limiting key from the request
    """
    if settings.is_development() or settings.is_testing():
        # Use a constant key in development for easier testing
        logger.debug("Using development rate limiting key function")
        return lambda _: "development"
    else:
        # Use client IP in production
        logger.debug("Using production rate limiting key function based on client IP")
        return get_remote_address


# Initialize the rate limiter with the appropriate key function
limiter = Limiter(key_func=get_key_function())


def configure_rate_limiter(request: Request, response: Response) -> None:
    """
    Configure rate limiter for the current request.

    Args:
        request: FastAPI request object
        response: FastAPI response object
    """
    # Add rate limiting headers to the response
    response.headers["X-RateLimit-Limit"] = str(settings.RATE_LIMIT_REQUESTS_PER_MINUTE)

    # Additional rate limiting configuration can be added here
    if hasattr(request.state, "rate_limit_remaining"):
        response.headers["X-RateLimit-Remaining"] = str(
            request.state.rate_limit_remaining
        )

    if hasattr(request.state, "rate_limit_reset"):
        response.headers["X-RateLimit-Reset"] = str(request.state.rate_limit_reset)

    # Log rate limiting information in debug mode
    logger.debug(
        f"Rate limiting applied to {request.method} {request.url.path} "
        f"from {get_remote_address(request)}"
    )


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/logging_config.py
import json
import logging
import sys
import time
import uuid
from datetime import datetime, timezone
from typing import Any, Dict, Optional

from fastapi import FastAPI, Request, Response
from starlette.middleware.base import BaseHTTPMiddleware

from data_capture_rightmove_service.config import Environment, settings

# Configure logger
logger = logging.getLogger("data_capture_rightmove_service")


# Request ID context for correlating log entries from the same request
class RequestContext:
    """Thread-local storage for request context such as request ID"""

    _request_id: Optional[str] = None

    @classmethod
    def get_request_id(cls) -> Optional[str]:
        return cls._request_id

    @classmethod
    def set_request_id(cls, request_id: str) -> None:
        cls._request_id = request_id

    @classmethod
    def clear_request_id(cls) -> None:
        cls._request_id = None


class RequestIdMiddleware(BaseHTTPMiddleware):
    """Middleware to add request ID to each request"""

    async def dispatch(self, request: Request, call_next):
        request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())
        RequestContext.set_request_id(request_id)
        response = await call_next(request)
        response.headers["X-Request-ID"] = request_id
        RequestContext.clear_request_id()
        return response


class JsonFormatter(logging.Formatter):
    """Custom JSON formatter for structured logging"""

    def format(self, record: logging.LogRecord) -> str:
        log_record = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
            # --- FIX: Use uppercase attribute ---
            "environment": str(settings.ENVIRONMENT.value),
        }
        if request_id := RequestContext.get_request_id():
            log_record["request_id"] = request_id
        if record.exc_info:
            log_record["exception"] = self.formatException(record.exc_info)
        if hasattr(record, "extra") and record.extra:
            log_record.update(record.extra)
        return json.dumps(log_record)


# For backward compatibility with imports
def configure_logging():
    """Configure logging for non-FastAPI applications like Alembic"""
    setup_logging()


def setup_logging(app: FastAPI = None) -> None:
    """Configure logging for the application

    Args:
        app: Optional FastAPI application to add middleware to.
             If None, only configures logging without middleware.
    """
    # --- FIX: Use uppercase attribute ---
    log_level = getattr(logging, settings.LOGGING_LEVEL.upper(), logging.INFO)

    root_logger = logging.getLogger()
    if root_logger.hasHandlers():
        root_logger.handlers.clear()

    # --- FIX: Use uppercase attribute ---
    if settings.ENVIRONMENT == Environment.PRODUCTION:
        formatter = JsonFormatter()
    else:
        formatter = logging.Formatter(
            "%(asctime)s - %(levelname)s - %(name)s - %(message)s"
        )

    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)
    root_logger.setLevel(log_level)

    # Configure specific loggers if needed
    logging.getLogger("auth_service").setLevel(log_level)
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)

    # Only add middleware if app is provided
    if app:
        app.add_middleware(RequestIdMiddleware)
        logger.info(
            # --- FIX: Use uppercase attribute ---
            f"Logging configured with level {settings.LOGGING_LEVEL} "
            f"and {'JSON' if settings.ENVIRONMENT == Environment.PRODUCTION else 'plain text'} format"
        )


class LoggingMiddleware(BaseHTTPMiddleware):
    """Middleware to log request and response information"""

    async def dispatch(self, request: Request, call_next):
        if request.url.path in ["/health", "/internal/health"]:
            return await call_next(request)

        start_time = time.time()
        request_id = RequestContext.get_request_id()

        try:
            response = await call_next(request)
            duration_ms = (time.time() - start_time) * 1000

            logger.info(
                "Request processed",
                extra={
                    "request": {
                        "method": request.method,
                        "path": request.url.path,
                        "client_host": request.client.host,
                        "request_id": request_id,
                    },
                    "response": {
                        "status_code": response.status_code,
                        "duration_ms": round(duration_ms, 2),
                    },
                },
            )
            return response
        except Exception as e:
            logger.error(
                f"Request failed: {e}", exc_info=True, extra={"request_id": request_id}
            )
            raise


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/security.py
"""
Security utilities for Data Capture Rightmove Service.
"""

import time
from typing import Dict, Optional

import jwt
from fastapi import Depends, HTTPException, Security
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer

from data_capture_rightmove_service.config import settings
from data_capture_rightmove_service.utils.logging_config import logger

security = HTTPBearer(auto_error=False)


async def validate_token(
    credentials: Optional[HTTPAuthorizationCredentials] = Security(security),
) -> Dict:
    """
    Validate JWT token from Authorization header.

    Args:
        credentials: JWT credentials from Authorization header

    Returns:
        Dict containing token claims

    Raises:
        HTTPException: If token is invalid or expired
    """
    if not credentials:
        logger.warning("Missing authentication token")
        raise HTTPException(
            status_code=401,
            detail="Missing authentication token",
            headers={"WWW-Authenticate": "Bearer"},
        )

    token = credentials.credentials

    try:
        # Validate the token
        payload = jwt.decode(
            token,
            settings.M2M_CLIENT_SECRET,
            algorithms=["HS256"],
            options={"verify_signature": True},
        )

        # Check if token has expired
        if payload.get("exp") and payload["exp"] < time.time():
            logger.warning(f"Token has expired: {payload.get('sub', 'unknown')}")
            raise HTTPException(
                status_code=401,
                detail="Token has expired",
                headers={"WWW-Authenticate": "Bearer"},
            )

        logger.debug(
            f"Successfully validated token for: {payload.get('sub', 'unknown')}"
        )
        return payload

    except jwt.ExpiredSignatureError:
        logger.warning("Token signature has expired")
        raise HTTPException(
            status_code=401,
            detail="Token has expired",
            headers={"WWW-Authenticate": "Bearer"},
        )
    except jwt.InvalidTokenError as e:
        logger.warning(f"Invalid token: {str(e)}")
        raise HTTPException(
            status_code=401,
            detail=f"Invalid token: {str(e)}",
            headers={"WWW-Authenticate": "Bearer"},
        )


async def get_current_service(
    token_data: Dict = Depends(validate_token),
) -> str:
    """
    Get the service name from the authenticated token.

    Args:
        token_data: Validated token data

    Returns:
        Service name from token

    Raises:
        HTTPException: If service is not found in token
    """
    if "service" not in token_data:
        logger.warning("Invalid token claims: service missing")
        raise HTTPException(
            status_code=401, detail="Invalid token claims: service missing"
        )

    service = token_data["service"]
    logger.debug(f"Authenticated service: {service}")
    return service


async def requires_scope(
    required_scope: str, token_data: Dict = Depends(validate_token)
) -> bool:
    """
    Check if token has the required scope.

    Args:
        required_scope: Scope required for access
        token_data: Validated token data

    Returns:
        True if token has required scope

    Raises:
        HTTPException: If token does not have required scope
    """
    if "scope" not in token_data:
        logger.warning("Token missing scope claim")
        raise HTTPException(
            status_code=403, detail="Insufficient permissions: missing scope claim"
        )

    scopes = token_data["scope"].split()

    if required_scope not in scopes:
        logger.warning(f"Token missing required scope: {required_scope}")
        raise HTTPException(
            status_code=403,
            detail=f"Insufficient permissions: required scope '{required_scope}' not granted",
        )

    return True


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/__init__.py
"""
Utility modules for Data Capture Rightmove Service.

Exports utilities for logging, rate limiting, security, and other common functions.
"""

from data_capture_rightmove_service.utils.logging_config import (
    configure_logging,
    logger,
)
from data_capture_rightmove_service.utils.rate_limiting import limiter
from data_capture_rightmove_service.utils.security import (
    get_current_service,
    requires_scope,
    validate_token,
)

__all__ = [
    "configure_logging",
    "logger",
    "limiter",
    "validate_token",
    "get_current_service",
    "requires_scope",
]


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/url_parsing.py
"""
Utility functions for parsing URLs and extracting useful information.
"""

import re
from typing import Optional, Tuple
from urllib.parse import urlparse

# Regex pattern for extracting property ID from Rightmove URLs
# Matches patterns like:
# - https://www.rightmove.co.uk/properties/154508327
# - https://www.rightmove.co.uk/properties/154508327#/?channel=RES_LET
RIGHTMOVE_PROPERTY_ID_PATTERN = r"rightmove\.co\.uk/properties/(\d+)"


def extract_rightmove_property_id(url: str) -> Optional[int]:
    """
    Extract the property ID from a Rightmove URL.
    
    Args:
        url: A Rightmove property URL
        
    Returns:
        int: The extracted property ID, or None if not found
        
    Examples:
        >>> extract_rightmove_property_id("https://www.rightmove.co.uk/properties/154508327#/?channel=RES_LET")
        154508327
        >>> extract_rightmove_property_id("https://www.rightmove.co.uk/properties/123456789")
        123456789
    """
    if not url:
        return None
    
    # Parse URL to validate it's a proper URL
    try:
        parsed_url = urlparse(url)
        if not parsed_url.netloc or "rightmove.co.uk" not in parsed_url.netloc.lower():
            return None
    except Exception:
        return None
        
    # Extract property ID using regex
    match = re.search(RIGHTMOVE_PROPERTY_ID_PATTERN, url)
    if match and match.group(1):
        try:
            return int(match.group(1))
        except ValueError:
            return None
            
    return None


def is_valid_rightmove_url(url: str) -> bool:
    """
    Check if a URL is a valid Rightmove property URL.
    
    Args:
        url: URL to check
        
    Returns:
        bool: True if the URL is a valid Rightmove property URL, False otherwise
    """
    if not url:
        return False
        
    # First validate it's a proper URL with rightmove.co.uk domain
    try:
        parsed_url = urlparse(url)
        if not parsed_url.netloc or "rightmove.co.uk" not in parsed_url.netloc.lower():
            return False
    except Exception:
        return False
    
    # Check if it has a property ID
    return extract_rightmove_property_id(url) is not None


def determine_rightmove_api_endpoints(url: str) -> Tuple[str, str]:
    """
    Determine which Rightmove API endpoints to use based on the URL structure.
    
    Args:
        url: A Rightmove property URL
        
    Returns:
        Tuple[str, str]: A tuple of (primary_endpoint, secondary_endpoint)
        Where primary is the preferred endpoint to try first
    """
    if not url:
        return ("properties_details", "property_for_sale")
    
    # Default choice
    primary = "properties_details"
    secondary = "property_for_sale"
    
    # If the URL contains keywords indicating it's a property for sale,
    # prioritize the property-for-sale endpoint
    url_lower = url.lower()
    if "property-for-sale" in url_lower or "for-sale" in url_lower:
        primary, secondary = secondary, primary
    
    return (primary, secondary)


# data_capture_rightmove_service/src/data_capture_rightmove_service/utils/db_utils.py
"""
Database utility functions to help bridge the gap between API responses and database models.
"""

from typing import Dict, Any, Optional, Type
import logging

logger = logging.getLogger(__name__)

def normalize_model_instance(model_class, data: dict) -> dict:
    """
    Normalizes data for a model instance by mapping API response field names to model attributes.
    Handles cases where SQLAlchemy model attributes differ from database column names
    due to the use of the 'name' parameter in Column definitions.
    
    Args:
        model_class: SQLAlchemy model class
        data: Dictionary of data to normalize
        
    Returns:
        Dict of normalized data that can be passed to the model constructor
    """
    # Create a copy to avoid modifying the original
    normalized_data = data.copy()
    
    # Extract column information directly from SQLAlchemy model
    # This includes the Python attribute name and the actual DB column name mapping
    model_columns = {}
    python_attr_to_db_column = {}
    db_column_to_python_attr = {}
    
    # Build a list of all valid attribute names from the model class
    model_attrs = set()
    
    # Create mappings between API fields and Python attributes
    # First create a mapping of both ways between Python attributes and DB column names
    for column in model_class.__table__.columns:
        python_attr = column.key  # Python attribute name as defined in the model (e.g., brand_name)
        db_column = column.name   # DB column name (e.g., brandName)
        
        # Add to our set of valid model attribute names
        model_attrs.add(python_attr)
        
        # Store info about each column
        model_columns[python_attr] = {
            'type': str(column.type),
            'db_column': db_column
        }
        
        # Create bidirectional maps (case-insensitive for easier matching)
        python_attr_to_db_column[python_attr.lower()] = db_column
        db_column_to_python_attr[db_column.lower()] = python_attr
    
    logger.debug(f"Model {model_class.__name__} has {len(model_columns)} columns")
    logger.debug(f"Python attributes for {model_class.__name__}: {sorted(model_attrs)[:5]}...")
    
    # Create a clean dictionary with the correct attribute names
    clean_values = {}
    unmapped_keys = []
    
    # Process all fields from the input data
    for api_field, value in normalized_data.items():
        # Don't process keys we've already mapped
        if api_field in clean_values:
            continue
            
        # 1. Direct exact match with model Python attribute
        if api_field in model_attrs:
            clean_values[api_field] = value
            logger.debug(f"Direct match: API field '{api_field}' -> model attr '{api_field}'")
            continue
            
        # 2. Try to match with DB column names (which may differ from Python attributes)
        api_field_lower = api_field.lower()
        if api_field_lower in db_column_to_python_attr:
            # Found a match where API field matches a DB column name
            attr_name = db_column_to_python_attr[api_field_lower]
            if attr_name not in clean_values:  # Don't overwrite direct matches
                logger.debug(f"DB column match: API field '{api_field}' -> model attr '{attr_name}'")
                clean_values[attr_name] = value
            continue
                
        # 3. Case-insensitive match with model attributes
        matching_attrs = [attr for attr in model_attrs if attr.lower() == api_field_lower]
        if matching_attrs:
            attr_name = matching_attrs[0]  # Use the first match
            if attr_name not in clean_values:
                logger.debug(f"Case-insensitive match: API field '{api_field}' -> model attr '{attr_name}'")
                clean_values[attr_name] = value
            continue
                
        # If we get here, we couldn't map this field at all
        unmapped_keys.append(api_field)
    
    # Log any unmapped keys
    if unmapped_keys:
        logger.debug(f"Unmapped keys for {model_class.__name__}: {unmapped_keys[:10]}...")
    
    # Special handling for known types
    for attr_name in list(clean_values.keys()):
        value = clean_values[attr_name]
        
        # Handle array fields
        if 'ARRAY' in model_columns.get(attr_name, {}).get('type', ''):
            if value is None:
                clean_values[attr_name] = []
            elif isinstance(value, str):
                clean_values[attr_name] = [value]
            elif not isinstance(value, list):
                try:
                    clean_values[attr_name] = list(value)
                except Exception as e:
                    logger.warning(f"Could not convert {attr_name} to list: {str(e)}, using empty list")
                    clean_values[attr_name] = []
        
        # Handle JSON/JSONB fields
        elif 'JSON' in model_columns.get(attr_name, {}).get('type', ''):
            if not isinstance(value, dict) and value is not None:
                try:
                    if isinstance(value, str):
                        import json
                        clean_values[attr_name] = json.loads(value)
                    else:
                        clean_values[attr_name] = dict(value)
                except Exception as e:
                    logger.warning(f"Could not convert {attr_name} to dict: {str(e)}, using empty dict")
                    clean_values[attr_name] = {}
    
    return clean_values


# data_capture_rightmove_service/src/data_capture_rightmove_service/models/scrape_event.py
import enum

from sqlalchemy import BigInteger, Column, DateTime
from sqlalchemy import Enum as SAEnum
from sqlalchemy import Integer, String, Text
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy.sql import func

from .base import Base


class ScrapeEventTypeEnum(enum.Enum):
    REQUEST_RECEIVED = "REQUEST_RECEIVED"
    API_CALL_ATTEMPT = "API_CALL_ATTEMPT"
    API_CALL_SUCCESS = "API_CALL_SUCCESS"
    API_CALL_FAILURE = "API_CALL_FAILURE"
    DATA_PARSED_SUCCESS = "DATA_PARSED_SUCCESS"
    DATA_PARSED_FAILURE = "DATA_PARSED_FAILURE"
    DATA_STORED_SUCCESS = "DATA_STORED_SUCCESS"
    DATA_STORED_FAILURE = "DATA_STORED_FAILURE"


class ScrapeEvent(Base):
    __tablename__ = "scrape_events"

    id = Column(BigInteger, primary_key=True)
    super_id = Column(UUID(as_uuid=True), nullable=False, index=True)
    rightmove_property_id = Column(BigInteger, index=True)

    event_type = Column(SAEnum(ScrapeEventTypeEnum), nullable=False, index=True)
    event_timestamp = Column(
        DateTime(timezone=True), server_default=func.now(), nullable=False
    )

    source_service_name = Column(Text)
    api_endpoint_called = Column(Text)

    http_status_code = Column(Integer)
    error_code = Column(Text)
    error_message = Column(Text)

    payload = Column(JSONB)  # Stores request params or API response

    response_item_count = Column(Integer)
    response_null_item_count = Column(Integer)

    created_at = Column(
        DateTime(timezone=True), server_default=func.now(), nullable=False
    )


# data_capture_rightmove_service/src/data_capture_rightmove_service/models/__init__.py
"""
Database models for the Data Capture Rightmove Service.
"""

from data_capture_rightmove_service.models.base import Base, SuperIdMixin
from data_capture_rightmove_service.models.properties_details_v2 import *
from data_capture_rightmove_service.models.property_details import *
from data_capture_rightmove_service.models.scrape_event import (
    ScrapeEvent,
    ScrapeEventTypeEnum,
)

# Export all models to make them discoverable by Alembic's 'import *'
__all__ = [
    "Base",
    "SuperIdMixin",
    # Models from properties_details_v2
    "ApiPropertiesDetailsV2",
    "ApiPropertiesDetailsV2Misinfo",
    "ApiPropertiesDetailsV2Status",
    "ApiPropertiesDetailsV2StampDuty",
    "ApiPropertiesDetailsV2Features",
    "ApiPropertiesDetailsV2Branch",
    "ApiPropertiesDetailsV2Brochure",
    "ApiPropertiesDetailsV2Price",
    "ApiPropertiesDetailsV2LocalTax",
    "ApiPropertiesDetailsV2Location",
    "ApiPropertiesDetailsV2SalesInfo",
    "ApiPropertiesDetailsV2Size",
    "ApiPropertiesDetailsV2Mortgage",
    "ApiPropertiesDetailsV2AnalyticsInfo",
    "ApiPropertiesDetailsV2Station",
    "ApiPropertiesDetailsV2Photo",
    "ApiPropertiesDetailsV2Epc",
    "ApiPropertiesDetailsV2Floorplan",
    "ApiPropertiesDetailsV2FeatureRisks",
    "ApiPropertiesDetailsV2FeatureObligations",
    "ApiPropertiesDetailsV2BrochureItem",
    "ApiPropertiesDetailsV2LocationStreetview",
    # Models from property_details
    "ApiPropertyDetails",
    "ApiPropertyDetailAddress",
    "ApiPropertyDetailBroadband",
    "ApiPropertyDetailContactInfo",
    "ApiPropertyDetailContactInfoTelephoneNumber",
    "ApiPropertyDetailCustomer",
    "ApiPropertyDetailCustomerDescription",
    "ApiPropertyDetailCustomerDevelopmentInfo",
    "ApiPropertyDetailCustomerProduct",
    "ApiPropertyDetailDfpAdInfo",
    "ApiPropertyDetailFloorplan",
    "ApiPropertyDetailFloorplanResizedUrl",
    "ApiPropertyDetailImage",
    "ApiPropertyDetailImageResizedUrl",
    "ApiPropertyDetailIndustryAffiliation",
    "ApiPropertyDetailInfoReelItem",
    "ApiPropertyDetailListingHistory",
    "ApiPropertyDetailLivingCost",
    "ApiPropertyDetailLocation",
    "ApiPropertyDetailMisInfo",
    "ApiPropertyDetailMortgageCalculator",
    "ApiPropertyDetailNearestStation",
    "ApiPropertyDetailNearestStationType",
    "ApiPropertyDetailPrice",
    "ApiPropertyDetailPropertyUrl",
    "ApiPropertyDetailSharedOwnership",
    "ApiPropertyDetailStaticMapImgUrl",
    "ApiPropertyDetailStatus",
    "ApiPropertyDetailStreetView",
    "ApiPropertyDetailTenure",
    "ApiPropertyDetailText",
    # Models from scrape_event
    "ScrapeEvent",
    "ScrapeEventTypeEnum",
]


# data_capture_rightmove_service/src/data_capture_rightmove_service/models/property_details.py
"""
Models for the Rightmove property-for-sale/detail API endpoint data.

--- MODIFICATION LOG ---
This file has been updated to support an insert-only, historical snapshot architecture.
Key Changes:
1.  The primary key on the main `ApiPropertyDetails` table is now `snapshot_id` (auto-incrementing).
2.  The Rightmove property ID is stored in the `id` column, which is now non-unique and indexed.
3.  All child tables now use `api_property_snapshot_id` to link to a specific historical record.
4.  All child tables also include a denormalized `api_property_id` for easy querying across all historical
    data for a single property, as per the original requirement.
"""

from sqlalchemy import (
    ARRAY,
    BigInteger,
    Boolean,
    Column,
    ForeignKey,
    Integer,
    Numeric,
    String,
    Text,
)
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm import relationship

from data_capture_rightmove_service.models.base import Base, SuperIdMixin


class ApiPropertyDetails(Base, SuperIdMixin):
    __tablename__ = "api_property_details"

    # --- MODIFICATION: Primary key is now a unique, auto-incrementing "snapshot" ID ---
    snapshot_id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION: The Rightmove property ID is now a regular, indexed, non-unique column ---
    id = Column(BigInteger, index=True, nullable=False)

    affordable_buying_scheme = Column(Boolean)
    ai_location_info = Column(Text)
    bathrooms = Column(Integer)
    bedrooms = Column(Integer)
    business_for_sale = Column(Boolean)
    channel = Column(String(50))
    commercial = Column(Boolean)
    country_guide = Column(Text)
    enc_id = Column(Text)
    fees_apply = Column(JSONB)
    lettings = Column(JSONB)
    property_sub_type = Column(Text)
    show_school_info = Column(Boolean)
    sold_property_type = Column(String(100))
    terms_of_use = Column(Text)
    transaction_type = Column(String(50))
    brochures = Column(JSONB)
    commercial_use_classes = Column(ARRAY(Text))
    epc_graphs = Column(JSONB)
    key_features = Column(ARRAY(Text))
    nearest_airports = Column(ARRAY(Text))
    rooms = Column(ARRAY(Text))
    sizings = Column(JSONB)
    tags = Column(ARRAY(Text))

    # Relationships
    address = relationship(
        "ApiPropertyDetailAddress",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    broadband = relationship(
        "ApiPropertyDetailBroadband",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    contact_info = relationship(
        "ApiPropertyDetailContactInfo",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    customer = relationship(
        "ApiPropertyDetailCustomer",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    dfp_ad_info = relationship(
        "ApiPropertyDetailDfpAdInfo",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    floorplans = relationship(
        "ApiPropertyDetailFloorplan",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    images = relationship(
        "ApiPropertyDetailImage",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    industry_affiliations = relationship(
        "ApiPropertyDetailIndustryAffiliation",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    info_reel_items = relationship(
        "ApiPropertyDetailInfoReelItem",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    listing_history = relationship(
        "ApiPropertyDetailListingHistory",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    living_costs = relationship(
        "ApiPropertyDetailLivingCost",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    location = relationship(
        "ApiPropertyDetailLocation",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    mis_info = relationship(
        "ApiPropertyDetailMisInfo",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    mortgage_calculator = relationship(
        "ApiPropertyDetailMortgageCalculator",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    nearest_stations = relationship(
        "ApiPropertyDetailNearestStation",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    price = relationship(
        "ApiPropertyDetailPrice",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    property_urls = relationship(
        "ApiPropertyDetailPropertyUrl",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    shared_ownership = relationship(
        "ApiPropertyDetailSharedOwnership",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    static_map_img_urls = relationship(
        "ApiPropertyDetailStaticMapImgUrl",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    status = relationship(
        "ApiPropertyDetailStatus",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    street_view = relationship(
        "ApiPropertyDetailStreetView",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    tenure = relationship(
        "ApiPropertyDetailTenure",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    text = relationship(
        "ApiPropertyDetailText",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )


class ApiPropertyDetailAddress(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_addresses"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    country_code = Column(String(10))
    delivery_point_id = Column(BigInteger)
    display_address = Column(Text)
    incode = Column(String(10))
    outcode = Column(String(10))
    uk_country = Column(String(100))
    property = relationship("ApiPropertyDetails", back_populates="address")


class ApiPropertyDetailBroadband(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_broadbands"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    broadband_checker_url = Column(Text)
    disclaimer = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="broadband")


class ApiPropertyDetailContactInfo(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_contact_infos"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    contact_method = Column(String(100))
    property = relationship("ApiPropertyDetails", back_populates="contact_info")
    telephone_numbers = relationship(
        "ApiPropertyDetailContactInfoTelephoneNumber",
        back_populates="contact_info",
        uselist=False,
        cascade="all, delete-orphan",
    )


class ApiPropertyDetailCustomerProduct(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_customer_products"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    customer_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_detail_customers.id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    has_microsite = Column(Boolean)
    customer = relationship("ApiPropertyDetailCustomer", back_populates="products")


class ApiPropertyDetailContactInfoTelephoneNumber(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_contact_info_telephone_numbers"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    contact_info_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_property_detail_contact_infos.id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    disclaimer_description = Column(Text)
    disclaimer_text = Column(Text)
    disclaimer_title = Column(Text)
    international_number = Column(String(50))
    local_number = Column(String(50))
    contact_info = relationship(
        "ApiPropertyDetailContactInfo", back_populates="telephone_numbers"
    )


class ApiPropertyDetailCustomer(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_customers"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    banner_ad = Column(Text)
    branch_display_name = Column(String(255))
    branch_id = Column(Integer)
    branch_name = Column(String(255))
    build_to_rent = Column(Boolean)
    build_to_rent_benefits = Column(ARRAY(Text))
    commercial = Column(Boolean)
    company_name = Column(String(255))
    company_trading_name = Column(String(255))
    customer_banner_ad_profile_url = Column(Text)
    customer_mpu_ad_profile_url = Column(Text)
    customer_profile_url = Column(Text)
    customer_properties_url = Column(Text)
    display_address = Column(Text)
    is_new_home_developer = Column(Boolean)
    logo_path = Column(Text)
    mpu_ad = Column(Text)
    show_brochure_lead_modal = Column(Boolean)
    spotlight = Column(Text)
    valuation_form_url = Column(Text)
    video_enabled = Column(Boolean)
    video_url = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="customer")
    description = relationship(
        "ApiPropertyDetailCustomerDescription",
        back_populates="customer",
        uselist=False,
        cascade="all, delete-orphan",
    )
    development_info = relationship(
        "ApiPropertyDetailCustomerDevelopmentInfo",
        back_populates="customer",
        uselist=False,
        cascade="all, delete-orphan",
    )
    products = relationship(
        "ApiPropertyDetailCustomerProduct",
        back_populates="customer",
        uselist=False,
        cascade="all, delete-orphan",
    )


class ApiPropertyDetailCustomerDescription(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_customer_descriptions"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    customer_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_detail_customers.id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    is_truncated = Column(Boolean)
    truncated_description_html = Column(Text)
    customer = relationship("ApiPropertyDetailCustomer", back_populates="description")


class ApiPropertyDetailCustomerDevelopmentInfo(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_customer_development_infos"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    customer_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_detail_customers.id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    site_plan_uri = Column(Text)
    microsite_features = Column(ARRAY(Text))
    customer = relationship(
        "ApiPropertyDetailCustomer", back_populates="development_info"
    )


class ApiPropertyDetailDfpAdInfo(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_dfp_ad_infos"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    channel = Column(String(50))
    targeting = Column(JSONB)  # API returns array of objects, JSONB is flexible
    property = relationship("ApiPropertyDetails", back_populates="dfp_ad_info")


class ApiPropertyDetailFloorplan(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_floorplans"
    id = Column(Integer, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    caption = Column(String(255))
    type = Column(String(50))
    url = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="floorplans")
    resized_floorplan_urls = relationship(
        "ApiPropertyDetailFloorplanResizedUrl",
        back_populates="floorplan",
        uselist=False,
        cascade="all, delete-orphan",
    )


class ApiPropertyDetailFloorplanResizedUrl(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_floorplan_resized_floorplan_urls"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    floorplan_id = Column(
        Integer,
        ForeignKey("rightmove.api_property_detail_floorplans.id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    size_296x197 = Column(Text)
    floorplan = relationship(
        "ApiPropertyDetailFloorplan", back_populates="resized_floorplan_urls"
    )


class ApiPropertyDetailImage(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_images"
    id = Column(Integer, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    caption = Column(String(255))
    url = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="images")
    resized_image_urls = relationship(
        "ApiPropertyDetailImageResizedUrl",
        back_populates="image",
        uselist=False,
        cascade="all, delete-orphan",
    )


class ApiPropertyDetailImageResizedUrl(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_image_resized_image_urls"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    image_id = Column(
        Integer,
        ForeignKey("rightmove.api_property_detail_images.id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    size_135x100 = Column(Text)
    size_476x317 = Column(Text)
    size_656x437 = Column(Text)
    image = relationship("ApiPropertyDetailImage", back_populates="resized_image_urls")


class ApiPropertyDetailIndustryAffiliation(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_industry_affiliations"
    id = Column(Integer, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    image_path = Column(Text)
    name = Column(Text)
    property = relationship(
        "ApiPropertyDetails", back_populates="industry_affiliations"
    )


class ApiPropertyDetailInfoReelItem(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_info_reel_items"
    id = Column(Integer, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    primary_text = Column(Text)
    secondary_text = Column(Text)
    title = Column(Text)
    tooltip_text = Column(Text)
    type = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="info_reel_items")


class ApiPropertyDetailListingHistory(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_listing_history"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    listing_update_reason = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="listing_history")


class ApiPropertyDetailLivingCost(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_living_costs"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    annual_ground_rent = Column(Text)
    annual_service_charge = Column(Text)
    council_tax_band = Column(String(10))
    council_tax_exempt = Column(Boolean)
    council_tax_included = Column(Boolean)
    domestic_rates = Column(Text)
    ground_rent_percentage_increase = Column(Text)
    ground_rent_review_period_in_years = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="living_costs")


class ApiPropertyDetailLocation(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_locations"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    circle_radius_on_map = Column(Integer)
    latitude = Column(Numeric(10, 8))
    longitude = Column(Numeric(11, 8))
    pin_type = Column(String(50))
    show_map = Column(Boolean)
    zoom_level = Column(Integer)
    property = relationship("ApiPropertyDetails", back_populates="location")


class ApiPropertyDetailMisInfo(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_mis_infos"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    branch_id = Column(Integer)
    brand_plus = Column(Boolean)
    featured_property = Column(Boolean)
    offer_advert_stamp_type_id = Column(Text)
    premium_display = Column(Boolean)
    premium_display_stamp_id = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="mis_info")


class ApiPropertyDetailMortgageCalculator(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_mortgage_calculators"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    price = Column(BigInteger)
    property_type_alias = Column(String(100))
    property = relationship("ApiPropertyDetails", back_populates="mortgage_calculator")


class ApiPropertyDetailNearestStation(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_nearest_stations"
    id = Column(Integer, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    distance = Column(Numeric(18, 16))
    name = Column(Text)
    unit = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="nearest_stations")
    types = relationship(
        "ApiPropertyDetailNearestStationType",
        back_populates="station",
        cascade="all, delete-orphan",
    )


class ApiPropertyDetailNearestStationType(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_nearest_station_types"
    id = Column(Integer, primary_key=True, autoincrement=True)
    station_id = Column(
        Integer,
        ForeignKey(
            "rightmove.api_property_detail_nearest_stations.id", ondelete="CASCADE"
        ),
        nullable=False,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    type = Column(String(100))
    station = relationship("ApiPropertyDetailNearestStation", back_populates="types")


class ApiPropertyDetailPrice(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_prices"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    display_price_qualifier = Column(String(255))
    exchange_rate = Column(Text)
    message = Column(Text)
    price_per_sq_ft = Column(String(100))
    primary_price = Column(String(100))
    secondary_price = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="price")


class ApiPropertyDetailPropertyUrl(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_property_urls"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    nearby_sold_properties_url = Column(Text)
    similar_properties_url = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="property_urls")


class ApiPropertyDetailSharedOwnership(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_shared_ownerships"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    ownership_percentage = Column(Numeric(10, 4))
    rent_frequency = Column(String(100))
    rent_price = Column(Numeric(12, 2))
    shared_ownership = Column(Boolean)  # API field is 'sharedOwnership'
    property = relationship("ApiPropertyDetails", back_populates="shared_ownership")


class ApiPropertyDetailStaticMapImgUrl(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_static_map_img_urls"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    static_map_img_url_desktop_large = Column(Text)
    static_map_img_url_desktop_small = Column(Text)
    static_map_img_url_mobile = Column(Text)
    static_map_img_url_tablet = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="static_map_img_urls")


class ApiPropertyDetailStatus(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_status"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    archived = Column(Boolean)
    published = Column(Boolean)
    property = relationship("ApiPropertyDetails", back_populates="status")


class ApiPropertyDetailStreetView(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_street_views"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    heading = Column(Text)
    latitude = Column(Numeric(10, 8))
    longitude = Column(Numeric(11, 8))
    pitch = Column(Text)
    zoom = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="street_view")


class ApiPropertyDetailTenure(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_tenures"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    message = Column(Text)
    tenure_type = Column(String(100))
    years_remaining_on_lease = Column(Integer)
    property = relationship("ApiPropertyDetails", back_populates="tenure")


class ApiPropertyDetailText(Base, SuperIdMixin):
    __tablename__ = "api_property_detail_texts"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey("rightmove.api_property_details.snapshot_id", ondelete="CASCADE"),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    auction_fees_disclaimer = Column(Text)
    description = Column(Text)
    disclaimer = Column(Text)
    guide_price_disclaimer = Column(Text)
    new_homes_brochure_disclaimer = Column(Text)
    page_title = Column(Text)
    property_phrase = Column(String(255))
    reserve_price_disclaimer = Column(Text)
    share_description = Column(Text)
    share_text = Column(Text)
    short_description = Column(Text)
    static_map_disclaimer_text = Column(Text)
    property = relationship("ApiPropertyDetails", back_populates="text")


# data_capture_rightmove_service/src/data_capture_rightmove_service/models/properties_details_v2.py
"""
Models for the Rightmove properties/details v2 API endpoint data.
This module defines SQLAlchemy models that map to the tables in the rightmove schema.

--- MODIFICATION LOG ---
This file has been updated to support an insert-only, historical snapshot architecture.
Key Changes:
1.  The primary key on the main `ApiPropertiesDetailsV2` table is now `snapshot_id` (auto-incrementing).
2.  The Rightmove property ID is stored in the `id` column, which is now non-unique and indexed.
3.  All child tables now use `api_property_snapshot_id` to link to a specific historical record.
4.  All child tables also include a denormalized `api_property_id` for easy querying across all historical
    data for a single property, as per the original requirement.
"""

from sqlalchemy import (
    ARRAY,
    TIMESTAMP,
    BigInteger,
    Boolean,
    Column,
    ForeignKey,
    Integer,
    Numeric,
    String,
    Text,
)
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm import relationship

from data_capture_rightmove_service.models.base import Base, SuperIdMixin


class ApiPropertiesDetailsV2(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2"

    # --- MODIFICATION: Primary key is now a unique, auto-incrementing "snapshot" ID ---
    snapshot_id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION: The Rightmove property ID is now a regular, indexed, non-unique column ---
    id = Column(BigInteger, index=True, nullable=False)

    transaction_type = Column(String(50))
    channel = Column(String(50))
    bedrooms = Column(Integer)
    bathrooms = Column(Integer)
    address = Column(Text)
    contact_method = Column(String(50))
    property_disclaimer = Column(Text)
    property_phrase = Column(String(255))
    full_description = Column(Text)
    listing_update_reason = Column(String(255))
    property_url = Column(Text)
    school_checker_url = Column(Text)
    lettings_info = Column(JSONB)
    property_display_type = Column(String(100))
    telephone_number = Column(String(50))
    saved = Column(Boolean)
    sold_prices_url = Column(Text)
    market_info_url = Column(Text)
    note = Column(Text)
    link_to_glossary = Column(Text)
    enquired_timestamp = Column(TIMESTAMP(timezone=True), nullable=True)
    key_features = Column(ARRAY(Text))
    tags = Column(ARRAY(Text))
    virtual_tours = Column(JSONB)

    # Relationships
    misinfo = relationship(
        "ApiPropertiesDetailsV2Misinfo",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    status = relationship(
        "ApiPropertiesDetailsV2Status",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    stamp_duty = relationship(
        "ApiPropertiesDetailsV2StampDuty",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    features = relationship(
        "ApiPropertiesDetailsV2Features",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    branch = relationship(
        "ApiPropertiesDetailsV2Branch",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    brochure = relationship(
        "ApiPropertiesDetailsV2Brochure",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    price = relationship(
        "ApiPropertiesDetailsV2Price",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    local_tax = relationship(
        "ApiPropertiesDetailsV2LocalTax",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    location = relationship(
        "ApiPropertiesDetailsV2Location",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    sales_info = relationship(
        "ApiPropertiesDetailsV2SalesInfo",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    size = relationship(
        "ApiPropertiesDetailsV2Size",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    mortgage = relationship(
        "ApiPropertiesDetailsV2Mortgage",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    analytics_info = relationship(
        "ApiPropertiesDetailsV2AnalyticsInfo",
        back_populates="property",
        uselist=False,
        cascade="all, delete-orphan",
    )
    stations = relationship(
        "ApiPropertiesDetailsV2Station",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    photos = relationship(
        "ApiPropertiesDetailsV2Photo",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    epcs = relationship(
        "ApiPropertiesDetailsV2Epc",
        back_populates="property",
        cascade="all, delete-orphan",
    )
    floorplans = relationship(
        "ApiPropertiesDetailsV2Floorplan",
        back_populates="property",
        cascade="all, delete-orphan",
    )


class ApiPropertiesDetailsV2Misinfo(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_mis_info"

    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    branch_id = Column(Integer)
    offer_advert_stamp_type_id = Column(Text)
    brand_plus = Column(Boolean)
    featured_property = Column(Boolean)
    channel = Column(String(50))
    premium_display = Column(Boolean)
    premium_display_stamp_id = Column(Text)
    country_code = Column(String(10))
    property = relationship("ApiPropertiesDetailsV2", back_populates="misinfo")


class ApiPropertiesDetailsV2Status(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_status"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    available = Column(Boolean)
    label = Column(Text)
    property = relationship("ApiPropertiesDetailsV2", back_populates="status")


class ApiPropertiesDetailsV2StampDuty(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_stamp_duty"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    country = Column(String(100))
    price = Column(BigInteger)
    buyer_type = Column(Text)
    result = Column(Text)
    property = relationship("ApiPropertiesDetailsV2", back_populates="stamp_duty")


class ApiPropertiesDetailsV2Features(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_features"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    electricity = Column(JSONB)
    broadband = Column(JSONB)
    water = Column(JSONB)
    sewerage = Column(JSONB)
    heating = Column(JSONB)
    accessibility = Column(JSONB)
    parking = Column(JSONB)
    garden = Column(JSONB)
    property = relationship("ApiPropertiesDetailsV2", back_populates="features")
    risks = relationship(
        "ApiPropertiesDetailsV2FeatureRisks",
        back_populates="feature",
        uselist=False,
        cascade="all, delete-orphan",
    )
    obligations = relationship(
        "ApiPropertiesDetailsV2FeatureObligations",
        back_populates="feature",
        uselist=False,
        cascade="all, delete-orphan",
    )


class ApiPropertiesDetailsV2Branch(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_branch"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    identifier = Column(Integer)
    name = Column(String(255))
    brand_name = Column(String(255))
    display_name = Column(String(255))
    address = Column(Text)
    logo = Column(Text)
    developer = Column(Boolean)
    property = relationship("ApiPropertiesDetailsV2", back_populates="branch")


class ApiPropertiesDetailsV2Brochure(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_brochure"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    title = Column(String(255))
    show_brochure_lead = Column(Boolean)
    property = relationship("ApiPropertiesDetailsV2", back_populates="brochure")
    items = relationship(
        "ApiPropertiesDetailsV2BrochureItem",
        back_populates="brochure",
        cascade="all, delete-orphan",
    )


class ApiPropertiesDetailsV2BrochureItem(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_brochure_items"
    id = Column(Integer, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    brochure_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2_brochure.id", ondelete="CASCADE"
        ),
        nullable=False,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    url = Column(Text)
    caption = Column(String(255))
    brochure = relationship("ApiPropertiesDetailsV2Brochure", back_populates="items")


class ApiPropertiesDetailsV2Price(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_price"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    primary_price = Column(String(100))
    secondary_price = Column(String(255))
    property = relationship("ApiPropertiesDetailsV2", back_populates="price")


class ApiPropertiesDetailsV2LocalTax(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_local_tax"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    type = Column(String(100))
    status = Column(Text)
    value = Column(String(100))
    property = relationship("ApiPropertiesDetailsV2", back_populates="local_tax")


class ApiPropertiesDetailsV2Location(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_location"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    pin_type = Column(String(100))
    latitude = Column(Numeric(10, 8))
    longitude = Column(Numeric(11, 8))
    map_preview_url = Column(Text)
    property = relationship("ApiPropertiesDetailsV2", back_populates="location")
    streetview = relationship(
        "ApiPropertiesDetailsV2LocationStreetview",
        back_populates="location",
        uselist=False,
        cascade="all, delete-orphan",
    )


class ApiPropertiesDetailsV2LocationStreetview(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_location_street_view"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    location_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2_location.id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    latitude = Column(Numeric(10, 8))
    longitude = Column(Numeric(11, 8))
    heading = Column(Text)
    pitch = Column(Text)
    zoom = Column(Text)
    url = Column(Text)
    location = relationship(
        "ApiPropertiesDetailsV2Location", back_populates="streetview"
    )


class ApiPropertiesDetailsV2SalesInfo(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_sales_info"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    tenure_type = Column(String(100))
    tenure_display_type = Column(String(100))
    ground_rent = Column(Text)
    annual_service_charge = Column(Text)
    estate_charge = Column(Text)
    length_of_lease = Column(Text)
    shared_ownership_percentage = Column(Text)
    shared_ownership_rent = Column(Text)
    property = relationship("ApiPropertiesDetailsV2", back_populates="sales_info")


class ApiPropertiesDetailsV2Size(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_size"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    primary_size = Column(String(100))
    secondary_size = Column(Text)
    property = relationship("ApiPropertiesDetailsV2", back_populates="size")


class ApiPropertiesDetailsV2Mortgage(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_mortgage"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    price = Column(BigInteger)
    property_type_alias = Column(String(100))
    property = relationship("ApiPropertiesDetailsV2", back_populates="mortgage")


class ApiPropertiesDetailsV2AnalyticsInfo(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_analytics_info"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    branch_id = Column(String(50))
    property_id = Column(
        String(50)
    )  # Note: This is a string field from the API, distinct from our integer ID
    online_viewing = Column(String(10))
    image_count = Column(String(10))
    floorplan_count = Column(String(10))
    beds = Column(String(10))
    postcode = Column(String(20))
    property_type = Column(String(100))
    property_sub_type = Column(String(100))
    added = Column(String(20))
    price = Column(String(50))
    tenure = Column(String(100))
    bathrooms = Column(String(10))
    shared_ownership = Column(String(10))
    electricity = Column(String(50))
    broadband = Column(String(50))
    water = Column(String(50))
    sewerage = Column(String(50))
    heating = Column(String(50))
    accessibility = Column(String(50))
    parking = Column(String(50))
    garden = Column(String(50))
    flood_history = Column(String(50))
    flood_defences = Column(String(50))
    flood_risk = Column(String(50))
    listed = Column(String(50))
    restrictions = Column(String(50))
    private_access = Column(String(50))
    public_access = Column(String(50))
    property = relationship("ApiPropertiesDetailsV2", back_populates="analytics_info")


class ApiPropertiesDetailsV2Station(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_stations"
    id = Column(Integer, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    station = Column(String(255))
    distance = Column(Numeric(8, 2))
    type = Column(String(50))
    property = relationship("ApiPropertiesDetailsV2", back_populates="stations")


class ApiPropertiesDetailsV2Photo(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_photos"
    id = Column(Integer, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    url = Column(Text)
    thumbnail_url = Column(Text)
    max_size_url = Column(Text)
    caption = Column(Text)
    property = relationship("ApiPropertiesDetailsV2", back_populates="photos")


class ApiPropertiesDetailsV2Epc(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_epcs"
    id = Column(Integer, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    url = Column(Text)
    caption = Column(String(255))
    property = relationship("ApiPropertiesDetailsV2", back_populates="epcs")


class ApiPropertiesDetailsV2Floorplan(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_floorplans"
    id = Column(Integer, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    api_property_snapshot_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2.snapshot_id", ondelete="CASCADE"
        ),
        nullable=False,
    )
    api_property_id = Column(BigInteger, nullable=False, index=True)

    url = Column(Text)
    thumbnail_url = Column(Text)
    caption = Column(String(255))
    property = relationship("ApiPropertiesDetailsV2", back_populates="floorplans")


class ApiPropertiesDetailsV2FeatureRisks(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_feature_risks"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    feature_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2_features.id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    flood_history = Column(JSONB)
    flood_defences = Column(JSONB)
    flood_risk = Column(JSONB)
    feature = relationship("ApiPropertiesDetailsV2Features", back_populates="risks")


class ApiPropertiesDetailsV2FeatureObligations(Base, SuperIdMixin):
    __tablename__ = "api_properties_details_v2_feature_obligations"
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    # --- MODIFICATION ---
    feature_id = Column(
        BigInteger,
        ForeignKey(
            "rightmove.api_properties_details_v2_features.id", ondelete="CASCADE"
        ),
        nullable=False,
        unique=True,
    )
    api_property_snapshot_id = Column(BigInteger, nullable=False, index=True)
    api_property_id = Column(BigInteger, nullable=False, index=True)

    listed = Column(JSONB)
    restrictions = Column(JSONB)
    private_access = Column(JSONB)
    public_access = Column(JSONB)
    feature = relationship(
        "ApiPropertiesDetailsV2Features", back_populates="obligations"
    )


# data_capture_rightmove_service/src/data_capture_rightmove_service/models/base.py
"""
Base model classes and common SQLAlchemy components.
"""

from sqlalchemy import Column, DateTime, MetaData, func
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.ext.declarative import declared_attr
from sqlalchemy.orm import DeclarativeBase

# Define naming convention for constraints to ensure consistent naming
convention = {
    "ix": "ix_%(column_0_label)s",
    "uq": "uq_%(table_name)s_%(column_0_name)s",
    "ck": "ck_%(table_name)s_%(constraint_name)s",
    "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
    "pk": "pk_%(table_name)s",
}

# Create metadata with naming convention and schema
metadata = MetaData(naming_convention=convention, schema="rightmove")


class Base(DeclarativeBase):
    """Base class for all SQLAlchemy models."""
    
    metadata = metadata
    
    # Add created_at and updated_at timestamps to all tables
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)
    
    # Add tablename based on class name, using snake_case format
    @declared_attr.directive
    def __tablename__(cls) -> str:
        # Convert camel case to snake case
        import re
        name = re.sub('(?<!^)(?=[A-Z])', '_', cls.__name__).lower()
        return name


class SuperIdMixin:
    """Mixin for models that require a super_id field for tracking."""
    
    super_id = Column(UUID(as_uuid=True), nullable=False, index=True)


# data_capture_rightmove_service/src/data_capture_rightmove_service/schemas/property_data.py
"""
Schemas for property data requests and responses.
"""

from datetime import datetime
from typing import Any, Dict, List, Optional
from uuid import UUID

from pydantic import BaseModel, Field, HttpUrl, field_validator, model_validator


# Base schemas for shared fields
class PropertyBase(BaseModel):
    """Base schema for property data requests."""
    
    property_id: int = Field(..., description="Rightmove property ID")
    description: Optional[str] = Field(None, description="Optional description for tracking purposes")


# Request schemas
class FetchPropertyDetailsRequest(BaseModel):
    """Request to fetch property details from Rightmove."""
    
    property_id: Optional[int] = Field(
        None, 
        description="Rightmove property ID"
    )
    property_url: Optional[str] = Field(
        None, 
        description="Rightmove property URL (alternative to property_id)"
    )
    super_id: Optional[UUID] = Field(
        None,
        description="Optional Super ID for tracking purposes"
    )
    description: Optional[str] = Field(
        None, 
        description="Optional description for tracking purposes"
    )
    
    @model_validator(mode='after')
    def validate_property_identifier(self):
        # This validator runs after the model is created and all fields are set
        # Check that at least one of property_id or property_url is provided
        if not self.property_id and not self.property_url:
            raise ValueError("Either property_id or property_url must be provided")
        return self
        
    class Config:
        schema_extra = {
            "example": {
                "property_id": 123456789,
                "description": "Property listing for review"
            }
        }


class FetchBatchRequest(BaseModel):
    """Request to fetch a batch of properties."""
    
    property_ids: List[int] = Field(..., description="List of Rightmove property IDs to fetch")
    api_type: str = Field(..., description="API type to use: 'properties_details' or 'property_for_sale'")


# Response schemas
class FetchPropertyResponse(BaseModel):
    """Response for a property fetch operation."""
    
    property_id: int = Field(..., description="Rightmove property ID")
    super_id: UUID = Field(..., description="Tracking UUID")
    status: str = Field(..., description="Status of the fetch operation")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Timestamp of operation")
    message: Optional[str] = Field(None, description="Additional information")


class FetchBatchResponse(BaseModel):
    """Response for a batch fetch operation."""
    
    batch_id: UUID = Field(..., description="Batch operation ID")
    total: int = Field(..., description="Total number of properties in batch")
    successful: int = Field(..., description="Number of successfully fetched properties")
    failed: int = Field(..., description="Number of failed fetch operations")
    results: List[FetchPropertyResponse] = Field(..., description="Individual property fetch results")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Timestamp of operation")


# Data storage schemas
class PropertyDetailsStorageResponse(BaseModel):
    """Response when property details have been stored."""
    
    property_id: int = Field(..., description="Rightmove property ID")
    super_id: UUID = Field(..., description="Tracking UUID")
    stored: bool = Field(..., description="Whether the property was stored successfully")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Timestamp of storage")
    message: Optional[str] = Field(None, description="Additional information about storage")
    
    class Config:
        schema_extra = {
            "example": {
                "property_id": 12345678,
                "super_id": "123e4567-e89b-12d3-a456-426614174000",
                "stored": True,
                "timestamp": "2023-10-25T12:34:56.789Z",
                "message": "Property data stored successfully"
            }
        }


# Search request schemas
class PropertySearchRequest(BaseModel):
    """Request to search for properties based on criteria."""
    
    location: str = Field(..., description="Location identifier or name")
    min_price: Optional[int] = Field(None, description="Minimum price")
    max_price: Optional[int] = Field(None, description="Maximum price")
    min_bedrooms: Optional[int] = Field(None, description="Minimum number of bedrooms")
    max_bedrooms: Optional[int] = Field(None, description="Maximum number of bedrooms")
    property_type: Optional[str] = Field(None, description="Type of property")
    radius: Optional[float] = Field(None, description="Search radius in miles")
    page_number: int = Field(0, description="Page number for pagination")
    page_size: int = Field(10, description="Number of results per page")
    
    class Config:
        schema_extra = {
            "example": {
                "location": "London",
                "min_price": 200000,
                "max_price": 500000,
                "min_bedrooms": 2,
                "max_bedrooms": 3,
                "property_type": "FLAT",
                "radius": 1.0,
                "page_number": 0,
                "page_size": 10
            }
        }


# data_capture_rightmove_service/src/data_capture_rightmove_service/schemas/__init__.py
"""
Pydantic schemas for data validation, serialization, and documentation.
"""

# Core dependencies
from pydantic import BaseModel, Field
from typing import List, Optional, Union, Dict, Any
from datetime import datetime
from uuid import UUID


# data_capture_rightmove_service/src/data_capture_rightmove_service/schemas/common.py
"""
Common schemas shared across multiple endpoints.
"""

from datetime import datetime
from enum import Enum
from typing import Dict, List, Optional
from uuid import UUID

from pydantic import BaseModel, Field


class MessageResponse(BaseModel):
    """Standard message response for API operations."""
    
    message: str = Field(..., description="Response message")
    success: bool = Field(..., description="Operation success status")


class ErrorResponse(BaseModel):
    """Standard error response for API operations."""
    
    detail: str = Field(..., description="Error detail")
    error_type: Optional[str] = Field(None, description="Type of error")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Timestamp of error")


class HealthStatus(str, Enum):
    """Health status enum for health check responses."""
    
    OK = "ok"
    WARNING = "warning"
    ERROR = "error"
    DEGRADED = "degraded"


class ComponentHealth(BaseModel):
    """Health information for a single component."""
    
    status: HealthStatus = Field(..., description="Status of the component")
    message: Optional[str] = Field(None, description="Optional message about the component health")


class HealthCheckResponse(BaseModel):
    """Standard health check response."""
    
    status: HealthStatus = Field(..., description="Overall service health status")
    version: str = Field(..., description="Service version")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Timestamp of health check")
    components: Dict[str, ComponentHealth] = Field(..., description="Health of individual components")
    uptime_seconds: Optional[float] = Field(None, description="Service uptime in seconds")


# data_capture_rightmove_service/src/data_capture_rightmove_service/crud/properties_details.py
"""
CRUD operations for the properties_details endpoint data.
"""

import re
import uuid
from typing import Any, Dict, List, Optional, Tuple

from sqlalchemy import select
from sqlalchemy.exc import IntegrityError
from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.models.properties_details_v2 import *
from data_capture_rightmove_service.utils.db_utils import normalize_model_instance
from data_capture_rightmove_service.utils.logging_config import logger
from data_capture_rightmove_service.utils.property_mapper import map_property_data


def camel_to_snake(name: str) -> str:
    """Converts a camelCase string to a snake_case string."""
    s1 = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", name)
    return re.sub("([a-z0-9])([A-Z])", r"\1_\2", s1).lower()


import json

from sqlalchemy import String, Text


def map_data_to_model(data: Dict[str, Any], model_class) -> Dict[str, Any]:
    """
    Takes a dictionary with camelCase keys (from an API) and maps it to
    a dictionary with snake_case keys suitable for a SQLAlchemy model.
    It only includes keys that are actual attributes of the model.

    Automatically converts dictionary values to JSON strings for TEXT/String columns.
    """
    snake_case_data = {}
    valid_model_keys = {c.name: c for c in model_class.__table__.columns}

    for key, value in data.items():
        snake_key = camel_to_snake(key)

        # Handle special cases where API name doesn't map cleanly
        if model_class == ApiPropertiesDetailsV2 and snake_key == "identifier":
            snake_key = "id"
        if model_class == ApiPropertiesDetailsV2Price and snake_key == "primary":
            snake_key = "primary_price"
        if model_class == ApiPropertiesDetailsV2Price and snake_key == "secondary":
            snake_key = "secondary_price"
        if model_class == ApiPropertiesDetailsV2Brochure:
            if snake_key == "brochures":  # The API nests the list under 'brochures'
                snake_key = "items"

        if snake_key in valid_model_keys:
            # If we're storing a dictionary in a Text/String column, serialize it to JSON
            column = valid_model_keys[snake_key]
            if isinstance(value, dict) and isinstance(column.type, (Text, String)):
                logger.debug(
                    f"Converting dict to JSON string for {snake_key} in {model_class.__name__}"
                )
                snake_case_data[snake_key] = json.dumps(value)
            else:
                snake_case_data[snake_key] = value
        else:
            logger.debug(
                f"Skipping unmapped key '{key}' (as '{snake_key}') for model {model_class.__name__}"
            )

    return snake_case_data


async def store_properties_details(
    db: AsyncSession, data: Dict[str, Any], super_id: uuid.UUID
) -> Tuple[bool, str]:
    """
    Store property details data from the properties/details v2 API.
    This function creates a new snapshot for each request.
    """
    property_data = data.get("data")
    if not property_data:
        return False, "API response is missing the 'data' object."

    property_id = property_data.get("identifier")
    if not property_id:
        return False, "Could not find 'identifier' in property data."

    try:
        # 1. Main object
        main_values = map_property_data(property_data, ApiPropertiesDetailsV2)
        main_values["id"] = property_id
        main_values["super_id"] = super_id
        property_record = ApiPropertiesDetailsV2(**main_values)
        db.add(property_record)
        await db.flush()  # Flush to get snapshot_id for relationships
        snapshot_id = property_record.snapshot_id

        # 2. Nested one-to-one relationships
        one_to_one_models = {
            "misInfo": ApiPropertiesDetailsV2Misinfo,
            "status": ApiPropertiesDetailsV2Status,
            "stampDutyCalculator": ApiPropertiesDetailsV2StampDuty,
            "branch": ApiPropertiesDetailsV2Branch,
            "price": ApiPropertiesDetailsV2Price,
            "localPropertyTax": ApiPropertiesDetailsV2LocalTax,
            "salesInfo": ApiPropertiesDetailsV2SalesInfo,
            "size": ApiPropertiesDetailsV2Size,
            "mortgageCalculator": ApiPropertiesDetailsV2Mortgage,
            "analyticsInfo": ApiPropertiesDetailsV2AnalyticsInfo,
            "features": ApiPropertiesDetailsV2Features,
            "brochure": ApiPropertiesDetailsV2Brochure,
            "location": ApiPropertiesDetailsV2Location,
        }

        # Store instances to use their generated IDs for nested children
        instance_cache = {}

        for api_key, model_class in one_to_one_models.items():
            if api_key in property_data and property_data[api_key]:
                nested_data = property_data[api_key]
                nested_values = map_property_data(nested_data, model_class)
                nested_values["api_property_snapshot_id"] = snapshot_id
                nested_values["api_property_id"] = property_id
                nested_values["super_id"] = super_id

                instance = model_class(**nested_values)
                db.add(instance)
                instance_cache[api_key] = instance

        # Flush to get IDs for nested relationships
        await db.flush()

        # 3. Deeply nested relationships (children of children)
        if "features" in instance_cache:
            features_instance = instance_cache["features"]
            features_data = property_data.get("features", {})

            if "risks" in features_data and features_data["risks"]:
                risk_values = map_property_data(
                    features_data["risks"], ApiPropertiesDetailsV2FeatureRisks
                )
                # --- FIX: Use correct keyword 'feature_id' ---
                risk_values["feature_id"] = features_instance.id
                risk_values["api_property_snapshot_id"] = snapshot_id
                risk_values["api_property_id"] = property_id
                risk_values["super_id"] = super_id
                db.add(ApiPropertiesDetailsV2FeatureRisks(**risk_values))

            if "obligations" in features_data and features_data["obligations"]:
                obligation_values = map_property_data(
                    features_data["obligations"],
                    ApiPropertiesDetailsV2FeatureObligations,
                )
                # --- FIX: Use correct keyword 'feature_id' ---
                obligation_values["feature_id"] = features_instance.id
                obligation_values["api_property_snapshot_id"] = snapshot_id
                obligation_values["api_property_id"] = property_id
                obligation_values["super_id"] = super_id
                db.add(ApiPropertiesDetailsV2FeatureObligations(**obligation_values))

        if "location" in instance_cache:
            location_instance = instance_cache["location"]
            location_data = property_data.get("location", {})
            if "streetView" in location_data and location_data["streetView"]:
                streetview_values = map_property_data(
                    location_data["streetView"],
                    ApiPropertiesDetailsV2LocationStreetview,
                )
                # --- FIX: Use correct keyword 'location_id' ---
                streetview_values["location_id"] = location_instance.id
                streetview_values["api_property_snapshot_id"] = snapshot_id
                streetview_values["api_property_id"] = property_id
                streetview_values["super_id"] = super_id
                db.add(ApiPropertiesDetailsV2LocationStreetview(**streetview_values))

        if "brochure" in instance_cache:
            brochure_instance = instance_cache["brochure"]
            brochure_data = property_data.get("brochure", {})
            if "brochures" in brochure_data and isinstance(
                brochure_data["brochures"], list
            ):
                for item_data in brochure_data["brochures"]:
                    item_values = map_property_data(
                        item_data, ApiPropertiesDetailsV2BrochureItem
                    )
                    # --- FIX: Use correct keyword 'brochure_id' ---
                    item_values["brochure_id"] = brochure_instance.id
                    item_values["api_property_snapshot_id"] = snapshot_id
                    item_values["api_property_id"] = property_id
                    item_values["super_id"] = super_id
                    db.add(ApiPropertiesDetailsV2BrochureItem(**item_values))

        # 4. Handle one-to-many relationships
        one_to_many_models = {
            "stations": ApiPropertiesDetailsV2Station,
            "photos": ApiPropertiesDetailsV2Photo,
            "epcs": ApiPropertiesDetailsV2Epc,
            "floorplans": ApiPropertiesDetailsV2Floorplan,
        }

        for api_key, model_class in one_to_many_models.items():
            if api_key in property_data and isinstance(property_data[api_key], list):
                for item_data in property_data[api_key]:
                    item_values = map_property_data(item_data, model_class)
                    item_values["api_property_snapshot_id"] = snapshot_id
                    item_values["api_property_id"] = property_id
                    item_values["super_id"] = super_id
                    db.add(model_class(**item_values))

        logger.info(f"Successfully prepared snapshot for property {property_id}.")
        return True, f"Successfully stored property {property_id} details."

    except IntegrityError as e:
        await db.rollback()
        logger.error(
            f"DB Integrity Error for property {property_id}: {e.orig}", exc_info=True
        )
        return False, f"Database integrity error: {e.orig}"
    except Exception as e:
        await db.rollback()
        logger.error(f"Error storing property {property_id}: {e}", exc_info=True)
        return False, f"Error storing property details: {e}"


async def get_property_details_by_id(
    db: AsyncSession, property_id: int
) -> Optional[Dict[str, Any]]:
    """
    Get property details by ID with all related information.

    Args:
        db: Database session
        property_id: Rightmove property ID

    Returns:
        Optional[Dict[str, Any]]: Property details or None if not found
    """
    try:
        # Query the main property details
        result = await db.execute(
            select(ApiPropertiesDetailsV2).where(
                ApiPropertiesDetailsV2.id == property_id
            )
        )
        property_details = result.scalar_one_or_none()

        if not property_details:
            return None

        # Get branch information
        branch_result = await db.execute(
            select(ApiPropertiesDetailsV2Branch).where(
                ApiPropertiesDetailsV2Branch.api_property_id == property_id
            )
        )
        branch = branch_result.scalar_one_or_none()

        # Get price information
        price_result = await db.execute(
            select(ApiPropertiesDetailsV2Price).where(
                ApiPropertiesDetailsV2Price.api_property_id == property_id
            )
        )
        price = price_result.scalar_one_or_none()

        # Get location information
        location_result = await db.execute(
            select(ApiPropertiesDetailsV2Location).where(
                ApiPropertiesDetailsV2Location.api_property_id == property_id
            )
        )
        location = location_result.scalar_one_or_none()

        # Get images
        images_result = await db.execute(
            select(ApiPropertiesDetailsV2Photo).where(
                ApiPropertiesDetailsV2Photo.api_property_id == property_id
            )
        )
        images = images_result.scalars().all()

        # Get floorplans
        floorplans_result = await db.execute(
            select(ApiPropertiesDetailsV2Floorplan).where(
                ApiPropertiesDetailsV2Floorplan.api_property_id == property_id
            )
        )
        floorplans = floorplans_result.scalars().all()

        # Get nearest stations
        stations_result = await db.execute(
            select(ApiPropertiesDetailsV2Station).where(
                ApiPropertiesDetailsV2Station.api_property_id == property_id
            )
        )
        stations = stations_result.scalars().all()

        # Convert database models to dictionary
        property_dict = {
            "id": property_details.id,
            "super_id": str(property_details.super_id),
            "transaction_type": property_details.transaction_type,
            "channel": property_details.channel,
            "bedrooms": property_details.bedrooms,
            "bathrooms": property_details.bathrooms,
            "address": property_details.address,
            "contact_method": property_details.contact_method,
            "property_disclaimer": property_details.property_disclaimer,
            "property_phrase": property_details.property_phrase,
            "full_description": property_details.full_description,
            "listing_update_reason": property_details.listing_update_reason,
            "property_url": property_details.property_url,
            "school_checker_url": property_details.school_checker_url,
            "lettings_info": property_details.lettings_info,
            "property_display_type": property_details.property_display_type,
            "telephone_number": property_details.telephone_number,
            "saved": property_details.saved,
            "sold_prices_url": property_details.sold_prices_url,
            "market_info_url": property_details.market_info_url,
            "note": property_details.note,
            "link_to_glossary": property_details.link_to_glossary,
            "enquired_timestamp": property_details.enquired_timestamp,
            "key_features": property_details.key_features,
            "tags": property_details.tags,
            "virtual_tours": property_details.virtual_tours,
            "branch": branch.__dict__ if branch else None,
            "price": price.__dict__ if price else None,
            "location": location.__dict__ if location else None,
            "images": [img.__dict__ for img in images] if images else [],
            "floorplans": [fp.__dict__ for fp in floorplans] if floorplans else [],
            "nearest_stations": [ns.__dict__ for ns in stations] if stations else [],
            "created_at": property_details.created_at.isoformat(),
            "updated_at": property_details.updated_at.isoformat(),
        }

        # Clean up the dictionaries to remove SQLAlchemy instance state
        for dict_key in ["branch", "price", "location"]:
            if property_dict[dict_key]:
                property_dict[dict_key].pop("_sa_instance_state", None)

        for items_key in ["images", "floorplans", "nearest_stations"]:
            for item in property_dict[items_key]:
                item.pop("_sa_instance_state", None)

        return property_dict

    except Exception as e:
        logger.error(f"Error retrieving property details: {str(e)}")
        return None


async def get_all_property_ids(
    db: AsyncSession, limit: int = 1000, offset: int = 0
) -> List[int]:
    """
    Get all property IDs stored in the database.

    Args:
        db: Database session
        limit: Maximum number of IDs to return
        offset: Offset for pagination

    Returns:
        List[int]: List of property IDs
    """
    try:
        result = await db.execute(
            select(ApiPropertiesDetailsV2.id)
            .order_by(ApiPropertiesDetailsV2.id)
            .limit(limit)
            .offset(offset)
        )
        return [row[0] for row in result.fetchall()]
    except Exception as e:
        logger.error(f"Error retrieving all property IDs: {str(e)}")
        return []


# data_capture_rightmove_service/src/data_capture_rightmove_service/crud/__init__.py
"""
CRUD operations for database interactions in the Data Capture Rightmove Service.
"""

from data_capture_rightmove_service.crud.properties_details import (
    store_properties_details,
    get_property_details_by_id,
    get_all_property_ids
)
from data_capture_rightmove_service.crud.property_details import (
    store_property_details,
    get_property_sale_details_by_id,
    get_all_property_sale_ids
)

__all__ = [
    'store_properties_details',
    'get_property_details_by_id',
    'get_all_property_ids',
    'store_property_details',
    'get_property_sale_details_by_id',
    'get_all_property_sale_ids'
]


# data_capture_rightmove_service/src/data_capture_rightmove_service/crud/property_details.py
"""
CRUD operations for the property-for-sale/detail endpoint data.
"""

import json
import re
import uuid
from typing import Any, Dict, List, Optional, Tuple

from sqlalchemy import String, Text, select
from sqlalchemy.exc import IntegrityError
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from data_capture_rightmove_service.models.property_details import *
from data_capture_rightmove_service.utils.logging_config import logger
from data_capture_rightmove_service.utils.property_mapper import map_property_data


def camel_to_snake(name: str) -> str:
    """Converts a camelCase string to a snake_case string."""
    s1 = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", name)
    return re.sub("([a-z0-9])([A-Z])", r"\1_\2", s1).lower()


def map_data_to_model(data: Dict[str, Any], model_class) -> Dict[str, Any]:
    """
    Takes a dictionary with camelCase keys and maps it to a dictionary with
    snake_case keys suitable for a SQLAlchemy model.

    Automatically converts dictionary values to JSON strings for TEXT/String columns.
    """
    snake_case_data = {}
    valid_model_keys = {c.name: c for c in model_class.__table__.columns}

    for key, value in data.items():
        snake_key = camel_to_snake(key)

        # Special case for 'id' which is the primary key in the main model
        if model_class == ApiPropertyDetails and key == "id":
            snake_key = "id"

        if snake_key in valid_model_keys:
            # If we're storing a dictionary in a Text/String column, serialize it to JSON
            column = valid_model_keys[snake_key]
            if isinstance(value, dict) and isinstance(column.type, (Text, String)):
                logger.debug(
                    f"Converting dict to JSON string for {snake_key} in {model_class.__name__}"
                )
                snake_case_data[snake_key] = json.dumps(value)
            else:
                snake_case_data[snake_key] = value
        else:
            logger.debug(
                f"Skipping unmapped key '{key}' (as '{snake_key}') for model {model_class.__name__}"
            )

    return snake_case_data


def map_data_to_model(data: Dict[str, Any], model_class) -> Dict[str, Any]:
    """
    Takes a dictionary with camelCase keys and maps it to a dictionary with
    snake_case keys suitable for a SQLAlchemy model.

    Automatically converts dictionary values to JSON strings for TEXT/String columns.
    """
    snake_case_data = {}
    valid_model_keys = {c.name: c for c in model_class.__table__.columns}

    for key, value in data.items():
        snake_key = camel_to_snake(key)

        # Special case for 'id' which is the primary key in the main model
        if model_class == ApiPropertyDetails and key == "id":
            snake_key = "id"

        if snake_key in valid_model_keys:
            # If we're storing a dictionary in a Text/String column, serialize it to JSON
            column = valid_model_keys[snake_key]
            if isinstance(value, dict) and isinstance(column.type, (Text, String)):
                logger.debug(
                    f"Converting dict to JSON string for {snake_key} in {model_class.__name__}"
                )
                snake_case_data[snake_key] = json.dumps(value)
            else:
                snake_case_data[snake_key] = value
        else:
            logger.debug(
                f"Skipping unmapped key '{key}' (as '{snake_key}') for model {model_class.__name__}"
            )

    return snake_case_data


async def store_property_details(
    db: AsyncSession, data: Dict[str, Any], super_id: uuid.UUID
) -> Tuple[bool, str]:
    """
    Store property details data from the property-for-sale/detail API.
    This function creates a new snapshot for each request by explicitly creating
    the parent, flushing to get the ID, and then creating all children.
    """
    property_data = data.get("data")
    if not property_data:
        return False, "API response is missing the 'data' object."

    property_id = property_data.get("id")
    if not property_id:
        return False, "Could not find 'id' in property data."

    try:
        # 1. Create and insert the main parent record
        main_values = map_property_data(property_data, ApiPropertyDetails)
        main_values["id"] = property_id
        main_values["super_id"] = super_id
        property_record = ApiPropertyDetails(**main_values)
        db.add(property_record)
        await db.flush()  # Flush to get the generated snapshot_id
        snapshot_id = property_record.snapshot_id

        # Cache for instances that have their own children
        instance_cache = {}

        # 2. Handle one-to-one relationships
        one_to_one_mapping = {
            "address": ApiPropertyDetailAddress,
            "broadband": ApiPropertyDetailBroadband,
            "contactInfo": ApiPropertyDetailContactInfo,
            "customer": ApiPropertyDetailCustomer,
            "dfpAdInfo": ApiPropertyDetailDfpAdInfo,
            "listingHistory": ApiPropertyDetailListingHistory,
            "livingCosts": ApiPropertyDetailLivingCost,
            "location": ApiPropertyDetailLocation,
            "misInfo": ApiPropertyDetailMisInfo,
            "mortgageCalculator": ApiPropertyDetailMortgageCalculator,
            "price": ApiPropertyDetailPrice,  # Corrected from "prices"
            "propertyUrls": ApiPropertyDetailPropertyUrl,
            "sharedOwnership": ApiPropertyDetailSharedOwnership,
            "staticMapImgUrls": ApiPropertyDetailStaticMapImgUrl,
            "status": ApiPropertyDetailStatus,
            "streetView": ApiPropertyDetailStreetView,
            "tenure": ApiPropertyDetailTenure,
            "text": ApiPropertyDetailText,
        }

        for api_key, model_class in one_to_one_mapping.items():
            if api_key in property_data and property_data[api_key]:
                nested_values = map_property_data(property_data[api_key], model_class)
                nested_values["api_property_snapshot_id"] = snapshot_id
                nested_values["api_property_id"] = property_id
                nested_values["super_id"] = super_id

                instance = model_class(**nested_values)
                db.add(instance)
                instance_cache[api_key] = instance

        await db.flush()  # Flush to get IDs for one-to-one children

        # 3. Handle deeply nested relationships
        if "contactInfo" in instance_cache and property_data.get("contactInfo", {}).get(
            "telephoneNumbers"
        ):
            contact_info_instance = instance_cache["contactInfo"]
            tn_data = property_data["contactInfo"]["telephoneNumbers"]
            tn_values = map_property_data(
                tn_data, ApiPropertyDetailContactInfoTelephoneNumber
            )
            tn_values.update(
                {
                    "contact_info_id": contact_info_instance.id,
                    "api_property_snapshot_id": snapshot_id,
                    "api_property_id": property_id,
                    "super_id": super_id,
                }
            )
            db.add(ApiPropertyDetailContactInfoTelephoneNumber(**tn_values))

        if "customer" in instance_cache:
            customer_instance = instance_cache["customer"]
            customer_data = property_data.get("customer", {})
            if customer_data.get("customerDescription"):
                desc_values = map_property_data(
                    customer_data["customerDescription"],
                    ApiPropertyDetailCustomerDescription,
                )
                desc_values.update(
                    {
                        "customer_id": customer_instance.id,
                        "api_property_snapshot_id": snapshot_id,
                        "api_property_id": property_id,
                        "super_id": super_id,
                    }
                )
                db.add(ApiPropertyDetailCustomerDescription(**desc_values))

        # 4. Handle one-to-many relationships
        one_to_many_mapping = {
            "images": (
                ApiPropertyDetailImage,
                ApiPropertyDetailImageResizedUrl,
                "resizedImageUrls",
                "image_id",
            ),
            "floorplans": (
                ApiPropertyDetailFloorplan,
                ApiPropertyDetailFloorplanResizedUrl,
                "resizedFloorplanUrls",
                "floorplan_id",
            ),
            "industryAffiliations": (
                ApiPropertyDetailIndustryAffiliation,
                None,
                None,
                None,
            ),
            "infoReelItems": (ApiPropertyDetailInfoReelItem, None, None, None),
            "nearestStations": (
                ApiPropertyDetailNearestStation,
                ApiPropertyDetailNearestStationType,
                "types",
                "station_id",
            ),
        }

        for api_key, (
            parent_model,
            child_model,
            child_key,
            fk_name,
        ) in one_to_many_mapping.items():
            if api_key in property_data and isinstance(property_data[api_key], list):
                for item_data in property_data[api_key]:
                    parent_values = map_property_data(item_data, parent_model)
                    parent_values.update(
                        {
                            "api_property_snapshot_id": snapshot_id,
                            "api_property_id": property_id,
                            "super_id": super_id,
                        }
                    )
                    parent_instance = parent_model(**parent_values)
                    db.add(parent_instance)

                    if child_model and child_key and fk_name:
                        await db.flush()  # Flush to get parent instance ID
                        if child_key in item_data:
                            child_data_list = item_data[child_key]
                            if not isinstance(child_data_list, list):
                                child_data_list = [
                                    child_data_list
                                ]  # Handle single object case

                            for child_data in child_data_list:
                                # Check if the child data is a simple string (like for station 'types')
                                # or a dictionary (like for 'resizedImageUrls').
                                if isinstance(child_data, str):
                                    # Manually construct the dictionary for the model
                                    child_values = {"type": child_data}
                                elif isinstance(child_data, dict):
                                    # Use the existing mapper for dictionary-based children
                                    child_values = map_property_data(
                                        child_data, child_model
                                    )
                                else:
                                    logger.warning(
                                        f"Skipping unexpected child data type in {api_key}: {type(child_data)}"
                                    )
                                    continue
                                child_values.update(
                                    {
                                        fk_name: parent_instance.id,
                                        "api_property_snapshot_id": snapshot_id,
                                        "api_property_id": property_id,
                                        "super_id": super_id,
                                    }
                                )
                                db.add(child_model(**child_values))

        logger.info(
            f"Successfully prepared property-for-sale snapshot for {property_id}."
        )
        return True, f"Successfully stored property-for-sale {property_id} details."

    except IntegrityError as e:
        await db.rollback()
        logger.error(
            f"DB Integrity Error for property {property_id}: {e.orig}", exc_info=True
        )
        return False, f"Database integrity error: {e.orig}"
    except Exception as e:
        await db.rollback()
        logger.error(
            f"Error storing property-for-sale {property_id}: {e}", exc_info=True
        )
        return False, f"Error storing property-for-sale details: {e}"


async def get_property_sale_details_by_id(
    db: AsyncSession, property_id: int
) -> Optional[Dict[str, Any]]:
    """
    Get property sale details by ID with all related information,
    using efficient relationship loading.

    Args:
        db: Database session
        property_id: Rightmove property ID

    Returns:
        Optional[Dict[str, Any]]: Property details or None if not found
    """
    try:
        # Find the latest snapshot for the given property ID
        stmt = (
            select(ApiPropertyDetails)
            .where(ApiPropertyDetails.id == property_id)
            .order_by(ApiPropertyDetails.created_at.desc())
            .limit(1)
            .options(
                selectinload(ApiPropertyDetails.address),
                selectinload(ApiPropertyDetails.broadband),
                selectinload(ApiPropertyDetails.price),
                selectinload(ApiPropertyDetails.customer).selectinload(
                    ApiPropertyDetailCustomer.description
                ),
                selectinload(ApiPropertyDetails.listing_history),
                selectinload(ApiPropertyDetails.living_costs),
                selectinload(ApiPropertyDetails.location),
                selectinload(ApiPropertyDetails.tenure),
                selectinload(ApiPropertyDetails.text),
                selectinload(ApiPropertyDetails.images).selectinload(
                    ApiPropertyDetailImage.resized_image_urls
                ),
                selectinload(ApiPropertyDetails.floorplans).selectinload(
                    ApiPropertyDetailFloorplan.resized_floorplan_urls
                ),
                selectinload(ApiPropertyDetails.nearest_stations).selectinload(
                    ApiPropertyDetailNearestStation.types
                ),
                selectinload(ApiPropertyDetails.info_reel_items),
            )
        )

        result = await db.execute(stmt)
        property_details = result.scalar_one_or_none()

        if not property_details:
            return None

        # Helper function to convert model to dict, handling relationships
        def to_dict(obj):
            if obj is None:
                return None
            data = {c.name: getattr(obj, c.name) for c in obj.__table__.columns}
            data.pop("_sa_instance_state", None)
            return data

        response_dict = to_dict(property_details)

        # Manually add loaded relationships to the dictionary
        response_dict["address"] = to_dict(property_details.address)
        response_dict["broadband"] = to_dict(property_details.broadband)
        response_dict["price"] = to_dict(property_details.price)

        if property_details.customer:
            response_dict["customer"] = to_dict(property_details.customer)
            if property_details.customer.description:
                response_dict["customer"]["description"] = to_dict(
                    property_details.customer.description
                )

        response_dict["images"] = []
        for img in property_details.images:
            img_dict = to_dict(img)
            img_dict["resized_image_urls"] = to_dict(img.resized_image_urls)
            response_dict["images"].append(img_dict)

        response_dict["floorplans"] = []
        for fp in property_details.floorplans:
            fp_dict = to_dict(fp)
            fp_dict["resized_floorplan_urls"] = to_dict(fp.resized_floorplan_urls)
            response_dict["floorplans"].append(fp_dict)

        response_dict["nearest_stations"] = []
        for station in property_details.nearest_stations:
            station_dict = to_dict(station)
            station_dict["types"] = [to_dict(t) for t in station.types]
            response_dict["nearest_stations"].append(station_dict)

        response_dict["info_reel_items"] = [
            to_dict(item) for item in property_details.info_reel_items
        ]

        # Add other one-to-one relationships
        response_dict["listing_history"] = to_dict(property_details.listing_history)
        response_dict["living_costs"] = to_dict(property_details.living_costs)
        response_dict["location"] = to_dict(property_details.location)
        response_dict["tenure"] = to_dict(property_details.tenure)
        response_dict["text"] = to_dict(property_details.text)

        return response_dict

    except Exception as e:
        logger.error(
            f"Error retrieving property sale details for ID {property_id}: {e}",
            exc_info=True,
        )
        return None


async def get_all_property_sale_ids(
    db: AsyncSession, limit: int = 1000, offset: int = 0
) -> List[int]:
    """
    Get all property sale IDs stored in the database.

    Args:
        db: Database session
        limit: Maximum number of IDs to return
        offset: Offset for pagination

    Returns:
        List[int]: List of property IDs
    """
    try:
        stmt = (
            select(ApiPropertyDetails.id)
            .distinct()
            .order_by(ApiPropertyDetails.id)
            .limit(limit)
            .offset(offset)
        )
        result = await db.execute(stmt)
        return [row[0] for row in result.fetchall()]
    except Exception as e:
        logger.error(f"Error retrieving all property sale IDs: {str(e)}")
        return []


# data_capture_rightmove_service/src/data_capture_rightmove_service/crud/event_crud.py
from typing import Any, Dict, Optional
from uuid import UUID

from sqlalchemy.ext.asyncio import AsyncSession

from data_capture_rightmove_service.models.scrape_event import (
    ScrapeEvent,
    ScrapeEventTypeEnum,
)
from data_capture_rightmove_service.utils.logging_config import logger


async def log_scrape_event(
    db: AsyncSession,
    super_id: UUID,
    event_type: ScrapeEventTypeEnum,
    rightmove_property_id: Optional[int] = None,
    payload: Optional[Dict[str, Any]] = None,
    **kwargs,
) -> ScrapeEvent:
    """Logs a new scrape event to the database."""
    event = ScrapeEvent(
        super_id=super_id,
        event_type=event_type,
        rightmove_property_id=rightmove_property_id,
        payload=payload,
        **kwargs,
    )
    db.add(event)
    await db.commit()
    await db.refresh(event)
    logger.info(f"Logged event: {event_type.value} for super_id {super_id}")
    return event


# data_capture_rightmove_service/sql/property_for_sale.sql
--
-- DATABASE SCHEMA FOR PROPERTY-FOR-SALE API
--
-- This schema uses a hybrid approach:
-- 1. Main Table (`property_listings`): Flattens nested objects with a one-to-one relationship.
-- 2. Child Tables: Creates separate tables for arrays of objects (one-to-many relationships)
--    to maintain normalization and avoid data duplication.
--
-- This design is optimized for both data integrity and query performance.
--

-- =================================================================================
-- Table 1: property_listings
-- The central table for all property listings.
-- =================================================================================
CREATE TABLE property_listings (
    id BIGINT PRIMARY KEY,
    api_source_endpoint VARCHAR(100) NOT NULL, -- e.g., 'property-for-sale'

    -- Top-Level Property Attributes
    added_or_reduced VARCHAR(255),
    auction BOOLEAN,
    bathrooms INT,
    bedrooms INT,
    channel VARCHAR(50),
    commercial BOOLEAN,
    contact_url TEXT,
    country_code VARCHAR(10),
    development BOOLEAN,
    display_address VARCHAR(512),
    display_size VARCHAR(100),
    display_status VARCHAR(255),
    distance DECIMAL(10, 4),
    enhanced_listing BOOLEAN,
    enquired_timestamp TIMESTAMP,
    featured_property BOOLEAN,
    fees_apply BOOLEAN,
    fees_apply_text TEXT,
    first_visible_date TIMESTAMP,
    formatted_branch_name VARCHAR(255),
    formatted_distance VARCHAR(100),
    has_brand_plus BOOLEAN,
    heading TEXT,
    hidden BOOLEAN,
    is_recent BOOLEAN,
    keyword_match_type VARCHAR(100),
    keywords_json JSON, -- Stores the 'keywords' array as JSON
    number_of_floorplans INT,
    number_of_images INT,
    number_of_virtual_tours INT,
    online_viewings_available BOOLEAN,
    premium_listing BOOLEAN,
    property_sub_type VARCHAR(100),
    property_type_full_description VARCHAR(255),
    property_url TEXT,
    residential BOOLEAN,
    saved BOOLEAN,
    show_on_map BOOLEAN,
    static_map_url TEXT,
    students BOOLEAN,
    summary TEXT,
    transaction_type VARCHAR(50),

    -- Flattened 'customer' object fields
    customer_branch_display_name VARCHAR(255),
    customer_branch_id INT,
    customer_branch_landing_page_url TEXT,
    customer_branch_name VARCHAR(255),
    customer_brand_plus_logo_uri TEXT,
    customer_brand_plus_logo_url TEXT,
    customer_brand_trading_name VARCHAR(255),
    customer_build_to_rent BOOLEAN,
    customer_build_to_rent_benefits_json JSON, -- Stores the 'buildToRentBenefits' array
    customer_commercial BOOLEAN,
    customer_contact_telephone VARCHAR(50),
    customer_development BOOLEAN,
    customer_development_content TEXT,
    customer_enhanced_listing BOOLEAN,
    customer_show_on_map BOOLEAN,
    customer_show_reduced_properties BOOLEAN,

    -- Flattened 'listingUpdate' object fields
    listing_update_date TIMESTAMP,
    listing_update_reason VARCHAR(100),

    -- Flattened 'location' object fields
    location_latitude DECIMAL(10, 8),
    location_longitude DECIMAL(11, 8),

    -- Flattened 'lozengeModel' object fields
    lozenge_model_matching_lozenges_json JSON, -- Stores the 'matchingLozenges' array

    -- Flattened 'price' object fields (1-to-1 data)
    price_amount DECIMAL(14, 2),
    price_currency_code VARCHAR(10),
    price_frequency VARCHAR(50),

    -- Flattened 'productLabel' object fields
    product_label_text VARCHAR(255),
    product_label_spotlight_label BOOLEAN,
    
    -- Flattened 'propertyImages' object fields (1-to-1 data)
    property_images_main_image_src TEXT,
    property_images_main_map_image_src TEXT
);


-- =================================================================================
-- Table 2: property_display_prices
-- Stores the 'displayPrices' array from the 'price' object.
-- Each property can have multiple display price entries.
-- =================================================================================
CREATE TABLE property_display_prices (
    id INT PRIMARY KEY AUTO_INCREMENT,
    property_listing_id BIGINT NOT NULL,
    display_price VARCHAR(100),
    display_price_qualifier VARCHAR(255),
    FOREIGN KEY (property_listing_id) REFERENCES property_listings(id) ON DELETE CASCADE
);


-- =================================================================================
-- Table 3: property_images
-- Stores the list of images from the 'propertyImages.images' array.
-- Each property can have multiple images.
-- =================================================================================
CREATE TABLE property_images (
    id INT PRIMARY KEY AUTO_INCREMENT,
    property_listing_id BIGINT NOT NULL,
    caption VARCHAR(255),
    src_url TEXT,
    url TEXT,
    FOREIGN KEY (property_listing_id) REFERENCES property_listings(id) ON DELETE CASCADE
);

# data_capture_rightmove_service/sql/README.md
# Rightmove Data Capture Service SQL Schema

This directory contains SQL schema definitions for the Rightmove Data Capture Service database.

## Schema Overview

The `rightmove_schema.sql` file contains the full database schema definition for storing property data from the Rightmove API. It creates tables under the `rightmove` schema to keep the database organized and avoid conflicts with other services.

### Properties Detail Endpoint Tables

These tables store data from the `properties/details` API endpoint:

- `apipropertiesdetailsv2` - Main property details
- `apipropertiesdetailsagent` - Property agent information
- `apipropertiesdetailsprice` - Property price information
- `apipropertiesdetailslocation` - Property location data
- `apipropertiesdetailsimage` - Property images
- `apipropertiesdetailsfloorplan` - Property floorplans
- `apipropertiesdetailsneareststation` - Nearest stations to the property

### Property For Sale Endpoint Tables

These tables store data from the `property-for-sale/detail` API endpoint:

- `apipropertydetails` - Main property for sale details
- `apipropertydetailsprice` - Property for sale price information
- `apipropertydetailsagent` - Property for sale agent information
- `apipropertydetailsimage` - Property for sale images
- `apipropertydetailsfloorplan` - Property for sale floorplans

## Usage

### Manual Setup

To manually set up the database schema:

```bash
psql -h localhost -U postgres -d rightmove -f rightmove_schema.sql
```

### Alembic Migrations

In production environments, we recommend using Alembic migrations:

```bash
alembic upgrade head
```

This will apply all migrations, including the creation of these tables.

## Design Considerations

1. **Dedicated Schema**: All tables are in the `rightmove` schema to isolate them from other services
2. **Foreign Key Constraints**: Used to maintain referential integrity
3. **Cascade Deletion**: When a parent record is deleted, all related child records are automatically removed
4. **Automatic Timestamps**: All tables have `created_at` and `updated_at` timestamps that are automatically managed
5. **Super ID Tracking**: All tables include a `super_id` column for cross-service tracking


# data_capture_rightmove_service/sql/rightmove_schema.sql.bak
--
-- PostgreSQL database schema for Data Capture Rightmove Service
--
-- This schema defines tables for storing data from Rightmove API endpoints
--

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Name: rightmove; Type: SCHEMA; Schema: -; Owner: -
--
CREATE SCHEMA rightmove;

--
-- Tables for storing property data from properties/details API endpoint
--

-- Base mixin table for super_id tracking
CREATE TABLE rightmove.super_id_mixin (
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- Main property details table
CREATE TABLE rightmove.apipropertiesdetailsv2 (
    id BIGINT PRIMARY KEY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    transaction_type VARCHAR(50),
    channel VARCHAR(50),
    bedrooms INTEGER,
    bathrooms INTEGER,
    address TEXT,
    contact_method VARCHAR(50),
    property_disclaimer TEXT,
    property_phrase VARCHAR(255),
    full_description TEXT,
    listing_update_reason VARCHAR(255),
    property_url TEXT,
    school_checker_url TEXT,
    lettings_info TEXT,
    property_display_type VARCHAR(100),
    telephone_number VARCHAR(50),
    saved BOOLEAN,
    sold_prices_url TEXT,
    market_info_url TEXT,
    note TEXT,
    link_to_glossary TEXT,
    enquired_timestamp VARCHAR,
    key_features TEXT[],
    tags TEXT[],
    virtual_tours JSONB
);

-- Property agent information
CREATE TABLE rightmove.apipropertiesdetailsagent (
    id BIGINT PRIMARY KEY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertiesdetailsv2(id) ON DELETE CASCADE,
    branch_id BIGINT,
    branch_name VARCHAR(255),
    branch_logo_url TEXT,
    branch_email VARCHAR(255),
    company_name VARCHAR(255),
    company_type VARCHAR(50),
    branch_display_address TEXT
);

-- Property price information
CREATE TABLE rightmove.apipropertiesdetailsprice (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertiesdetailsv2(id) ON DELETE CASCADE,
    amount INTEGER,
    currency_code VARCHAR(3),
    frequency VARCHAR(50),
    qualifier VARCHAR(50),
    display_price VARCHAR(100)
);

-- Property location information
CREATE TABLE rightmove.apipropertiesdetailslocation (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertiesdetailsv2(id) ON DELETE CASCADE,
    latitude FLOAT,
    longitude FLOAT,
    street_name VARCHAR(255),
    town VARCHAR(255),
    postal_code VARCHAR(20),
    country_code VARCHAR(2)
);

-- Property images
CREATE TABLE rightmove.apipropertiesdetailsimage (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertiesdetailsv2(id) ON DELETE CASCADE,
    url TEXT,
    caption VARCHAR(255),
    order_index INTEGER
);

-- Property floorplans
CREATE TABLE rightmove.apipropertiesdetailsfloorplan (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertiesdetailsv2(id) ON DELETE CASCADE,
    url TEXT,
    caption VARCHAR(255),
    order_index INTEGER
);

-- Property nearest stations
CREATE TABLE rightmove.apipropertiesdetailsneareststation (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertiesdetailsv2(id) ON DELETE CASCADE,
    name VARCHAR(255),
    distance FLOAT,
    unit VARCHAR(10)
);

--
-- Tables for storing property data from property-for-sale/detail API endpoint
--

-- Main property for sale details table
CREATE TABLE rightmove.apipropertydetails (
    id BIGINT PRIMARY KEY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_type VARCHAR(100),
    property_subtype VARCHAR(100),
    bedrooms INTEGER,
    bathrooms INTEGER,
    summary TEXT,
    description TEXT,
    location VARCHAR(255),
    post_code VARCHAR(20),
    latitude FLOAT,
    longitude FLOAT,
    status VARCHAR(50),
    date_added VARCHAR(50),
    feature_list TEXT[]
);

-- Property for sale price information
CREATE TABLE rightmove.apipropertydetailsprice (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertydetails(id) ON DELETE CASCADE,
    amount INTEGER,
    currency_code VARCHAR(3),
    price_qualifier VARCHAR(50)
);

-- Property for sale agent information
CREATE TABLE rightmove.apipropertydetailsagent (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertydetails(id) ON DELETE CASCADE,
    branch_id BIGINT,
    branch_name VARCHAR(255),
    phone_number VARCHAR(50),
    email VARCHAR(255),
    website VARCHAR(255)
);

-- Property for sale images
CREATE TABLE rightmove.apipropertydetailsimage (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertydetails(id) ON DELETE CASCADE,
    url TEXT,
    caption VARCHAR(255),
    order_index INTEGER
);

-- Property for sale floorplans
CREATE TABLE rightmove.apipropertydetailsfloorplan (
    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
    super_id UUID NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    property_id BIGINT NOT NULL REFERENCES rightmove.apipropertydetails(id) ON DELETE CASCADE,
    url TEXT,
    caption VARCHAR(255),
    order_index INTEGER
);

-- Indexes for better performance
CREATE INDEX idx_apipropertiesdetailsv2_id ON rightmove.apipropertiesdetailsv2(id);
CREATE INDEX idx_apipropertiesdetailsv2_super_id ON rightmove.apipropertiesdetailsv2(super_id);
CREATE INDEX idx_apipropertiesdetailsagent_property_id ON rightmove.apipropertiesdetailsagent(property_id);
CREATE INDEX idx_apipropertiesdetailsprice_property_id ON rightmove.apipropertiesdetailsprice(property_id);
CREATE INDEX idx_apipropertiesdetailslocation_property_id ON rightmove.apipropertiesdetailslocation(property_id);

CREATE INDEX idx_apipropertydetails_id ON rightmove.apipropertydetails(id);
CREATE INDEX idx_apipropertydetails_super_id ON rightmove.apipropertydetails(super_id);
CREATE INDEX idx_apipropertydetailsagent_property_id ON rightmove.apipropertydetailsagent(property_id);
CREATE INDEX idx_apipropertydetailsprice_property_id ON rightmove.apipropertydetailsprice(property_id);
CREATE INDEX idx_apipropertydetailsimage_property_id ON rightmove.apipropertydetailsimage(property_id);


# data_capture_rightmove_service/sql/rightmove_schema.sql
--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 1: property-for-sale/detail endpoint schema
--

-- Use a transaction to ensure all commands succeed or fail together
BEGIN;

-- Drop the schema if it exists, along with all its tables (CASCADE)
-- This allows the script to be run multiple times without errors.
DROP SCHEMA IF EXISTS rightmove CASCADE;

-- Recreate the schema
CREATE SCHEMA rightmove;


-- Set session-specific settings
SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

-- Set the search path for this session to include the new schema
SELECT pg_catalog.set_config('search_path', 'rightmove, public', false);

--
-- Tables for property-for-sale/detail endpoint
--

CREATE TABLE rightmove.api_property_details (
    id BIGINT PRIMARY KEY,
    super_id UUID,
    affordable_buying_scheme BOOLEAN,
    ai_location_info TEXT,
    bathrooms INT,
    bedrooms INT,
    business_for_sale BOOLEAN,
    channel VARCHAR(50),
    commercial BOOLEAN,
    country_guide TEXT,
    enc_id TEXT,
    fees_apply JSONB,
    lettings JSONB,
    property_sub_type TEXT,
    show_school_info BOOLEAN,
    sold_property_type VARCHAR(100),
    terms_of_use TEXT,
    transaction_type VARCHAR(50),
    brochures JSONB,
    commercial_use_classes TEXT[],
    epc_graphs JSONB,
    key_features TEXT[],
    nearest_airports TEXT[],
    rooms TEXT[],
    sizings JSONB,
    tags TEXT[],
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE TABLE rightmove.api_property_detail_addresses (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    country_code VARCHAR(10),
    delivery_point_id BIGINT,
    display_address TEXT,
    incode VARCHAR(10),
    outcode VARCHAR(10),
    uk_country VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_broadbands (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    broadband_checker_url TEXT,
    disclaimer TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_contact_infos (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    contact_method VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_contact_info_telephone_numbers (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    contact_info_detail_id BIGINT NOT NULL UNIQUE,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    disclaimer_description TEXT,
    disclaimer_text TEXT,
    disclaimer_title TEXT,
    international_number VARCHAR(50),
    local_number VARCHAR(50),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (contact_info_detail_id) REFERENCES rightmove.api_property_detail_contact_infos(api_property_detail_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);


CREATE TABLE rightmove.api_property_detail_customers (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    banner_ad TEXT,
    branch_display_name VARCHAR(255),
    branch_id INT,
    branch_name VARCHAR(255),
    build_to_rent BOOLEAN,
    build_to_rent_benefits TEXT[],
    commercial BOOLEAN,
    company_name VARCHAR(255),
    company_trading_name VARCHAR(255),
    customer_banner_ad_profile_url TEXT,
    customer_mpu_ad_profile_url TEXT,
    customer_profile_url TEXT,
    customer_properties_url TEXT,
    display_address TEXT,
    is_new_home_developer BOOLEAN,
    logo_path TEXT,
    mpu_ad TEXT,
    show_brochure_lead_modal BOOLEAN,
    spotlight TEXT,
    valuation_form_url TEXT,
    video_enabled BOOLEAN,
    video_url TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_customer_descriptions (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    customer_api_property_detail_id BIGINT NOT NULL UNIQUE,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    description_html TEXT,
    is_truncated BOOLEAN,
    truncated_description_html TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (customer_api_property_detail_id) REFERENCES rightmove.api_property_detail_customers(api_property_detail_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);
--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 2: Additional property-for-sale/detail endpoint schema tables
--

CREATE TABLE rightmove.api_property_detail_customer_development_infos (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    customer_api_property_detail_id BIGINT NOT NULL UNIQUE,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    site_plan_uri TEXT,
    microsite_features TEXT[],
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (customer_api_property_detail_id) REFERENCES rightmove.api_property_detail_customers(api_property_detail_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_customer_products (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    customer_api_property_detail_id BIGINT NOT NULL UNIQUE,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    has_microsite BOOLEAN,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (customer_api_property_detail_id) REFERENCES rightmove.api_property_detail_customers(api_property_detail_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_dfp_ad_infos (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    channel VARCHAR(50),
    targeting JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_floorplans (
    id SERIAL PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    caption VARCHAR(255),
    type VARCHAR(50),
    url TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_floorplan_resized_floorplan_urls (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    floorplan_id INT NOT NULL UNIQUE,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    size_296x197 TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (floorplan_id) REFERENCES rightmove.api_property_detail_floorplans(id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_images (
    id SERIAL PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    caption VARCHAR(255),
    url TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_image_resized_image_urls (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    image_id INT NOT NULL UNIQUE,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    size_135x100 TEXT,
    size_476x317 TEXT,
    size_656x437 TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (image_id) REFERENCES rightmove.api_property_detail_images(id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_industry_affiliations (
    id SERIAL PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    image_path TEXT,
    name TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_info_reel_items (
    id SERIAL PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    primary_text TEXT,
    secondary_text TEXT,
    title TEXT,
    tooltip_text TEXT,
    type TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);
--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 3: More tables for property-for-sale/detail endpoint
--

CREATE TABLE rightmove.api_property_detail_listing_history (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    listing_update_reason TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_living_costs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    annual_ground_rent TEXT,
    annual_service_charge TEXT,
    council_tax_band VARCHAR(10),
    council_tax_exempt BOOLEAN,
    council_tax_included BOOLEAN,
    domestic_rates TEXT,
    ground_rent_percentage_increase TEXT,
    ground_rent_review_period_in_years TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_locations (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    circle_radius_on_map INT,
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    pin_type VARCHAR(50),
    show_map BOOLEAN,
    zoom_level INT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_mis_infos (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    branch_id INT,
    brand_plus BOOLEAN,
    featured_property BOOLEAN,
    offer_advert_stamp_type_id TEXT,
    premium_display BOOLEAN,
    premium_display_stamp_id TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_mortgage_calculators (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    price BIGINT,
    property_type_alias VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_nearest_stations (
    id SERIAL PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    distance DECIMAL(18, 16),
    name TEXT,
    unit TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_nearest_station_types (
    id SERIAL PRIMARY KEY,
    station_id INT NOT NULL,
    api_property_detail_id BIGINT NOT NULL,
    super_id UUID,
    type VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (station_id) REFERENCES rightmove.api_property_detail_nearest_stations(id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_prices (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    display_price_qualifier VARCHAR(255),
    exchange_rate TEXT,
    message TEXT,
    price_per_sq_ft VARCHAR(100),
    primary_price VARCHAR(100),
    secondary_price TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);
--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 4: Final tables for property-for-sale/detail endpoint
--

CREATE TABLE rightmove.api_property_detail_property_urls (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    nearby_sold_properties_url TEXT,
    similar_properties_url TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_shared_ownerships (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    ownership_percentage DECIMAL(10, 4),
    rent_frequency VARCHAR(100),
    rent_price DECIMAL(12, 2),
    shared_ownership_flag BOOLEAN,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_static_map_img_urls (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    static_map_img_url_desktop_large TEXT,
    static_map_img_url_desktop_small TEXT,
    static_map_img_url_mobile TEXT,
    static_map_img_url_tablet TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_status (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    archived BOOLEAN,
    published BOOLEAN,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_street_views (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    heading TEXT,
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    pitch TEXT,
    zoom TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_tenures (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    message TEXT,
    tenure_type VARCHAR(100),
    years_remaining_on_lease INT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_property_detail_texts (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_detail_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    auction_fees_disclaimer TEXT,
    description TEXT,
    disclaimer TEXT,
    guide_price_disclaimer TEXT,
    new_homes_brochure_disclaimer TEXT,
    page_title TEXT,
    property_phrase VARCHAR(255),
    reserve_price_disclaimer TEXT,
    share_description TEXT,
    share_text TEXT,
    short_description TEXT,
    static_map_disclaimer_text TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_detail_id) REFERENCES rightmove.api_property_details(id) ON DELETE CASCADE
);

-- Indexes for property-for-sale/detail endpoint tables
CREATE INDEX idx_api_property_details_id ON rightmove.api_property_details(id);
CREATE INDEX idx_api_property_details_super_id ON rightmove.api_property_details(super_id);
--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 5: properties/details v2 endpoint schema
--

--
-- Tables for properties/details v2 endpoint
--

CREATE TABLE rightmove.api_properties_details_v2 (
    id BIGINT PRIMARY KEY,
    super_id UUID,
    transaction_type VARCHAR(50),
    channel VARCHAR(50),
    bedrooms INT,
    bathrooms INT,
    address TEXT,
    contact_method VARCHAR(50),
    property_disclaimer TEXT,
    property_phrase VARCHAR(255),
    full_description TEXT,
    listing_update_reason VARCHAR(255),
    property_url TEXT,
    school_checker_url TEXT,
    lettings_info JSONB,
    property_display_type VARCHAR(100),
    telephone_number VARCHAR(50),
    saved BOOLEAN,
    sold_prices_url TEXT,
    market_info_url TEXT,
    note TEXT,
    link_to_glossary TEXT,
    enquired_timestamp TIMESTAMPTZ,
    key_features TEXT[],
    tags TEXT[],
    virtual_tours JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE TABLE rightmove.api_properties_details_v2_mis_info (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    branch_id INT,
    offer_advert_stamp_type_id TEXT,
    brand_plus BOOLEAN,
    featured_property BOOLEAN,
    channel VARCHAR(50),
    premium_display BOOLEAN,
    premium_display_stamp_id TEXT,
    country_code VARCHAR(10),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_status (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    available BOOLEAN,
    label TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_stamp_duty (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    country VARCHAR(100),
    price BIGINT,
    buyer_type TEXT,
    result TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_features (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    electricity JSONB,
    broadband JSONB,
    water JSONB,
    sewerage JSONB,
    heating JSONB,
    accessibility JSONB,
    parking JSONB,
    garden JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_branch (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    identifier INT,
    name VARCHAR(255),
    brand_name VARCHAR(255),
    display_name VARCHAR(255),
    address TEXT,
    logo TEXT,
    developer BOOLEAN,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);
--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 6: More tables for properties/details v2 endpoint
--

CREATE TABLE rightmove.api_properties_details_v2_brochure (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    title VARCHAR(255),
    show_brochure_lead BOOLEAN,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_price (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    primary_price VARCHAR(100),
    secondary_price VARCHAR(255),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_local_tax (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    type VARCHAR(100),
    status TEXT,
    value VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_location (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    pin_type VARCHAR(100),
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    map_preview_url TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_sales_info (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    tenure_type VARCHAR(100),
    tenure_display_type VARCHAR(100),
    ground_rent TEXT,
    annual_service_charge TEXT,
    estate_charge TEXT,
    length_of_lease TEXT,
    shared_ownership_percentage TEXT,
    shared_ownership_rent TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_size (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    primary_size VARCHAR(100),
    secondary_size TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_mortgage (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    price BIGINT,
    property_type_alias VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);
--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 7: Final tables for properties/details v2 endpoint
--

CREATE TABLE rightmove.api_properties_details_v2_analytics_info (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    api_property_id BIGINT NOT NULL UNIQUE,
    super_id UUID,
    branch_id VARCHAR(50),
    property_id VARCHAR(50),
    online_viewing VARCHAR(10),
    image_count VARCHAR(10),
    floorplan_count VARCHAR(10),
    beds VARCHAR(10),
    postcode VARCHAR(20),
    property_type VARCHAR(100),
    property_sub_type VARCHAR(100),
    added VARCHAR(20),
    price VARCHAR(50),
    tenure VARCHAR(100),
    bathrooms VARCHAR(10),
    shared_ownership VARCHAR(10),
    electricity VARCHAR(50),
    broadband VARCHAR(50),
    water VARCHAR(50),
    sewerage VARCHAR(50),
    heating VARCHAR(50),
    accessibility VARCHAR(50),
    parking VARCHAR(50),
    garden VARCHAR(50),
    flood_history VARCHAR(50),
    flood_defences VARCHAR(50),
    flood_risk VARCHAR(50),
    listed VARCHAR(50),
    restrictions VARCHAR(50),
    private_access VARCHAR(50),
    public_access VARCHAR(50),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_stations (
    id SERIAL PRIMARY KEY,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    station VARCHAR(255),
    distance DECIMAL(8, 2),
    type VARCHAR(50),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_photos (
    id SERIAL PRIMARY KEY,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    url TEXT,
    thumbnail_url TEXT,
    max_size_url TEXT,
    caption TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_epcs (
    id SERIAL PRIMARY KEY,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    url TEXT,
    caption VARCHAR(255),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_floorplans (
    id SERIAL PRIMARY KEY,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    url TEXT,
    thumbnail_url TEXT,
    caption VARCHAR(255),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_feature_risks (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    feature_api_property_id BIGINT NOT NULL UNIQUE,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    flood_history JSONB,
    flood_defences JSONB,
    flood_risk JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (feature_api_property_id) REFERENCES rightmove.api_properties_details_v2_features(api_property_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_feature_obligations (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    feature_api_property_id BIGINT NOT NULL UNIQUE,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    listed JSONB,
    restrictions JSONB,
    private_access JSONB,
    public_access JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (feature_api_property_id) REFERENCES rightmove.api_properties_details_v2_features(api_property_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_brochure_items (
    id SERIAL PRIMARY KEY,
    brochure_api_property_id BIGINT NOT NULL,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    url TEXT,
    caption VARCHAR(255),
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (brochure_api_property_id) REFERENCES rightmove.api_properties_details_v2_brochure(api_property_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

CREATE TABLE rightmove.api_properties_details_v2_location_street_view (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    location_api_property_id BIGINT NOT NULL UNIQUE,
    api_property_id BIGINT NOT NULL,
    super_id UUID,
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    heading TEXT,
    pitch TEXT,
    zoom TEXT,
    url TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    FOREIGN KEY (location_api_property_id) REFERENCES rightmove.api_properties_details_v2_location(api_property_id) ON DELETE CASCADE,
    FOREIGN KEY (api_property_id) REFERENCES rightmove.api_properties_details_v2(id) ON DELETE CASCADE
);

-- Indexes for properties/details v2 endpoint tables
CREATE INDEX idx_api_properties_details_v2_id ON rightmove.api_properties_details_v2(id);
CREATE INDEX idx_api_properties_details_v2_super_id ON rightmove.api_properties_details_v2(super_id);

--
-- PostgreSQL database schema for Data Capture Rightmove Service
-- Part 8: The Scrape Event Log (THE NEW PART)
--

-- This ENUM defines the different types of events we can log.
CREATE TYPE rightmove.scrape_event_type AS ENUM (
    'REQUEST_RECEIVED',
    'API_CALL_ATTEMPT',
    'API_CALL_SUCCESS',
    'API_CALL_FAILURE',
    'DATA_PARSED_SUCCESS',
    'DATA_PARSED_FAILURE',
    'DATA_STORED_SUCCESS',
    'DATA_STORED_FAILURE'
);

-- This is the new "Captain's Log" table.
CREATE TABLE rightmove.scrape_events (
    id BIGSERIAL PRIMARY KEY,
    super_id UUID NOT NULL,
    rightmove_property_id BIGINT,

    -- Event-specific details
    event_type rightmove.scrape_event_type NOT NULL,
    event_timestamp TIMESTAMPTZ NOT NULL DEFAULT now(),

    -- Context for the event
    source_service_name TEXT,
    api_endpoint_called TEXT,

    -- Data payload and errors
    http_status_code INT,
    error_code TEXT,
    error_message TEXT,

    -- Full JSON dump, as requested by the owner
    payload JSONB,

    -- Data completeness metrics, as requested
    response_item_count INT,
    response_null_item_count INT,

    created_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- Indexes for efficient querying of the log
CREATE INDEX idx_scrape_events_super_id ON rightmove.scrape_events(super_id);
CREATE INDEX idx_scrape_events_rightmove_property_id ON rightmove.scrape_events(rightmove_property_id);
CREATE INDEX idx_scrape_events_event_type ON rightmove.scrape_events(event_type);
CREATE INDEX idx_scrape_events_timestamp ON rightmove.scrape_events(event_timestamp);

COMMIT;

