name: Deploy to Production Server with Docker Compose

on:
  push:
    branches:
      - staging # Trigger on push to the staging branch
  workflow_dispatch:

# --- GLOBAL ENVIRONMENT VARIABLES ---
# These are used across multiple jobs for consistency.
env:
  DOCKER_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
  AUTH_SERVICE_IMAGE: ${{ secrets.DOCKERHUB_USERNAME }}/auth_service
  SUPER_ID_SERVICE_IMAGE: ${{ secrets.DOCKERHUB_USERNAME }}/super_id_service
  DATA_CAPTURE_RIGHTMOVE_SERVICE_IMAGE: ${{ secrets.DOCKERHUB_USERNAME }}/data_capture_rightmove_service

jobs:
  #########################################
  # Job 1: Detect Which Services Changed #
  #########################################
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      auth_service: ${{ steps.filter.outputs.auth_service }}
      super_id_service: ${{ steps.filter.outputs.super_id_service }}
      data_capture_rightmove_service: ${{ steps.filter.outputs.data_capture_rightmove_service }}
      workflow_changed: ${{ steps.filter.outputs.workflow_changed }}
    steps:
      - uses: actions/checkout@v3
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            auth_service:
              - 'auth_service/**'
            super_id_service:
              - 'super_id_service/**'
            data_capture_rightmove_service:
              - 'data_capture_rightmove_service/**'
            workflow_changed:
              - '.github/workflows/**'
              - 'docker-compose.prod.yml'

  ##############################################
  # JOBS 2, 3, 4: Build and push Docker images for each service. #
  # These jobs only run if changes are detected in their respective service directories #
  # or if the workflow is triggered manually. #
  ##############################################
  build-auth-service:
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.auth_service == 'true' || needs.detect-changes.outputs.workflow_changed == 'true' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/workflows/actions/build-push
        with:
          service_name: auth_service
          image_name: ${{ secrets.DOCKERHUB_USERNAME }}/auth_service
          dockerhub_username: ${{ secrets.DOCKERHUB_USERNAME }}
          dockerhub_token: ${{ secrets.DOCKERHUB_MONOREPO_TOKEN }}

  build-super-id-service:
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.super_id_service == 'true' || needs.detect-changes.outputs.workflow_changed == 'true' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/workflows/actions/build-push
        with:
          service_name: super_id_service
          image_name: ${{ secrets.DOCKERHUB_USERNAME }}/super_id_service
          dockerhub_username: ${{ secrets.DOCKERHUB_USERNAME }}
          dockerhub_token: ${{ secrets.DOCKERHUB_MONOREPO_TOKEN }}

  build-data-capture-service:
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.data_capture_rightmove_service == 'true' || needs.detect-changes.outputs.workflow_changed == 'true' || github.event_name == 'workflow_dispatch'
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/workflows/actions/build-push
        with:
          service_name: data_capture_rightmove_service
          image_name: ${{ secrets.DOCKERHUB_USERNAME }}/data_capture_rightmove_service
          dockerhub_username: ${{ secrets.DOCKERHUB_USERNAME }}
          dockerhub_token: ${{ secrets.DOCKERHUB_MONOREPO_TOKEN }}

  ####################################
  # Job 5: Deploy to Staging Server #
  ####################################
  deploy:
    # UPDATE: Now runs even if build is skipped, but checks if it ran
    needs:
      - detect-changes
      - build-auth-service
      - build-super-id-service
      - build-data-capture-service
    # It will only proceed if a change was detected or if manually triggered.
    if: always() && (needs.detect-changes.outputs.auth_service == 'true' || needs.detect-changes.outputs.super_id_service == 'true' || needs.detect-changes.outputs.data_capture_rightmove_service == 'true' || needs.detect-changes.outputs.workflow_changed == 'true' || github.event_name == 'workflow_dispatch')
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Server
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            set -e  # Exit immediately if a command fails

            # --- 1. PREPARE THE ENVIRONMENT ---
            echo "Navigating to deployment directory..."
            mkdir -p /home/ubuntu/paservices
            cd /home/ubuntu/paservices

            echo "Fetching the latest code from origin..."
            git fetch origin

            echo "Resetting local 'staging' branch to match remote..."
            # This is the crucial step to discard any manual changes on the server
            # and prevent 'git pull' conflicts.
            git reset --hard origin/staging
            echo "âœ… Local repository is now in a clean state."

            # --- 2. DECRYPT AND CREATE ENVIRONMENT FILES ---
            echo "Decrypting production environment files..."

            # Decrypt for auth_service
            gpg --quiet --batch --yes --decrypt \
              --passphrase="${{ secrets.GPG_PASSPHRASE }}" \
              -o auth_service/.env.prod auth_service/.env.prod.gpg
            echo "âœ… Decrypted environment for auth_service."

            # Decrypt for super_id_service
            gpg --quiet --batch --yes --decrypt \
              --passphrase="${{ secrets.GPG_PASSPHRASE }}" \
              -o super_id_service/.env.prod super_id_service/.env.prod.gpg
            echo "âœ… Decrypted environment for super_id_service."

            # Decrypt for data_capture_rightmove_service (note the .env.prod filename)
            gpg --quiet --batch --yes --decrypt \
              --passphrase="${{ secrets.GPG_PASSPHRASE }}" \
              -o data_capture_rightmove_service/.env.prod data_capture_rightmove_service/.env.prod.gpg
            echo "âœ… Decrypted environment for data_capture_rightmove_service."

            echo "Creating root .env file for Docker Compose..."
            cat > .env << EOF
            # Core variables needed by docker-compose.prod.yml
            DOCKER_USERNAME=${{ secrets.DOCKERHUB_USERNAME }}
            ACME_EMAIL=${{ secrets.ACME_EMAIL }}

            # Domain Names for Traefik labels
            AUTH_SERVICE_DOMAIN=${{ secrets.AUTH_SERVICE_DOMAIN }}
            SUPER_ID_SERVICE_DOMAIN=${{ secrets.SUPER_ID_SERVICE_DOMAIN }}
            DATA_CAPTURE_RIGHTMOVE_SERVICE_DOMAIN=${{ secrets.DATA_CAPTURE_RIGHTMOVE_SERVICE_DOMAIN }}

            # These variables are also needed by the services themselves, and Docker Compose
            # will make them available to the containers.
            AUTH_SERVICE_DATABASE_URL='${{ secrets.AUTH_SERVICE_DATABASE_URL }}'
            SUPER_ID_SERVICE_DATABASE_URL='${{ secrets.SUPER_ID_SERVICE_DATABASE_URL }}'
            DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL='${{ secrets.DATA_CAPTURE_RIGHTMOVE_SERVICE_DATABASE_URL }}'

            SUPABASE_URL='${{ secrets.SUPABASE_URL }}'
            SUPABASE_ANON_KEY='${{ secrets.SUPABASE_ANON_KEY }}'
            SUPABASE_SERVICE_ROLE_KEY='${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}'

            M2M_JWT_SECRET_KEY=${{ secrets.M2M_JWT_SECRET_KEY }}

            DATA_CAPTURE_M2M_CLIENT_ID=${{ secrets.DATA_CAPTURE_M2M_CLIENT_ID }}
            DATA_CAPTURE_M2M_CLIENT_SECRET=${{ secrets.DATA_CAPTURE_M2M_CLIENT_SECRET }}
            RAPID_API_KEY=${{ secrets.RAPID_API_KEY }}
            EOF
            echo "âœ… Root .env file created successfully."

            # --- 3. ORCHESTRATE DEPLOYMENT WITH DOCKER COMPOSE ---
            echo "Logging into Docker Hub..."
            echo ${{ secrets.DOCKERHUB_MONOREPO_TOKEN }} | docker login -u ${{ secrets.DOCKERHUB_USERNAME }} --password-stdin

            echo "Pulling latest Docker images..."
            docker compose -f docker-compose.prod.yml pull

            echo "Running database migrations..."
            # Run migrations for each service that has them, using their decrypted env files.
            docker compose -f docker-compose.prod.yml run --rm \
              --env-file ./auth_service/.env.prod \
              auth_service alembic upgrade head

            docker compose -f docker-compose.prod.yml run --rm \
              --env-file ./super_id_service/.env.prod \
              super_id_service alembic upgrade head
              
            docker compose -f docker-compose.prod.yml run --rm \
              --env-file ./data_capture_rightmove_service/.env.prod \
              data_capture_rightmove_service alembic upgrade head

            echo "Starting application stack..."
            # The 'env_file' directives within docker-compose.prod.yml will pick up the decrypted files.
            docker compose -f docker-compose.prod.yml up -d --remove-orphans

            # --- 4. CLEANUP ---
            echo "Cleaning up old Docker images..."
            docker image prune -f

            echo "ðŸš€ Deployment complete!"
